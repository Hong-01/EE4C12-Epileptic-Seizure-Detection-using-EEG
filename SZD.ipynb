{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4C12-Epileptic-Seizure-Detection-using-EEG\n",
    "\n",
    "\n",
    "    \n",
    "Group 16 Members:\n",
    "\n",
    "    1. Zhixuan Ge  \n",
    "    2. Yanqi Hong "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Program Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, precision_recall_curve, PrecisionRecallDisplay, roc_auc_score, RocCurveDisplay, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#load data on Yanqi Hong's computer\\ndata = pd.read_csv('E:\\\\DATA\\\\TUD\\\\Master\\\\TUD_Master_Y1\\\\Q1\\\\EE4C12 Machine Learning For Electrical Engineering\\\\CodeLab\\\\Project\\\\S&S_SZD (1)\\\\Data\\\\Project_Data_EE4C12_S&S_SZD.csv')\\ndata\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#load data on Yanqi Hong's computer\n",
    "data = pd.read_csv('E:\\DATA\\TUD\\Master\\TUD_Master_Y1\\Q1\\EE4C12 Machine Learning For Electrical Engineering\\CodeLab\\Project\\S&S_SZD (1)\\Data\\Project_Data_EE4C12_S&S_SZD.csv')\n",
    "data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>annotation</th>\n",
       "      <th>min|FP1-F7</th>\n",
       "      <th>min|F7-T3</th>\n",
       "      <th>min|T3-T5</th>\n",
       "      <th>min|T5-O1</th>\n",
       "      <th>min|FP2-F8</th>\n",
       "      <th>min|F8-T4</th>\n",
       "      <th>min|T4-T6</th>\n",
       "      <th>min|T6-O2</th>\n",
       "      <th>...</th>\n",
       "      <th>norm_power_HF|CZ-C4</th>\n",
       "      <th>norm_power_HF|C4-T4</th>\n",
       "      <th>norm_power_HF|FP1-F3</th>\n",
       "      <th>norm_power_HF|F3-C3</th>\n",
       "      <th>norm_power_HF|C3-P3</th>\n",
       "      <th>norm_power_HF|P3-O1</th>\n",
       "      <th>norm_power_HF|FP2-F4</th>\n",
       "      <th>norm_power_HF|F4-C4</th>\n",
       "      <th>norm_power_HF|C4-P4</th>\n",
       "      <th>norm_power_HF|P4-O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.066920</td>\n",
       "      <td>0.102402</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.690787</td>\n",
       "      <td>0.154544</td>\n",
       "      <td>0.062533</td>\n",
       "      <td>0.046460</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.086999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>0.225788</td>\n",
       "      <td>0.409987</td>\n",
       "      <td>0.184671</td>\n",
       "      <td>0.071133</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>0.079494</td>\n",
       "      <td>0.047536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037326</td>\n",
       "      <td>0.100177</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.622584</td>\n",
       "      <td>0.394504</td>\n",
       "      <td>0.225516</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.102142</td>\n",
       "      <td>0.068105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027546</td>\n",
       "      <td>0.107883</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.359140</td>\n",
       "      <td>0.276964</td>\n",
       "      <td>0.104977</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.079467</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>0.089385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036820</td>\n",
       "      <td>0.182520</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.328354</td>\n",
       "      <td>0.156929</td>\n",
       "      <td>0.151952</td>\n",
       "      <td>0.047532</td>\n",
       "      <td>0.135071</td>\n",
       "      <td>0.098320</td>\n",
       "      <td>0.137701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55451</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244334</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.058277</td>\n",
       "      <td>0.083594</td>\n",
       "      <td>0.114426</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>0.295364</td>\n",
       "      <td>0.185930</td>\n",
       "      <td>0.199585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55452</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588236</td>\n",
       "      <td>0.743060</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>0.228458</td>\n",
       "      <td>0.170603</td>\n",
       "      <td>0.351418</td>\n",
       "      <td>0.638666</td>\n",
       "      <td>0.490806</td>\n",
       "      <td>0.307429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55453</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296041</td>\n",
       "      <td>0.770194</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.090919</td>\n",
       "      <td>0.186074</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.231053</td>\n",
       "      <td>0.770637</td>\n",
       "      <td>0.285257</td>\n",
       "      <td>0.413382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55454</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440360</td>\n",
       "      <td>0.720855</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>0.077674</td>\n",
       "      <td>0.269610</td>\n",
       "      <td>0.186769</td>\n",
       "      <td>0.790173</td>\n",
       "      <td>0.473615</td>\n",
       "      <td>0.415771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55455</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019325</td>\n",
       "      <td>0.735140</td>\n",
       "      <td>0.030715</td>\n",
       "      <td>0.077191</td>\n",
       "      <td>0.095298</td>\n",
       "      <td>0.317765</td>\n",
       "      <td>0.271859</td>\n",
       "      <td>0.675646</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.561740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55456 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient  annotation  min|FP1-F7  min|F7-T3  min|T3-T5  min|T5-O1  \\\n",
       "0          258           1          50         61         57         53   \n",
       "1          258           1          48         62         60         46   \n",
       "2          258           1          51         60         59         45   \n",
       "3          258           1          49         58         56         42   \n",
       "4          258           1          45         57         61         41   \n",
       "...        ...         ...         ...        ...        ...        ...   \n",
       "55451    11580          -1          75         73         81         80   \n",
       "55452    11580          -1          74         74         77         71   \n",
       "55453    11580          -1          72         76         72         73   \n",
       "55454    11580          -1          77         82         74         75   \n",
       "55455    11580          -1          71         79         74         78   \n",
       "\n",
       "       min|FP2-F8  min|F8-T4  min|T4-T6  min|T6-O2  ...  norm_power_HF|CZ-C4  \\\n",
       "0              39         35         39         35  ...             0.016087   \n",
       "1              38         35         39         33  ...             0.024006   \n",
       "2              38         36         40         36  ...             0.037326   \n",
       "3              36         36         41         37  ...             0.027546   \n",
       "4              35         37         41         37  ...             0.036820   \n",
       "...           ...        ...        ...        ...  ...                  ...   \n",
       "55451          66         80         77         75  ...             0.244334   \n",
       "55452          79         75         82         77  ...             0.588236   \n",
       "55453          74         76         80         76  ...             0.296041   \n",
       "55454          82         85         80         76  ...             0.440360   \n",
       "55455          80         85         81         75  ...             1.019325   \n",
       "\n",
       "       norm_power_HF|C4-T4  norm_power_HF|FP1-F3  norm_power_HF|F3-C3  \\\n",
       "0                 0.066920              0.102402             0.481384   \n",
       "1                 0.064857              0.031791             0.225788   \n",
       "2                 0.100177              0.050009             0.622584   \n",
       "3                 0.107883              0.014017             0.359140   \n",
       "4                 0.182520              0.031397             0.328354   \n",
       "...                    ...                   ...                  ...   \n",
       "55451             0.625396              0.023821             0.058277   \n",
       "55452             0.743060              0.076294             0.332341   \n",
       "55453             0.770194              0.041190             0.090919   \n",
       "55454             0.720855              0.026959             0.026340   \n",
       "55455             0.735140              0.030715             0.077191   \n",
       "\n",
       "       norm_power_HF|C3-P3  norm_power_HF|P3-O1  norm_power_HF|FP2-F4  \\\n",
       "0                 0.690787             0.154544              0.062533   \n",
       "1                 0.409987             0.184671              0.071133   \n",
       "2                 0.394504             0.225516              0.050673   \n",
       "3                 0.276964             0.104977              0.018042   \n",
       "4                 0.156929             0.151952              0.047532   \n",
       "...                    ...                  ...                   ...   \n",
       "55451             0.083594             0.114426              0.119654   \n",
       "55452             0.228458             0.170603              0.351418   \n",
       "55453             0.186074             0.216797              0.231053   \n",
       "55454             0.077674             0.269610              0.186769   \n",
       "55455             0.095298             0.317765              0.271859   \n",
       "\n",
       "       norm_power_HF|F4-C4  norm_power_HF|C4-P4  norm_power_HF|P4-O2  \n",
       "0                 0.046460             0.066575             0.086999  \n",
       "1                 0.022369             0.079494             0.047536  \n",
       "2                 0.044906             0.102142             0.068105  \n",
       "3                 0.079467             0.078255             0.089385  \n",
       "4                 0.135071             0.098320             0.137701  \n",
       "...                    ...                  ...                  ...  \n",
       "55451             0.295364             0.185930             0.199585  \n",
       "55452             0.638666             0.490806             0.307429  \n",
       "55453             0.770637             0.285257             0.413382  \n",
       "55454             0.790173             0.473615             0.415771  \n",
       "55455             0.675646             0.506836             0.561740  \n",
       "\n",
       "[55456 rows x 362 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data on Zhixuan's computer\n",
    "data = pd.read_csv('D:\\\\User\\Zhixuan Ge\\Onedrive TUDelft\\OneDrive - Delft University of Technology\\Courses\\ML for EE\\SZD\\S&S_SZD\\Project_Data_EE4C12_S&S_SZD.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applied for the moment\n",
    "# x is the features, y is the label\n",
    "y = np.int32(data['annotation'].values)\n",
    "X = data.iloc[:, 2:].values\n",
    "\n",
    "#split the data into training and testing\n",
    "Shuffle_state = 42\n",
    "test_size = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=Shuffle_state)\n",
    "\n",
    "#k fold cross validation\n",
    "kf = KFold(n_splits=5, random_state=Shuffle_state, shuffle=True)\n",
    "\n",
    "idx_k_train = []\n",
    "idx_k_val = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "    idx_k_train.append(train_index)\n",
    "    idx_k_val.append(val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.int32(data['annotation'].values)\n",
    "X = data.iloc[:, 2:].values\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 0.05863727895765303, 0: 0.8704602962506767, 1: 0.07090242479167017}\n"
     ]
    }
   ],
   "source": [
    "n_p = data['annotation'].value_counts()[1]\n",
    "n_n = data['annotation'].value_counts()[-1]\n",
    "n_z = data['annotation'].value_counts()[0]\n",
    "\n",
    "weights = np.array([n_n, n_z, n_p])\n",
    "weights = weights / weights.sum()\n",
    "weights = 1 / weights\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "weights = {-1:weights[0], 0:weights[1], 1:weights[2]}\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Languages\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "clf_lr = LogisticRegression(max_iter=1000, class_weight=weights).fit(X_train, y_train)\n",
    "y_pred = clf_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance metrics\n",
    "Accuracy_LR = accuracy_score(y_test, y_pred)\n",
    "F1_LR = accuracy_score(y_test, y_pred)\n",
    "Precision_LR = accuracy_score(y_test, y_pred)\n",
    "Recall_LR = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \" + str(Accuracy_LR))\n",
    "print(\"F1 score: \" + str(F1_LR))\n",
    "print(\"Recall score: \" + str(Recall_LR))\n",
    "print(\"Precision score: \" + str(Precision_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not possible for multi-classification\n",
    "'''#ROC curve\n",
    "\n",
    "y_score_train = clf_lr.decision_function(X_train)\n",
    "y_score_test = clf_lr.decision_function(X_test)\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_score_train, pos_label=clf_lr.classes_[1])\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_score_test, pos_label=clf_lr.classes_[1])\n",
    "\n",
    "ax = plt.gca()\n",
    "train_disp = RocCurveDisplay(fpr=fpr_train, tpr=tpr_train)\n",
    "train_disp.plot(ax, name='Train')\n",
    "\n",
    "test_disp = RocCurveDisplay(fpr=fpr_test, tpr=tpr_test)\n",
    "test_disp.plot(ax, name='Test')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm_2c = confusion_matrix(y_test, y_pred)\n",
    "cm_display_2c = ConfusionMatrixDisplay(cm_2c).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel='linear', max_iter=2000,random_state=Shuffle_state, verbose=1, class_weight=weights).fit(X_train, y_train)\n",
    "y_pred = clf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance metrics\n",
    "Accuracy_LR = accuracy_score(y_test, y_pred)\n",
    "F1_LR = accuracy_score(y_test, y_pred)\n",
    "Precision_LR = accuracy_score(y_test, y_pred)\n",
    "Recall_LR = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \" + str(Accuracy_LR))\n",
    "print(\"F1 score: \" + str(F1_LR))\n",
    "print(\"Recall score: \" + str(Recall_LR))\n",
    "print(\"Precision score: \" + str(Precision_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm_2c = confusion_matrix(y_test, y_pred)\n",
    "cm_display_2c = ConfusionMatrixDisplay(cm_2c).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl_size = (128, 64)\n",
    "#hl_size = (256, 256, 256, 128, 64)\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=hl_size, activation='relu', solver='adam',\n",
    "                        alpha=0.0001, max_iter=1000, shuffle=True, random_state=Shuffle_state, verbose=True)\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "y_pred = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance metrics\n",
    "Accuracy_LR = accuracy_score(y_test, y_pred)\n",
    "F1_LR = accuracy_score(y_test, y_pred)\n",
    "Precision_LR = accuracy_score(y_test, y_pred)\n",
    "Recall_LR = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \" + str(Accuracy_LR))\n",
    "print(\"F1 score: \" + str(F1_LR))\n",
    "print(\"Recall score: \" + str(Recall_LR))\n",
    "print(\"Precision score: \" + str(Precision_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm_2c = confusion_matrix(y_test, y_pred)\n",
    "cm_display_2c = ConfusionMatrixDisplay(cm_2c).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf_etc = ExtraTreesClassifier(random_state=Shuffle_state).fit(X_train, y_train)\n",
    "y_pred = clf_etc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance metrics\n",
    "Accuracy_LR = accuracy_score(y_test, y_pred)\n",
    "F1_LR = accuracy_score(y_test, y_pred)\n",
    "Precision_LR = accuracy_score(y_test, y_pred)\n",
    "Recall_LR = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \" + str(Accuracy_LR))\n",
    "print(\"F1 score: \" + str(F1_LR))\n",
    "print(\"Recall score: \" + str(Recall_LR))\n",
    "print(\"Precision score: \" + str(Precision_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix\n",
    "cm_2c = confusion_matrix(y_test, y_pred)\n",
    "cm_display_2c = ConfusionMatrixDisplay(cm_2c).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_tensor(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        X = np.float32(X)\n",
    "        X = torch.from_numpy(X)\n",
    "        y = np.longlong(y) - y.min()\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        self.X = X.to(device)\n",
    "        self.y = y.to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_gpu = Data_tensor(X_train, y_train)\n",
    "testset_gpu = Data_tensor(X_test, y_test)\n",
    "\n",
    "batch_size = 1024\n",
    "train_dataloader = DataLoader(trainset_gpu, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(testset_gpu, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_gpu[:][1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=360, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size=512, output_size=10):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = DNN(X.shape[1], 3).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        print(pred.dtype)\n",
    "        print(y.dtype)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "torch.float32\n",
      "torch.int64\n",
      "loss: 16.393530  [ 1024/41592]\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.812493 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "torch.float32\n",
      "torch.int64\n",
      "loss: 0.570027  [ 1024/41592]\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.625896 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "torch.float32\n",
      "torch.int64\n",
      "loss: 0.551896  [ 1024/41592]\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.603920 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "torch.float32\n",
      "torch.int64\n",
      "loss: 0.492271  [ 1024/41592]\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.466731 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "torch.float32\n",
      "torch.int64\n",
      "loss: 0.635042  [ 1024/41592]\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.498873 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([552, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred(test_dataloader, model, loss_fn).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(test_dataloader.dataset[:][0]).detach().cpu().max(axis=1).indices.numpy()\n",
    "true = test_dataloader.dataset[:][1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8532169648009232\n",
      "F1 score: 0.8532169648009232\n",
      "Recall score: 0.8532169648009232\n",
      "Precision score: 0.8532169648009232\n"
     ]
    }
   ],
   "source": [
    "#Performance metrics\n",
    "Accuracy_LR = accuracy_score(true, pred)\n",
    "F1_LR = accuracy_score(true, pred)\n",
    "Precision_LR = accuracy_score(true, pred)\n",
    "Recall_LR = accuracy_score(true, pred)\n",
    "print(\"Accuracy: \" + str(Accuracy_LR))\n",
    "print(\"F1 score: \" + str(F1_LR))\n",
    "print(\"Recall score: \" + str(Recall_LR))\n",
    "print(\"Precision score: \" + str(Precision_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cm_2c = confusion_matrix(true, pred)\n",
    "cm_display_2c = ConfusionMatrixDisplay(cm_2c).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
