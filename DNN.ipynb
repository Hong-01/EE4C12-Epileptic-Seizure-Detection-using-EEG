{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EE4C12-Epileptic-Seizure-Detection-using-EEG**\n",
    "\n",
    "## *Classification of EEG signals using **Deep Neural Network***\n",
    "\n",
    "\n",
    "    \n",
    "Group 16 Members:\n",
    "\n",
    "    1. Zhixuan Ge  \n",
    "    2. Yanqi Hong "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, precision_recall_curve, PrecisionRecallDisplay, roc_auc_score, RocCurveDisplay, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>annotation</th>\n",
       "      <th>min|FP1-F7</th>\n",
       "      <th>min|F7-T3</th>\n",
       "      <th>min|T3-T5</th>\n",
       "      <th>min|T5-O1</th>\n",
       "      <th>min|FP2-F8</th>\n",
       "      <th>min|F8-T4</th>\n",
       "      <th>min|T4-T6</th>\n",
       "      <th>min|T6-O2</th>\n",
       "      <th>...</th>\n",
       "      <th>norm_power_HF|CZ-C4</th>\n",
       "      <th>norm_power_HF|C4-T4</th>\n",
       "      <th>norm_power_HF|FP1-F3</th>\n",
       "      <th>norm_power_HF|F3-C3</th>\n",
       "      <th>norm_power_HF|C3-P3</th>\n",
       "      <th>norm_power_HF|P3-O1</th>\n",
       "      <th>norm_power_HF|FP2-F4</th>\n",
       "      <th>norm_power_HF|F4-C4</th>\n",
       "      <th>norm_power_HF|C4-P4</th>\n",
       "      <th>norm_power_HF|P4-O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.066920</td>\n",
       "      <td>0.102402</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.690787</td>\n",
       "      <td>0.154544</td>\n",
       "      <td>0.062533</td>\n",
       "      <td>0.046460</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>0.086999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>0.225788</td>\n",
       "      <td>0.409987</td>\n",
       "      <td>0.184671</td>\n",
       "      <td>0.071133</td>\n",
       "      <td>0.022369</td>\n",
       "      <td>0.079494</td>\n",
       "      <td>0.047536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037326</td>\n",
       "      <td>0.100177</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.622584</td>\n",
       "      <td>0.394504</td>\n",
       "      <td>0.225516</td>\n",
       "      <td>0.050673</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.102142</td>\n",
       "      <td>0.068105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027546</td>\n",
       "      <td>0.107883</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.359140</td>\n",
       "      <td>0.276964</td>\n",
       "      <td>0.104977</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.079467</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>0.089385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036820</td>\n",
       "      <td>0.182520</td>\n",
       "      <td>0.031397</td>\n",
       "      <td>0.328354</td>\n",
       "      <td>0.156929</td>\n",
       "      <td>0.151952</td>\n",
       "      <td>0.047532</td>\n",
       "      <td>0.135071</td>\n",
       "      <td>0.098320</td>\n",
       "      <td>0.137701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55451</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244334</td>\n",
       "      <td>0.625396</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.058277</td>\n",
       "      <td>0.083594</td>\n",
       "      <td>0.114426</td>\n",
       "      <td>0.119654</td>\n",
       "      <td>0.295364</td>\n",
       "      <td>0.185930</td>\n",
       "      <td>0.199585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55452</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588236</td>\n",
       "      <td>0.743060</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>0.228458</td>\n",
       "      <td>0.170603</td>\n",
       "      <td>0.351418</td>\n",
       "      <td>0.638666</td>\n",
       "      <td>0.490806</td>\n",
       "      <td>0.307429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55453</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296041</td>\n",
       "      <td>0.770194</td>\n",
       "      <td>0.041190</td>\n",
       "      <td>0.090919</td>\n",
       "      <td>0.186074</td>\n",
       "      <td>0.216797</td>\n",
       "      <td>0.231053</td>\n",
       "      <td>0.770637</td>\n",
       "      <td>0.285257</td>\n",
       "      <td>0.413382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55454</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440360</td>\n",
       "      <td>0.720855</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.026340</td>\n",
       "      <td>0.077674</td>\n",
       "      <td>0.269610</td>\n",
       "      <td>0.186769</td>\n",
       "      <td>0.790173</td>\n",
       "      <td>0.473615</td>\n",
       "      <td>0.415771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55455</th>\n",
       "      <td>11580</td>\n",
       "      <td>-1</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019325</td>\n",
       "      <td>0.735140</td>\n",
       "      <td>0.030715</td>\n",
       "      <td>0.077191</td>\n",
       "      <td>0.095298</td>\n",
       "      <td>0.317765</td>\n",
       "      <td>0.271859</td>\n",
       "      <td>0.675646</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.561740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55456 rows Ã— 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient  annotation  min|FP1-F7  min|F7-T3  min|T3-T5  min|T5-O1  \\\n",
       "0          258           1          50         61         57         53   \n",
       "1          258           1          48         62         60         46   \n",
       "2          258           1          51         60         59         45   \n",
       "3          258           1          49         58         56         42   \n",
       "4          258           1          45         57         61         41   \n",
       "...        ...         ...         ...        ...        ...        ...   \n",
       "55451    11580          -1          75         73         81         80   \n",
       "55452    11580          -1          74         74         77         71   \n",
       "55453    11580          -1          72         76         72         73   \n",
       "55454    11580          -1          77         82         74         75   \n",
       "55455    11580          -1          71         79         74         78   \n",
       "\n",
       "       min|FP2-F8  min|F8-T4  min|T4-T6  min|T6-O2  ...  norm_power_HF|CZ-C4  \\\n",
       "0              39         35         39         35  ...             0.016087   \n",
       "1              38         35         39         33  ...             0.024006   \n",
       "2              38         36         40         36  ...             0.037326   \n",
       "3              36         36         41         37  ...             0.027546   \n",
       "4              35         37         41         37  ...             0.036820   \n",
       "...           ...        ...        ...        ...  ...                  ...   \n",
       "55451          66         80         77         75  ...             0.244334   \n",
       "55452          79         75         82         77  ...             0.588236   \n",
       "55453          74         76         80         76  ...             0.296041   \n",
       "55454          82         85         80         76  ...             0.440360   \n",
       "55455          80         85         81         75  ...             1.019325   \n",
       "\n",
       "       norm_power_HF|C4-T4  norm_power_HF|FP1-F3  norm_power_HF|F3-C3  \\\n",
       "0                 0.066920              0.102402             0.481384   \n",
       "1                 0.064857              0.031791             0.225788   \n",
       "2                 0.100177              0.050009             0.622584   \n",
       "3                 0.107883              0.014017             0.359140   \n",
       "4                 0.182520              0.031397             0.328354   \n",
       "...                    ...                   ...                  ...   \n",
       "55451             0.625396              0.023821             0.058277   \n",
       "55452             0.743060              0.076294             0.332341   \n",
       "55453             0.770194              0.041190             0.090919   \n",
       "55454             0.720855              0.026959             0.026340   \n",
       "55455             0.735140              0.030715             0.077191   \n",
       "\n",
       "       norm_power_HF|C3-P3  norm_power_HF|P3-O1  norm_power_HF|FP2-F4  \\\n",
       "0                 0.690787             0.154544              0.062533   \n",
       "1                 0.409987             0.184671              0.071133   \n",
       "2                 0.394504             0.225516              0.050673   \n",
       "3                 0.276964             0.104977              0.018042   \n",
       "4                 0.156929             0.151952              0.047532   \n",
       "...                    ...                  ...                   ...   \n",
       "55451             0.083594             0.114426              0.119654   \n",
       "55452             0.228458             0.170603              0.351418   \n",
       "55453             0.186074             0.216797              0.231053   \n",
       "55454             0.077674             0.269610              0.186769   \n",
       "55455             0.095298             0.317765              0.271859   \n",
       "\n",
       "       norm_power_HF|F4-C4  norm_power_HF|C4-P4  norm_power_HF|P4-O2  \n",
       "0                 0.046460             0.066575             0.086999  \n",
       "1                 0.022369             0.079494             0.047536  \n",
       "2                 0.044906             0.102142             0.068105  \n",
       "3                 0.079467             0.078255             0.089385  \n",
       "4                 0.135071             0.098320             0.137701  \n",
       "...                    ...                  ...                  ...  \n",
       "55451             0.295364             0.185930             0.199585  \n",
       "55452             0.638666             0.490806             0.307429  \n",
       "55453             0.770637             0.285257             0.413382  \n",
       "55454             0.790173             0.473615             0.415771  \n",
       "55455             0.675646             0.506836             0.561740  \n",
       "\n",
       "[55456 rows x 362 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data on Yanqi Hong's computer\n",
    "data = pd.read_csv('E:\\DATA\\TUD\\Master\\TUD_Master_Y1\\Q1\\EE4C12 Machine Learning For Electrical Engineering\\CodeLab\\Project\\S&S_SZD (1)\\Data\\Project_Data_EE4C12_S&S_SZD.csv')\n",
    "data\n",
    "\n",
    "# # load data on Zhixuan's computer\n",
    "# data = pd.read_csv('D:\\\\User\\Zhixuan Ge\\Onedrive TUDelft\\OneDrive - Delft University of Technology\\Courses\\ML for EE\\SZD\\S&S_SZD\\Project_Data_EE4C12_S&S_SZD.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# train test split\n",
    "\n",
    "X = data.iloc[:, 2:].values\n",
    "y = np.int32(data['annotation'].values)\n",
    "\n",
    "test_size = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "# test_size = 0.25\n",
    "# data_train, data_test = train_test_split(data, test_size=test_size, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "\n",
    "# Patient_count = data['Patient'].value_counts(sort=False)\n",
    "# Patient_ID = Patient_count.index.values\n",
    "# Patient_num = len(Patient_ID)\n",
    "# Patient_ID_inv = dict(zip(Patient_ID, range(Patient_num)))\n",
    "\n",
    "# itp_idx = []\n",
    "# itp_idx.append(0)\n",
    "# for i in range(1, len(data)):\n",
    "#     if data['Patient'][i] != data['Patient'][i-1]:\n",
    "#         itp_idx.append(i)\n",
    "# itp_idx.append(len(data))\n",
    "\n",
    "# data_list = []\n",
    "# for i in range(Patient_num):\n",
    "#     data_list.append([])    \n",
    "\n",
    "# for i in range(1, len(itp_idx)):\n",
    "#     data_temp = data.iloc[itp_idx[i-1]:itp_idx[i]]\n",
    "#     Patient_temp = data_temp['Patient'].iloc[0]\n",
    "#     data_list[Patient_ID_inv[Patient_temp]].append(data_temp)\n",
    "    \n",
    "# X_train_scaled = np.zeros([0, 360])\n",
    "# X_test_scaled = np.zeros([0, 360])\n",
    "# y_train = np.zeros(0, dtype=int)\n",
    "# y_test = np.zeros(0, dtype=int)\n",
    "\n",
    "# for i in range(15):\n",
    "#     for j in range(len(data_list[i])):\n",
    "#         idx_search = data_list[i][j].index\n",
    "        \n",
    "#         idx_search_train = data_train.index.intersection(idx_search)\n",
    "#         idx_search_test = data_test.index.intersection(idx_search)\n",
    "        \n",
    "#         data_search_train = data_train.loc[idx_search_train]\n",
    "#         data_search_test = data_test.loc[idx_search_test]\n",
    "    \n",
    "#         X_search_train = data_search_train.iloc[:, 2:].values\n",
    "#         X_search_test = data_search_test.iloc[:, 2:].values\n",
    "        \n",
    "#         scaler = StandardScaler().fit(X_search_train)\n",
    "#         X_search_train = scaler.transform(X_search_train)\n",
    "#         X_search_test = scaler.transform(X_search_test)\n",
    "        \n",
    "#         X_train_scaled = np.concatenate((X_train_scaled, X_search_train), axis=0)\n",
    "#         X_test_scaled = np.concatenate((X_test_scaled, X_search_test), axis=0)\n",
    "        \n",
    "#         y_train_search = np.int32(data_search_train['annotation'].values)\n",
    "#         y_test_search = np.int32(data_search_test['annotation'].values)\n",
    "        \n",
    "#         y_train = np.concatenate((y_train, y_train_search))\n",
    "#         y_test = np.concatenate((y_test, y_test_search))\n",
    "        \n",
    "# X_train_scaled, y_train = sklearn.utils.shuffle(X_train_scaled, y_train, random_state=random_state)\n",
    "# X_test_scaled, y_test = sklearn.utils.shuffle(X_test_scaled, y_test, random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original number of training feature is:  360\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current number of training feature after feature selection is:  120\n"
     ]
    }
   ],
   "source": [
    "# Feature selection by extra tree classifier\n",
    "\n",
    "print(\"The original number of training feature is: \", X_train_scaled.shape[1])\n",
    "clf_etc = ExtraTreesClassifier(random_state=random_state).fit(X_train_scaled, y_train) # fit the model\n",
    "feature_importances = clf_etc.feature_importances_  # get the feature importance\n",
    "\n",
    "plt.bar(range(len(feature_importances)), feature_importances)   # plot the feature importance\n",
    "plt.xlabel(\"Feature index\")\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.title(\"Feature importance of all features\")\n",
    "plt.show()\n",
    "\n",
    "important_feature_indices=np.argsort(feature_importances)   # sort the feature importance  \n",
    "important_feature_indices_cut=important_feature_indices[:int(len(important_feature_indices)/1.5)]   # select the most important features  \n",
    "\n",
    "X_train_selected=np.delete(X_train_scaled,important_feature_indices_cut,1)    # delete the least important features\n",
    "X_test_selected=np.delete(X_test_scaled,important_feature_indices_cut,1)      # delete the least important features\n",
    "print(\"The current number of training feature after feature selection is: \", X_train_selected.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection by PCA\n",
    "pca = PCA().fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a10e570210>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cumulative explained variance ratio for PCA and cumulative feature importance for Extra Trees\n",
    "\n",
    "plt.plot(np.sort(feature_importances)[::-1].cumsum(), label='Cumulative feature importance of Extra Trees')\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum(), label='Cumulative explained variance ratio of PCA')\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Cumulative importance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "# Attemptï¼šoversample and undersample\n",
    "\n",
    "# The oversample and undersample method can increase the discrimination of the samples with label 0\n",
    "# However, the oversample and undersample method is not used in the final model because it will decrease the accuracy of the model, so that the model cannot predict the label 1 and -1 correctly\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "# num_zero=np.sum(y_train==0)\n",
    "# num_one=np.sum(y_train==1)\n",
    "# num_negatives_one=np.sum(y_train==-1)\n",
    "# print('The original sample number of 0 is', num_zero)\n",
    "# print('The original sample number of 1 is', num_one)\n",
    "# print('The original sample number of -1 is', num_negatives_one)\n",
    "\n",
    "# # oversampling & undersampling\n",
    "# smt = SMOTETomek(random_state=Shuffle_state)\n",
    "# X_train_selected, y_train = smt.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "# num_zero=np.sum(y_train==0)\n",
    "# num_one=np.sum(y_train==1)\n",
    "# num_negatives_one=np.sum(y_train==-1)\n",
    "\n",
    "# print('')\n",
    "# print('The current sample number of 0 is', num_zero)\n",
    "# print('The current sample number of 1 is', num_one)\n",
    "# print('The current sample number of -1 is', num_negatives_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data tensor\n",
    "\n",
    "class Data_tensor(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        X = np.float32(X)\n",
    "        X = torch.from_numpy(X)\n",
    "        # In pytorch, labels must start from 0\n",
    "        # shift required\n",
    "        y = np.longlong(y) - y.min()\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        self.X = X.to(device)\n",
    "        self.y = y.to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN class for random search\n",
    "class DNN_rs(nn.Module):\n",
    "    # Available activation functions: ReLU, Sigmoid, Tanh, LeakyReLU, ELU, SELU, Softplus, Softsign, LogSigmoid, PReLU, Softmin, Softmax, if the input is not in the list, ReLU will be used\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, activition_layer=nn.ReLU()):\n",
    "        super(DNN_rs, self).__init__()\n",
    "        depth=len(hidden_sizes)\n",
    "        layers = []\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_size, hidden_sizes[i])) \n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            if activition_layer==\"ReLU\":\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activition_layer==\"Sigmoid\":\n",
    "                layers.append(nn.Sigmoid())\n",
    "            elif activition_layer==\"Tanh\":\n",
    "                layers.append(nn.Tanh())\n",
    "            elif activition_layer==\"LeakyReLU\":\n",
    "                layers.append(nn.LeakyReLU())\n",
    "            elif activition_layer==\"ELU\":\n",
    "                layers.append(nn.ELU())\n",
    "            elif activition_layer==\"SELU\":\n",
    "                layers.append(nn.SELU())\n",
    "            elif activition_layer==\"Softplus\":\n",
    "                layers.append(nn.Softplus())\n",
    "            elif activition_layer==\"Softsign\":\n",
    "                layers.append(nn.Softsign())\n",
    "            elif activition_layer==\"LogSigmoid\":\n",
    "                layers.append(nn.LogSigmoid())\n",
    "            elif activition_layer==\"PReLU\":\n",
    "                layers.append(nn.PReLU())\n",
    "            elif activition_layer==\"Softmin\":\n",
    "                layers.append(nn.Softmin())\n",
    "            elif activition_layer==\"Softmax\":\n",
    "                layers.append(nn.Softmax())\n",
    "            else:\n",
    "                layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear( hidden_sizes[-1], output_size))\n",
    "        self.linear_relu_stack = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN_rs(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=360, out_features=100, bias=True)\n",
      "    (1): PReLU(num_parameters=1)\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Test output for DNN_rs\n",
    "input_size = X_train_scaled.shape[1]\n",
    "output_size = 3\n",
    "model_rs = DNN_rs(input_size, hidden_sizes=[100], output_size=output_size, activition_layer=\"PReLU\")\n",
    "print(model_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test functions\n",
    "def train(dataloader, model, loss_fn, optimizer):  \n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>5f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # CrossEntropyLoss for multi-classification\n",
    "optimizer_rs = torch.optim.Adam(model_rs.parameters(),weight_decay=0.005)   # Adam optimizer for random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k fold cross validation function\n",
    "def Kfold_split(X_train, y_train, Shuffle_state, k=5):   # Split the data into training and validation sets\n",
    "    #example : X_k_train, y_k_train, X_k_val, y_k_val = Kfold_split(X_train, y_train, Shuffle_state)\n",
    "    kf = KFold(n_splits=k, random_state=Shuffle_state, shuffle=True)    # 5-fold cross validation\n",
    "    kf.get_n_splits(X_train)    \n",
    "    X_k_train = []\n",
    "    y_k_train = []\n",
    "    X_k_val = []\n",
    "    y_k_val = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(X_train):  # Split the data into training and validation sets\n",
    "        X_k_train.append(X_train[train_index])\n",
    "        y_k_train.append(y_train[train_index])\n",
    "        X_k_val.append(X_train[val_index])\n",
    "        y_k_val.append(y_train[val_index])\n",
    "    \n",
    "    return X_k_train, y_k_train, X_k_val, y_k_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the performance value and confusion matrix \n",
    "\n",
    "def performance_eval(true, pred, score_display=True, matrix_display=False, result_return=False):\n",
    "    Accuracy = accuracy_score(true, pred)\n",
    "    F1 = accuracy_score(true, pred)\n",
    "    Precision = accuracy_score(true, pred)\n",
    "    Recall = accuracy_score(true, pred)\n",
    "    \n",
    "    if score_display==True:\n",
    "        print(\"Accuracy: \" + str(Accuracy))\n",
    "        print(\"F1 score: \" + str(F1))\n",
    "        print(\"Recall score: \" + str(Recall))\n",
    "        print(\"Precision score: \" + str(Precision))\n",
    "        \n",
    "    if matrix_display==True:\n",
    "        label = ['Non-seizure', 'Transition','Seizure']\n",
    "        cm = confusion_matrix(true, pred)\n",
    "        cm_display = ConfusionMatrixDisplay(cm, display_labels=label).plot()\n",
    "        plt.show(cm_display)\n",
    "    \n",
    "    if result_return:\n",
    "        return Accuracy, F1, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation dataloader\n",
    "batch_size = 1024\n",
    "\n",
    "train_dataloader_list = []\n",
    "val_dataloader_list = []\n",
    "\n",
    "X_k_train_list, y_k_train_list, X_k_val_list, y_k_val_list = Kfold_split(X_train_selected, y_train, random_state)   # K-fold cross validation for DNN\n",
    "for i in range(5):\n",
    "    trainset_gpu = Data_tensor(X_k_train_list[i], y_k_train_list[i])\n",
    "    valset_gpu = Data_tensor(X_k_val_list[i], y_k_val_list[i])\n",
    "    train_dataloader_list.append(DataLoader(trainset_gpu, batch_size=batch_size, shuffle=True))\n",
    "    val_dataloader_list.append(DataLoader(valset_gpu, batch_size=batch_size, shuffle=True))\n",
    "    \n",
    "valset_gpu_k = Data_tensor(X_train_selected, y_train)\n",
    "val_dataloader_k = DataLoader(valset_gpu_k, batch_size=batch_size, shuffle=True)\n",
    "testset_gpu = Data_tensor(X_test_selected, y_test)\n",
    "test_dataloader = DataLoader(testset_gpu, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyper parameters for random search\n",
    "\n",
    "min_width=8  # The minimum number of neurons in each hidden layer\n",
    "max_width=720   # The maximum number of neurons in each hidden layer\n",
    "min_hl=1    # The minimum number of hidden layers\n",
    "max_hl=3   # The maximum number of hidden layers\n",
    "activition_list = [\"ReLU\", \"Tanh\", \"LeakyReLU\",\"Sigmoid\"]   # The activation function list\n",
    "\n",
    "optimizer_list = [\"SGD\", \"Adam\"]    \n",
    "min_learning_rate=0.0001\n",
    "max_learning_rate=0.5\n",
    "\n",
    "#alpha: weight decay (L2 penalty)\n",
    "max_alpha= 0         # denotes alpha=10^0\n",
    "min_alpha= -4        # denotes alpha=10^-4\n",
    "\n",
    "epochs = 20 # The maximum number of epochs for training\n",
    "\n",
    "\n",
    "def get_hps():\n",
    "    num_hl = random.randint(min_hl, max_hl)\n",
    "    hl = []\n",
    "    for i in range(num_hl):\n",
    "        hl.append(random.randint(min_width, max_width))\n",
    "    alpha = np.power(10, random.uniform(min_alpha, max_alpha)) # The L2 rate is in the range of 10^-4 to 10^0\n",
    "    activition = random.choice(activition_list)\n",
    "    optimizer = random.choice(optimizer_list)\n",
    "    lr = random.uniform(min_learning_rate, max_learning_rate)\n",
    "    \n",
    "    return {'hl': hl, 'alpha': alpha, 'activition': activition, 'optimizer': optimizer, 'lr': lr}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Search progess: 1/500\n",
      "--------------------\n",
      "{'hl': [122, 33, 289], 'alpha': 0.0009540418265608062, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.33838207376271334}\n",
      "loss: 1.066193  [ 1024/33273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.479894 \n",
      "\n",
      "loss: 0.477712  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.471836 \n",
      "\n",
      "loss: 0.457926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.432877 \n",
      "\n",
      "loss: 0.445573  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.464377 \n",
      "\n",
      "loss: 0.476965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.410018 \n",
      "\n",
      "loss: 0.457543  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.405471 \n",
      "\n",
      "loss: 0.384353  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.393756 \n",
      "\n",
      "loss: 0.387952  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.370119 \n",
      "\n",
      "loss: 0.386561  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.390291 \n",
      "\n",
      "loss: 0.388522  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.362697 \n",
      "\n",
      "loss: 0.346984  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.369824 \n",
      "\n",
      "loss: 0.377572  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.374363 \n",
      "\n",
      "loss: 0.366597  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.355559 \n",
      "\n",
      "loss: 0.357967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.358934 \n",
      "\n",
      "loss: 0.359168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.335985 \n",
      "\n",
      "loss: 0.346784  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.344610 \n",
      "\n",
      "loss: 0.380829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.356876 \n",
      "\n",
      "loss: 0.328679  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.340121 \n",
      "\n",
      "loss: 0.333757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.339530 \n",
      "\n",
      "loss: 0.310163  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.334682 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 2/500\n",
      "--------------------\n",
      "{'hl': [97, 612, 440], 'alpha': 0.00013400799762636407, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.11640718060603072}\n",
      "loss: 1.119435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.550134 \n",
      "\n",
      "loss: 0.489122  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.474458 \n",
      "\n",
      "loss: 0.476669  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.460145 \n",
      "\n",
      "loss: 0.476173  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.418278 \n",
      "\n",
      "loss: 0.442221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.397903 \n",
      "\n",
      "loss: 0.423835  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.388352 \n",
      "\n",
      "loss: 0.413332  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.399667 \n",
      "\n",
      "loss: 0.355138  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.370355 \n",
      "\n",
      "loss: 0.378042  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.373061 \n",
      "\n",
      "loss: 0.362812  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346254 \n",
      "\n",
      "loss: 0.376912  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.342618 \n",
      "\n",
      "loss: 0.310313  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.357925 \n",
      "\n",
      "loss: 0.365024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.345503 \n",
      "\n",
      "loss: 0.304122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.370812 \n",
      "\n",
      "loss: 0.376728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.330214 \n",
      "\n",
      "loss: 0.339169  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.347181 \n",
      "\n",
      "loss: 0.340798  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.341513 \n",
      "\n",
      "loss: 0.301546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.328063 \n",
      "\n",
      "loss: 0.289242  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.331392 \n",
      "\n",
      "loss: 0.302766  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.308625 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 3/500\n",
      "--------------------\n",
      "{'hl': [35, 582, 211], 'alpha': 0.07312711696136041, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.22465960223729842}\n",
      "loss: 1.144768  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.982508 \n",
      "\n",
      "loss: 1.027210  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.879609 \n",
      "\n",
      "loss: 0.863273  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.861161 \n",
      "\n",
      "loss: 0.892832  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.825986 \n",
      "\n",
      "loss: 0.864550  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.007261 \n",
      "\n",
      "loss: 1.034037  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.937897 \n",
      "\n",
      "loss: 0.933758  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.828780 \n",
      "\n",
      "loss: 0.833308  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.136719 \n",
      "\n",
      "loss: 1.133590  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.918522 \n",
      "\n",
      "loss: 0.907749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.968740 \n",
      "\n",
      "loss: 0.981664  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.820770 \n",
      "\n",
      "loss: 0.804866  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.956781 \n",
      "\n",
      "loss: 0.949840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.887902 \n",
      "\n",
      "loss: 0.870474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.937877 \n",
      "\n",
      "loss: 0.906861  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.878149 \n",
      "\n",
      "loss: 0.857998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.040192 \n",
      "\n",
      "loss: 1.003088  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.884788 \n",
      "\n",
      "loss: 0.879880  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.861870 \n",
      "\n",
      "loss: 0.896703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.846175 \n",
      "\n",
      "loss: 0.840736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.850492 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 4/500\n",
      "--------------------\n",
      "{'hl': [14, 171], 'alpha': 0.06202368709072582, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.0778242019559096}\n",
      "loss: 1.106684  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.483387 \n",
      "\n",
      "loss: 0.472868  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.485709 \n",
      "\n",
      "loss: 0.475595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.466289 \n",
      "\n",
      "loss: 0.472888  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.483877 \n",
      "\n",
      "loss: 0.479089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.481467 \n",
      "\n",
      "loss: 0.481709  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.488046 \n",
      "\n",
      "loss: 0.457472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.476557 \n",
      "\n",
      "loss: 0.470066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.479698 \n",
      "\n",
      "loss: 0.472879  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.488843 \n",
      "\n",
      "loss: 0.519502  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.476868 \n",
      "\n",
      "loss: 0.518511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.520732 \n",
      "\n",
      "loss: 0.533280  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.496444 \n",
      "\n",
      "loss: 0.514710  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.488735 \n",
      "\n",
      "loss: 0.488507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.494810 \n",
      "\n",
      "loss: 0.501330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.491757 \n",
      "\n",
      "loss: 0.442544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.489950 \n",
      "\n",
      "loss: 0.504435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.489355 \n",
      "\n",
      "loss: 0.454014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.477265 \n",
      "\n",
      "loss: 0.508059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.497173 \n",
      "\n",
      "loss: 0.492538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.492595 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 5/500\n",
      "--------------------\n",
      "{'hl': [112, 102], 'alpha': 0.003309094749748571, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.30190264308030884}\n",
      "loss: 1.043634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 17.906708 \n",
      "\n",
      "loss: 14.101375  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 2.247576 \n",
      "\n",
      "loss: 2.247618  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.664009 \n",
      "\n",
      "loss: 0.732803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.518087 \n",
      "\n",
      "loss: 0.489658  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.417190 \n",
      "\n",
      "loss: 0.397813  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.409886 \n",
      "\n",
      "loss: 0.440038  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.396034 \n",
      "\n",
      "loss: 0.398248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.396633 \n",
      "\n",
      "loss: 0.376657  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.359624 \n",
      "\n",
      "loss: 0.334794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.346113 \n",
      "\n",
      "loss: 0.351825  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.354856 \n",
      "\n",
      "loss: 0.368593  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.384014 \n",
      "\n",
      "loss: 0.375881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.360917 \n",
      "\n",
      "loss: 0.281258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.468166 \n",
      "\n",
      "loss: 0.425020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.359884 \n",
      "\n",
      "loss: 0.377987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.391740 \n",
      "\n",
      "loss: 0.408297  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.427941 \n",
      "\n",
      "loss: 0.401822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.392993 \n",
      "\n",
      "loss: 0.346857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.369587 \n",
      "\n",
      "loss: 0.361081  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.349071 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 6/500\n",
      "--------------------\n",
      "{'hl': [478], 'alpha': 0.01396086623070043, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.2760651115734862}\n",
      "loss: 0.976212  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.052113 \n",
      "\n",
      "loss: 0.994504  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.067773 \n",
      "\n",
      "loss: 1.092443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 1.019379 \n",
      "\n",
      "loss: 0.873130  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 2.246412 \n",
      "\n",
      "loss: 2.384463  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 4.164069 \n",
      "\n",
      "loss: 4.519269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.144698 \n",
      "\n",
      "loss: 1.323228  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 1.013552 \n",
      "\n",
      "loss: 1.058652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 1.076336 \n",
      "\n",
      "loss: 1.054806  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.626873 \n",
      "\n",
      "loss: 1.561648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.975213 \n",
      "\n",
      "loss: 1.019066  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.779645 \n",
      "\n",
      "loss: 0.713820  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.942204 \n",
      "\n",
      "loss: 1.026347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 2.545945 \n",
      "\n",
      "loss: 2.920709  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 1.290197 \n",
      "\n",
      "loss: 1.424508  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 3.692382 \n",
      "\n",
      "loss: 3.968829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.165331 \n",
      "\n",
      "loss: 1.038035  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 1.165519 \n",
      "\n",
      "loss: 0.990162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.885998 \n",
      "\n",
      "loss: 0.859321  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 1.948120 \n",
      "\n",
      "loss: 2.172592  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.903787 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 7/500\n",
      "--------------------\n",
      "{'hl': [641, 378, 599], 'alpha': 0.0005876982006303733, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3306655329519983}\n",
      "loss: 1.098840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.517840 \n",
      "\n",
      "loss: 0.505780  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.424730 \n",
      "\n",
      "loss: 0.413250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.416805 \n",
      "\n",
      "loss: 0.420366  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.384690 \n",
      "\n",
      "loss: 0.350361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.352881 \n",
      "\n",
      "loss: 0.371614  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.343161 \n",
      "\n",
      "loss: 0.328959  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.353537 \n",
      "\n",
      "loss: 0.355686  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.339787 \n",
      "\n",
      "loss: 0.337171  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.321715 \n",
      "\n",
      "loss: 0.348691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.308570 \n",
      "\n",
      "loss: 0.332898  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.308853 \n",
      "\n",
      "loss: 0.331265  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.305774 \n",
      "\n",
      "loss: 0.361027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.306550 \n",
      "\n",
      "loss: 0.292687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.318262 \n",
      "\n",
      "loss: 0.288260  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.295088 \n",
      "\n",
      "loss: 0.293987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.294414 \n",
      "\n",
      "loss: 0.289284  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.272712 \n",
      "\n",
      "loss: 0.316362  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.275516 \n",
      "\n",
      "loss: 0.266286  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.283179 \n",
      "\n",
      "loss: 0.286919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.322978 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 8/500\n",
      "--------------------\n",
      "{'hl': [89, 246], 'alpha': 0.29237125168168926, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2267598101539809}\n",
      "loss: 1.088199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 1.484879 \n",
      "\n",
      "loss: 1.526482  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.311274 \n",
      "\n",
      "loss: 1.345065  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.410012 \n",
      "\n",
      "loss: 2.625253  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.849372 \n",
      "\n",
      "loss: 0.877659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.820438 \n",
      "\n",
      "loss: 0.807795  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.947402 \n",
      "\n",
      "loss: 0.948436  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.462148 \n",
      "\n",
      "loss: 1.469809  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.322868 \n",
      "\n",
      "loss: 1.282349  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.069707 \n",
      "\n",
      "loss: 1.072131  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.177090 \n",
      "\n",
      "loss: 2.088030  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.154813 \n",
      "\n",
      "loss: 1.139772  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.370169 \n",
      "\n",
      "loss: 1.342095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.346328 \n",
      "\n",
      "loss: 2.138356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.880067 \n",
      "\n",
      "loss: 0.872325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.548503 \n",
      "\n",
      "loss: 1.542536  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.350627 \n",
      "\n",
      "loss: 1.311075  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 3.857909 \n",
      "\n",
      "loss: 3.856478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 3.422378 \n",
      "\n",
      "loss: 3.436934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.508128 \n",
      "\n",
      "loss: 1.505942  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.953027 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 9/500\n",
      "--------------------\n",
      "{'hl': [174, 387], 'alpha': 0.0026368340665125158, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.30460458973292737}\n",
      "loss: 1.066180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.469822 \n",
      "\n",
      "loss: 0.459644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.427525 \n",
      "\n",
      "loss: 0.413242  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.402509 \n",
      "\n",
      "loss: 0.409575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.399131 \n",
      "\n",
      "loss: 0.378981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.366558 \n",
      "\n",
      "loss: 0.386325  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.362604 \n",
      "\n",
      "loss: 0.352066  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.351623 \n",
      "\n",
      "loss: 0.342804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.355147 \n",
      "\n",
      "loss: 0.320221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.352144 \n",
      "\n",
      "loss: 0.373770  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.330601 \n",
      "\n",
      "loss: 0.371881  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.389421 \n",
      "\n",
      "loss: 0.366767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.342201 \n",
      "\n",
      "loss: 0.314362  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.337522 \n",
      "\n",
      "loss: 0.334076  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.316494 \n",
      "\n",
      "loss: 0.309986  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.310896 \n",
      "\n",
      "loss: 0.316622  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.341967 \n",
      "\n",
      "loss: 0.329509  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.325307 \n",
      "\n",
      "loss: 0.305034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.308170 \n",
      "\n",
      "loss: 0.321081  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.355651 \n",
      "\n",
      "loss: 0.362433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.295055 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 10/500\n",
      "--------------------\n",
      "{'hl': [554], 'alpha': 0.08251011488217917, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.1897897753346481}\n",
      "loss: 1.086370  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 4.945884 \n",
      "\n",
      "loss: 4.957807  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 18.8%, Avg loss: 7.900478 \n",
      "\n",
      "loss: 8.419363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 3.823307 \n",
      "\n",
      "loss: 3.811238  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 2.932754 \n",
      "\n",
      "loss: 3.049238  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 5.558166 \n",
      "\n",
      "loss: 5.680934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 2.450121 \n",
      "\n",
      "loss: 2.596181  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 4.709411 \n",
      "\n",
      "loss: 4.640758  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 3.704380 \n",
      "\n",
      "loss: 3.942376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 3.400114 \n",
      "\n",
      "loss: 3.006447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 2.797511 \n",
      "\n",
      "loss: 2.825846  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 3.039755 \n",
      "\n",
      "loss: 3.252187  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 2.295899 \n",
      "\n",
      "loss: 2.495791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 3.733959 \n",
      "\n",
      "loss: 4.063317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 5.451300 \n",
      "\n",
      "loss: 5.788473  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 3.975809 \n",
      "\n",
      "loss: 3.949483  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 6.658193 \n",
      "\n",
      "loss: 6.406896  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 2.805117 \n",
      "\n",
      "loss: 2.686849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 3.960611 \n",
      "\n",
      "loss: 3.726034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 2.026426 \n",
      "\n",
      "loss: 1.941666  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 2.292567 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 11/500\n",
      "--------------------\n",
      "{'hl': [712, 578, 232], 'alpha': 0.0547591885563413, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.4109191167440035}\n",
      "loss: 1.126762  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.486355 \n",
      "\n",
      "loss: 0.479869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.469053 \n",
      "\n",
      "loss: 0.439479  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.457526 \n",
      "\n",
      "loss: 0.468576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.441610 \n",
      "\n",
      "loss: 0.461535  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.445047 \n",
      "\n",
      "loss: 0.429592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.443261 \n",
      "\n",
      "loss: 0.473634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.456132 \n",
      "\n",
      "loss: 0.435570  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.439560 \n",
      "\n",
      "loss: 0.439313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.437750 \n",
      "\n",
      "loss: 0.419616  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.433767 \n",
      "\n",
      "loss: 0.439446  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.440024 \n",
      "\n",
      "loss: 0.454882  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.439878 \n",
      "\n",
      "loss: 0.444166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.447693 \n",
      "\n",
      "loss: 0.428774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.445902 \n",
      "\n",
      "loss: 0.435373  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.438360 \n",
      "\n",
      "loss: 0.456248  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.437056 \n",
      "\n",
      "loss: 0.429998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.447969 \n",
      "\n",
      "loss: 0.435425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.436221 \n",
      "\n",
      "loss: 0.435214  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.438647 \n",
      "\n",
      "loss: 0.441692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.433938 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 12/500\n",
      "--------------------\n",
      "{'hl': [418, 282], 'alpha': 0.00018397314000745925, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.32775378878091055}\n",
      "loss: 1.134026  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.489455 \n",
      "\n",
      "loss: 0.533219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.436022 \n",
      "\n",
      "loss: 0.443447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.391174 \n",
      "\n",
      "loss: 0.356999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.369409 \n",
      "\n",
      "loss: 0.339518  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.351422 \n",
      "\n",
      "loss: 0.366560  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.354537 \n",
      "\n",
      "loss: 0.384633  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.350435 \n",
      "\n",
      "loss: 0.325730  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.331832 \n",
      "\n",
      "loss: 0.331579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.328376 \n",
      "\n",
      "loss: 0.310857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.325671 \n",
      "\n",
      "loss: 0.305197  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.321343 \n",
      "\n",
      "loss: 0.294905  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.326045 \n",
      "\n",
      "loss: 0.332964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.319713 \n",
      "\n",
      "loss: 0.304837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.328620 \n",
      "\n",
      "loss: 0.311900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.298582 \n",
      "\n",
      "loss: 0.301421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.290412 \n",
      "\n",
      "loss: 0.277558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.311125 \n",
      "\n",
      "loss: 0.289143  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.287760 \n",
      "\n",
      "loss: 0.277844  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.299157 \n",
      "\n",
      "loss: 0.276786  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.287427 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 13/500\n",
      "--------------------\n",
      "{'hl': [666, 477], 'alpha': 0.00037280897736830773, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3725199921475941}\n",
      "loss: 1.125195  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.472914 \n",
      "\n",
      "loss: 0.453947  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.478697 \n",
      "\n",
      "loss: 0.484318  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.469740 \n",
      "\n",
      "loss: 0.441474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.408881 \n",
      "\n",
      "loss: 0.405713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.408065 \n",
      "\n",
      "loss: 0.453124  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.458292 \n",
      "\n",
      "loss: 0.473687  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.440193 \n",
      "\n",
      "loss: 0.433599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.397896 \n",
      "\n",
      "loss: 0.374860  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.396740 \n",
      "\n",
      "loss: 0.427414  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.378482 \n",
      "\n",
      "loss: 0.380044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.380234 \n",
      "\n",
      "loss: 0.394638  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.412693 \n",
      "\n",
      "loss: 0.406412  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.358502 \n",
      "\n",
      "loss: 0.340209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.371001 \n",
      "\n",
      "loss: 0.361629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.352746 \n",
      "\n",
      "loss: 0.341511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.357067 \n",
      "\n",
      "loss: 0.360350  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.394820 \n",
      "\n",
      "loss: 0.401765  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.375483 \n",
      "\n",
      "loss: 0.376585  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.357880 \n",
      "\n",
      "loss: 0.354952  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.380192 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 14/500\n",
      "--------------------\n",
      "{'hl': [277, 606, 446], 'alpha': 0.3902038358974784, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.10973844750272595}\n",
      "loss: 1.058280  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.777584 \n",
      "\n",
      "loss: 3.538358  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.113754 \n",
      "\n",
      "loss: 1.116431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.824263 \n",
      "\n",
      "loss: 0.809701  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.826321 \n",
      "\n",
      "loss: 0.805382  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.940449 \n",
      "\n",
      "loss: 0.938454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.829625 \n",
      "\n",
      "loss: 0.849183  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.906843 \n",
      "\n",
      "loss: 0.883352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.875747 \n",
      "\n",
      "loss: 4.123581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 7.333872 \n",
      "\n",
      "loss: 7.505090  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.908269 \n",
      "\n",
      "loss: 3.254635  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.069077 \n",
      "\n",
      "loss: 4.847011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 5.061051 \n",
      "\n",
      "loss: 5.075447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 10.969069 \n",
      "\n",
      "loss: 11.357408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 11.083946 \n",
      "\n",
      "loss: 11.239484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 5.971613 \n",
      "\n",
      "loss: 5.822174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.189192 \n",
      "\n",
      "loss: 1.239810  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.196366 \n",
      "\n",
      "loss: 1.200157  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.128141 \n",
      "\n",
      "loss: 2.056381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.960218 \n",
      "\n",
      "loss: 0.991399  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.942108 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 15/500\n",
      "--------------------\n",
      "{'hl': [529], 'alpha': 0.00942026976168187, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.0765053755421957}\n",
      "loss: 1.102715  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.504659 \n",
      "\n",
      "loss: 0.552878  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.479277 \n",
      "\n",
      "loss: 0.489300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.465529 \n",
      "\n",
      "loss: 0.457824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.436498 \n",
      "\n",
      "loss: 0.450164  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.431091 \n",
      "\n",
      "loss: 0.407124  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.424632 \n",
      "\n",
      "loss: 0.426978  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.431529 \n",
      "\n",
      "loss: 0.407444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.410112 \n",
      "\n",
      "loss: 0.464191  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.404151 \n",
      "\n",
      "loss: 0.385832  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.391070 \n",
      "\n",
      "loss: 0.408033  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.395131 \n",
      "\n",
      "loss: 0.389774  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.396084 \n",
      "\n",
      "loss: 0.381235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.391076 \n",
      "\n",
      "loss: 0.433847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.393342 \n",
      "\n",
      "loss: 0.394867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.380811 \n",
      "\n",
      "loss: 0.413239  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.380629 \n",
      "\n",
      "loss: 0.375461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.386096 \n",
      "\n",
      "loss: 0.381735  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.378212 \n",
      "\n",
      "loss: 0.427024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.384236 \n",
      "\n",
      "loss: 0.392687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.362320 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 16/500\n",
      "--------------------\n",
      "{'hl': [704], 'alpha': 0.00488247318970224, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.19087148132461773}\n",
      "loss: 1.040757  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 16.603779 \n",
      "\n",
      "loss: 12.746139  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 5.872103 \n",
      "\n",
      "loss: 7.324611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 2.708979 \n",
      "\n",
      "loss: 3.076171  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 1.181076 \n",
      "\n",
      "loss: 1.322563  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 1.066051 \n",
      "\n",
      "loss: 0.998767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 1.448590 \n",
      "\n",
      "loss: 1.378787  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.921324 \n",
      "\n",
      "loss: 0.762032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 20.727259 \n",
      "\n",
      "loss: 17.546028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 32.781774 \n",
      "\n",
      "loss: 31.576048  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 35.668231 \n",
      "\n",
      "loss: 39.941498  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 99.825900 \n",
      "\n",
      "loss: 98.073807  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 15.516227 \n",
      "\n",
      "loss: 13.401999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 2.452450 \n",
      "\n",
      "loss: 2.022439  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.905172 \n",
      "\n",
      "loss: 1.263231  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.510754 \n",
      "\n",
      "loss: 0.470540  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.641343 \n",
      "\n",
      "loss: 0.519592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.521703 \n",
      "\n",
      "loss: 0.484907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.442047 \n",
      "\n",
      "loss: 0.379978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.547374 \n",
      "\n",
      "loss: 0.556879  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.468619 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 17/500\n",
      "--------------------\n",
      "{'hl': [549, 265], 'alpha': 0.7661494787650481, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3408870134763847}\n",
      "loss: 1.028400  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.989602 \n",
      "\n",
      "loss: 0.985630  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.990553 \n",
      "\n",
      "loss: 0.987609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.990108 \n",
      "\n",
      "loss: 0.990920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.989912 \n",
      "\n",
      "loss: 0.988577  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.991541 \n",
      "\n",
      "loss: 0.991399  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991992 \n",
      "\n",
      "loss: 0.993084  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.991388 \n",
      "\n",
      "loss: 0.986627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.990580 \n",
      "\n",
      "loss: 0.987656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.987974 \n",
      "\n",
      "loss: 0.992140  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.987749 \n",
      "\n",
      "loss: 0.991256  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.990047 \n",
      "\n",
      "loss: 0.989043  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.992114 \n",
      "\n",
      "loss: 0.993905  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.987791 \n",
      "\n",
      "loss: 0.988256  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.987674 \n",
      "\n",
      "loss: 0.989513  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.990361 \n",
      "\n",
      "loss: 0.991055  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.988425 \n",
      "\n",
      "loss: 0.992384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.990444 \n",
      "\n",
      "loss: 0.985940  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.987700 \n",
      "\n",
      "loss: 0.988686  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.988661 \n",
      "\n",
      "loss: 0.989050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.990730 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 18/500\n",
      "--------------------\n",
      "{'hl': [281, 664, 356], 'alpha': 0.00027938860831667404, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.22691648079397028}\n",
      "loss: 1.266430  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.832381 \n",
      "\n",
      "loss: 0.826806  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.826105 \n",
      "\n",
      "loss: 0.822944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.819651 \n",
      "\n",
      "loss: 0.812494  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.820632 \n",
      "\n",
      "loss: 0.800449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.806347 \n",
      "\n",
      "loss: 0.807987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819487 \n",
      "\n",
      "loss: 0.821665  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.827253 \n",
      "\n",
      "loss: 0.807161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809932 \n",
      "\n",
      "loss: 0.798804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 0.805568 \n",
      "\n",
      "loss: 0.817712  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 0.800102 \n",
      "\n",
      "loss: 0.794943  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.772820 \n",
      "\n",
      "loss: 0.781805  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.767103 \n",
      "\n",
      "loss: 0.732771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.713510 \n",
      "\n",
      "loss: 0.713945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.595373 \n",
      "\n",
      "loss: 0.582065  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.546858 \n",
      "\n",
      "loss: 0.570867  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.531977 \n",
      "\n",
      "loss: 0.548763  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.555813 \n",
      "\n",
      "loss: 0.561722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.570649 \n",
      "\n",
      "loss: 0.556143  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.517555 \n",
      "\n",
      "loss: 0.543848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.604906 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 19/500\n",
      "--------------------\n",
      "{'hl': [277, 520, 190], 'alpha': 0.010733137632580618, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4208505071514163}\n",
      "loss: 1.097200  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 17.500460 \n",
      "\n",
      "loss: 20.933584  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 28.101801 \n",
      "\n",
      "loss: 20.193539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 8.683921 \n",
      "\n",
      "loss: 8.346295  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 3.294432 \n",
      "\n",
      "loss: 3.093809  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.283834 \n",
      "\n",
      "loss: 4.219277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 407.688329 \n",
      "\n",
      "loss: 340.958527  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.851445 \n",
      "\n",
      "loss: 0.836870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.823672 \n",
      "\n",
      "loss: 0.798247  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.862752 \n",
      "\n",
      "loss: 0.843725  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.815954 \n",
      "\n",
      "loss: 0.825751  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817355 \n",
      "\n",
      "loss: 0.820817  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824299 \n",
      "\n",
      "loss: 0.823489  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.825003 \n",
      "\n",
      "loss: 0.834513  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.816430 \n",
      "\n",
      "loss: 0.820165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.815126 \n",
      "\n",
      "loss: 0.823526  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817601 \n",
      "\n",
      "loss: 0.820171  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.825865 \n",
      "\n",
      "loss: 0.840727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.816123 \n",
      "\n",
      "loss: 0.811000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.819997 \n",
      "\n",
      "loss: 0.805477  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.819062 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 20/500\n",
      "--------------------\n",
      "{'hl': [631, 211, 164], 'alpha': 0.0031308006143219093, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.2995123977716685}\n",
      "loss: 1.077578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.477522 \n",
      "\n",
      "loss: 0.481348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.464900 \n",
      "\n",
      "loss: 0.496089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.449683 \n",
      "\n",
      "loss: 0.477206  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.434309 \n",
      "\n",
      "loss: 0.458301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.423348 \n",
      "\n",
      "loss: 0.411605  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.426126 \n",
      "\n",
      "loss: 0.471223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.425166 \n",
      "\n",
      "loss: 0.389465  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.444119 \n",
      "\n",
      "loss: 0.444501  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.409165 \n",
      "\n",
      "loss: 0.379834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.388590 \n",
      "\n",
      "loss: 0.390521  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.412589 \n",
      "\n",
      "loss: 0.453152  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.394181 \n",
      "\n",
      "loss: 0.379584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.398338 \n",
      "\n",
      "loss: 0.371302  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.406942 \n",
      "\n",
      "loss: 0.418491  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.386215 \n",
      "\n",
      "loss: 0.435432  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.371366 \n",
      "\n",
      "loss: 0.382982  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.415778 \n",
      "\n",
      "loss: 0.389048  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.381460 \n",
      "\n",
      "loss: 0.355017  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.395405 \n",
      "\n",
      "loss: 0.362080  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.353307 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 21/500\n",
      "--------------------\n",
      "{'hl': [27, 122], 'alpha': 0.5204685179267371, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.029056790730444357}\n",
      "loss: 1.090269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.943554 \n",
      "\n",
      "loss: 0.942058  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.943832 \n",
      "\n",
      "loss: 0.942086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.950539 \n",
      "\n",
      "loss: 0.949695  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.958531 \n",
      "\n",
      "loss: 0.964678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.959778 \n",
      "\n",
      "loss: 0.956979  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.963006 \n",
      "\n",
      "loss: 0.964182  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.966815 \n",
      "\n",
      "loss: 0.963871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.961799 \n",
      "\n",
      "loss: 0.970166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.962850 \n",
      "\n",
      "loss: 0.971845  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.960618 \n",
      "\n",
      "loss: 0.962149  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.962789 \n",
      "\n",
      "loss: 0.959476  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.965472 \n",
      "\n",
      "loss: 0.960808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.964450 \n",
      "\n",
      "loss: 0.966891  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.961872 \n",
      "\n",
      "loss: 0.961546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962016 \n",
      "\n",
      "loss: 0.963168  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.963487 \n",
      "\n",
      "loss: 0.966532  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.964789 \n",
      "\n",
      "loss: 0.964045  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.963115 \n",
      "\n",
      "loss: 0.967365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.963791 \n",
      "\n",
      "loss: 0.965311  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.961222 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 22/500\n",
      "--------------------\n",
      "{'hl': [88, 95, 505], 'alpha': 0.18369317204038144, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.32990943629140895}\n",
      "loss: 1.106544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.607278 \n",
      "\n",
      "loss: 0.596790  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.602627 \n",
      "\n",
      "loss: 0.591220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.593764 \n",
      "\n",
      "loss: 0.592061  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.578480 \n",
      "\n",
      "loss: 0.596918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.596652 \n",
      "\n",
      "loss: 0.580993  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.589203 \n",
      "\n",
      "loss: 0.601985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.592430 \n",
      "\n",
      "loss: 0.579356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.607032 \n",
      "\n",
      "loss: 0.585800  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.579159 \n",
      "\n",
      "loss: 0.564607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.601268 \n",
      "\n",
      "loss: 0.604662  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.586053 \n",
      "\n",
      "loss: 0.589708  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.583013 \n",
      "\n",
      "loss: 0.593744  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.594209 \n",
      "\n",
      "loss: 0.568778  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.594560 \n",
      "\n",
      "loss: 0.598717  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.588213 \n",
      "\n",
      "loss: 0.596219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.596543 \n",
      "\n",
      "loss: 0.625843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.596166 \n",
      "\n",
      "loss: 0.618605  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.592102 \n",
      "\n",
      "loss: 0.587979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.594205 \n",
      "\n",
      "loss: 0.615904  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.595655 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 23/500\n",
      "--------------------\n",
      "{'hl': [177, 279, 548], 'alpha': 0.30883901903888494, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.46446385515178823}\n",
      "loss: 1.159142  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.398264 \n",
      "\n",
      "loss: 3.380012  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.869690 \n",
      "\n",
      "loss: 1.849904  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.141104 \n",
      "\n",
      "loss: 3.269921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.598710 \n",
      "\n",
      "loss: 2.531435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.362116 \n",
      "\n",
      "loss: 3.272770  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.030193 \n",
      "\n",
      "loss: 2.024240  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.703732 \n",
      "\n",
      "loss: 3.645916  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.600178 \n",
      "\n",
      "loss: 2.642066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.592297 \n",
      "\n",
      "loss: 3.614216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.058596 \n",
      "\n",
      "loss: 2.059902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.024642 \n",
      "\n",
      "loss: 3.014521  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 3.506958 \n",
      "\n",
      "loss: 3.460383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.340353 \n",
      "\n",
      "loss: 3.375126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.630923 \n",
      "\n",
      "loss: 2.668811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.248486 \n",
      "\n",
      "loss: 3.295278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.305061 \n",
      "\n",
      "loss: 2.322197  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.767484 \n",
      "\n",
      "loss: 3.755183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.839877 \n",
      "\n",
      "loss: 1.818104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.230118 \n",
      "\n",
      "loss: 3.322599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.226306 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 24/500\n",
      "--------------------\n",
      "{'hl': [714, 213, 327], 'alpha': 0.0039442932829558495, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.4498170809130084}\n",
      "loss: 1.115332  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 37605.194444 \n",
      "\n",
      "loss: 38214.785156  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 5795.393989 \n",
      "\n",
      "loss: 5162.023438  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 1915.061103 \n",
      "\n",
      "loss: 1574.987671  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 876.191861 \n",
      "\n",
      "loss: 1077.902588  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 773.215325 \n",
      "\n",
      "loss: 685.522278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 216.977765 \n",
      "\n",
      "loss: 182.180176  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 704.339789 \n",
      "\n",
      "loss: 720.256165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 297.550642 \n",
      "\n",
      "loss: 296.941284  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 70.059317 \n",
      "\n",
      "loss: 59.616314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 98.855235 \n",
      "\n",
      "loss: 108.415642  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 67.817363 \n",
      "\n",
      "loss: 74.840057  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 38.462831 \n",
      "\n",
      "loss: 41.234886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 94.221670 \n",
      "\n",
      "loss: 76.242081  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 40.350092 \n",
      "\n",
      "loss: 42.490677  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 36.772233 \n",
      "\n",
      "loss: 47.578732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 22.321684 \n",
      "\n",
      "loss: 16.086304  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 61.135932 \n",
      "\n",
      "loss: 47.347473  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 38.145969 \n",
      "\n",
      "loss: 40.806461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 63.956727 \n",
      "\n",
      "loss: 59.599087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 60.252725 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 25/500\n",
      "--------------------\n",
      "{'hl': [131, 261], 'alpha': 0.0007921170257824812, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.29419552835677093}\n",
      "loss: 1.072227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.471331 \n",
      "\n",
      "loss: 0.483772  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.433127 \n",
      "\n",
      "loss: 0.441638  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.397213 \n",
      "\n",
      "loss: 0.401194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.383341 \n",
      "\n",
      "loss: 0.426516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.351301 \n",
      "\n",
      "loss: 0.346800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.413068 \n",
      "\n",
      "loss: 0.399454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.362279 \n",
      "\n",
      "loss: 0.345355  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.337252 \n",
      "\n",
      "loss: 0.352372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.330934 \n",
      "\n",
      "loss: 0.309423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.319672 \n",
      "\n",
      "loss: 0.331903  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.311911 \n",
      "\n",
      "loss: 0.315742  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.328642 \n",
      "\n",
      "loss: 0.347711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.340632 \n",
      "\n",
      "loss: 0.333264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.339240 \n",
      "\n",
      "loss: 0.326297  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.297443 \n",
      "\n",
      "loss: 0.298239  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.337421 \n",
      "\n",
      "loss: 0.344199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.316684 \n",
      "\n",
      "loss: 0.299136  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.341406 \n",
      "\n",
      "loss: 0.343730  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.307453 \n",
      "\n",
      "loss: 0.305142  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.291728 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 26/500\n",
      "--------------------\n",
      "{'hl': [610], 'alpha': 0.0007600979089991644, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.11454799772719608}\n",
      "loss: 1.027020  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.494505 \n",
      "\n",
      "loss: 0.475183  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.468287 \n",
      "\n",
      "loss: 0.436695  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.440992 \n",
      "\n",
      "loss: 0.437379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.411934 \n",
      "\n",
      "loss: 0.422636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.400839 \n",
      "\n",
      "loss: 0.433885  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.400916 \n",
      "\n",
      "loss: 0.375487  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.401442 \n",
      "\n",
      "loss: 0.390904  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.383965 \n",
      "\n",
      "loss: 0.412575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.383739 \n",
      "\n",
      "loss: 0.400558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.378290 \n",
      "\n",
      "loss: 0.358850  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.369524 \n",
      "\n",
      "loss: 0.353594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.378029 \n",
      "\n",
      "loss: 0.347474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.373292 \n",
      "\n",
      "loss: 0.376693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.371127 \n",
      "\n",
      "loss: 0.387697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.347027 \n",
      "\n",
      "loss: 0.362272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.358912 \n",
      "\n",
      "loss: 0.319079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360896 \n",
      "\n",
      "loss: 0.382056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.347009 \n",
      "\n",
      "loss: 0.347252  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.339900 \n",
      "\n",
      "loss: 0.344886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.329818 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 27/500\n",
      "--------------------\n",
      "{'hl': [346], 'alpha': 0.00019205667222613914, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.33452199137031063}\n",
      "loss: 1.130064  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 2.882965 \n",
      "\n",
      "loss: 2.508005  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 3.163219 \n",
      "\n",
      "loss: 3.181154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 1.149572 \n",
      "\n",
      "loss: 1.015246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 1.492594 \n",
      "\n",
      "loss: 1.574380  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 1.866883 \n",
      "\n",
      "loss: 1.747437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.697825 \n",
      "\n",
      "loss: 1.766077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 2.849399 \n",
      "\n",
      "loss: 2.677871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.084789 \n",
      "\n",
      "loss: 0.998313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.947907 \n",
      "\n",
      "loss: 2.048731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 1.732926 \n",
      "\n",
      "loss: 1.481955  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 2.357170 \n",
      "\n",
      "loss: 2.513202  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 2.475913 \n",
      "\n",
      "loss: 2.482782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 1.488224 \n",
      "\n",
      "loss: 1.236715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 1.848799 \n",
      "\n",
      "loss: 2.239805  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 2.464860 \n",
      "\n",
      "loss: 2.409992  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 2.040015 \n",
      "\n",
      "loss: 2.180703  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 1.683859 \n",
      "\n",
      "loss: 1.575790  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 1.733168 \n",
      "\n",
      "loss: 1.380712  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 2.255605 \n",
      "\n",
      "loss: 1.947174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 2.487731 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 28/500\n",
      "--------------------\n",
      "{'hl': [560], 'alpha': 0.00033825746896044834, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3923312502029476}\n",
      "loss: 1.030782  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.061628 \n",
      "\n",
      "loss: 0.886216  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 1.771227 \n",
      "\n",
      "loss: 1.831033  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 1.359583 \n",
      "\n",
      "loss: 1.651363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.213992 \n",
      "\n",
      "loss: 2.293314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.876339 \n",
      "\n",
      "loss: 0.779121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 1.478009 \n",
      "\n",
      "loss: 1.575327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 1.050640 \n",
      "\n",
      "loss: 1.024531  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.853020 \n",
      "\n",
      "loss: 0.871259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.954791 \n",
      "\n",
      "loss: 0.994481  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.766822 \n",
      "\n",
      "loss: 0.745115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 1.900914 \n",
      "\n",
      "loss: 1.921227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.749671 \n",
      "\n",
      "loss: 0.735328  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 1.123026 \n",
      "\n",
      "loss: 1.113019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.690201 \n",
      "\n",
      "loss: 0.706491  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 1.429236 \n",
      "\n",
      "loss: 1.507511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.743634 \n",
      "\n",
      "loss: 0.572402  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.754178 \n",
      "\n",
      "loss: 0.748603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.564496 \n",
      "\n",
      "loss: 0.579426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.558390 \n",
      "\n",
      "loss: 0.573303  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.947846 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 29/500\n",
      "--------------------\n",
      "{'hl': [202, 104], 'alpha': 0.00024418740348565617, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.21184695364765838}\n",
      "loss: 1.213472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.613221 \n",
      "\n",
      "loss: 0.636520  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.543927 \n",
      "\n",
      "loss: 0.538986  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.517304 \n",
      "\n",
      "loss: 0.483162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.684091 \n",
      "\n",
      "loss: 0.730140  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.943189 \n",
      "\n",
      "loss: 0.919909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.495355 \n",
      "\n",
      "loss: 0.457551  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.634326 \n",
      "\n",
      "loss: 0.650193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.595538 \n",
      "\n",
      "loss: 0.561186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.815267 \n",
      "\n",
      "loss: 0.783224  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.470518 \n",
      "\n",
      "loss: 0.462729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.504739 \n",
      "\n",
      "loss: 0.514857  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.522189 \n",
      "\n",
      "loss: 0.519249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.526763 \n",
      "\n",
      "loss: 0.525751  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 1.126975 \n",
      "\n",
      "loss: 1.006673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.496353 \n",
      "\n",
      "loss: 0.487150  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.567409 \n",
      "\n",
      "loss: 0.590161  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.532839 \n",
      "\n",
      "loss: 0.512502  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.553219 \n",
      "\n",
      "loss: 0.531212  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.859955 \n",
      "\n",
      "loss: 0.786070  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.466183 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 30/500\n",
      "--------------------\n",
      "{'hl': [63, 697], 'alpha': 0.041098119733119214, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.20137037892292414}\n",
      "loss: 1.103640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.495468 \n",
      "\n",
      "loss: 0.494244  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.485197 \n",
      "\n",
      "loss: 0.441689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.446359 \n",
      "\n",
      "loss: 0.479104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.439500 \n",
      "\n",
      "loss: 0.434414  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.433636 \n",
      "\n",
      "loss: 0.421503  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.421400 \n",
      "\n",
      "loss: 0.412773  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.435947 \n",
      "\n",
      "loss: 0.418647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.428887 \n",
      "\n",
      "loss: 0.433660  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.415986 \n",
      "\n",
      "loss: 0.469647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.419256 \n",
      "\n",
      "loss: 0.384544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.423423 \n",
      "\n",
      "loss: 0.390420  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.430787 \n",
      "\n",
      "loss: 0.393162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.432734 \n",
      "\n",
      "loss: 0.403642  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.418243 \n",
      "\n",
      "loss: 0.453218  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.421548 \n",
      "\n",
      "loss: 0.467840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.422910 \n",
      "\n",
      "loss: 0.471549  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.431947 \n",
      "\n",
      "loss: 0.404141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.420037 \n",
      "\n",
      "loss: 0.427087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.427404 \n",
      "\n",
      "loss: 0.421572  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.408655 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 31/500\n",
      "--------------------\n",
      "{'hl': [119, 262], 'alpha': 0.0005839293282904162, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.21099863175321865}\n",
      "loss: 1.099761  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.479112 \n",
      "\n",
      "loss: 1.408974  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.785740 \n",
      "\n",
      "loss: 0.754829  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.597403 \n",
      "\n",
      "loss: 0.589247  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.535492 \n",
      "\n",
      "loss: 0.557067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.528051 \n",
      "\n",
      "loss: 0.514749  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.517803 \n",
      "\n",
      "loss: 0.488511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.517884 \n",
      "\n",
      "loss: 0.496622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.513952 \n",
      "\n",
      "loss: 0.476796  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.502376 \n",
      "\n",
      "loss: 0.506313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.509266 \n",
      "\n",
      "loss: 0.500736  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.498367 \n",
      "\n",
      "loss: 0.502970  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.507155 \n",
      "\n",
      "loss: 0.510566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.484047 \n",
      "\n",
      "loss: 0.490499  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.479249 \n",
      "\n",
      "loss: 0.540803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.486604 \n",
      "\n",
      "loss: 0.487046  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.477894 \n",
      "\n",
      "loss: 0.493098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.476355 \n",
      "\n",
      "loss: 0.451781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.480130 \n",
      "\n",
      "loss: 0.471872  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.492087 \n",
      "\n",
      "loss: 0.480050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.480951 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 32/500\n",
      "--------------------\n",
      "{'hl': [481, 263], 'alpha': 0.314734112319519, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.40403032014137813}\n",
      "loss: 1.060233  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1074.290602 \n",
      "\n",
      "loss: 1047.266968  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 609.696343 \n",
      "\n",
      "loss: 569.231262  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 1763.081136 \n",
      "\n",
      "loss: 1736.323730  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 1792.374335 \n",
      "\n",
      "loss: 1852.457031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1518.588067 \n",
      "\n",
      "loss: 1506.290039  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1035.454339 \n",
      "\n",
      "loss: 992.473694  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 263.925435 \n",
      "\n",
      "loss: 302.351807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 171.633146 \n",
      "\n",
      "loss: 162.190659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 2.907535 \n",
      "\n",
      "loss: 3.235146  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.603509 \n",
      "\n",
      "loss: 0.587364  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.494118 \n",
      "\n",
      "loss: 0.486310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.533734 \n",
      "\n",
      "loss: 0.452173  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.465993 \n",
      "\n",
      "loss: 0.481587  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.492328 \n",
      "\n",
      "loss: 0.495107  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.484434 \n",
      "\n",
      "loss: 0.513773  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.562453 \n",
      "\n",
      "loss: 0.559634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.492578 \n",
      "\n",
      "loss: 0.478523  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.502757 \n",
      "\n",
      "loss: 0.468603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.500262 \n",
      "\n",
      "loss: 0.500264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.515988 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 33/500\n",
      "--------------------\n",
      "{'hl': [108, 59, 675], 'alpha': 0.9934130793518847, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.463190854805763}\n",
      "loss: 1.105418  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.007197 \n",
      "\n",
      "loss: 1.005484  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.006918 \n",
      "\n",
      "loss: 1.003631  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.004445 \n",
      "\n",
      "loss: 1.005305  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.007555 \n",
      "\n",
      "loss: 1.009015  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.004668 \n",
      "\n",
      "loss: 1.005227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.009326 \n",
      "\n",
      "loss: 1.009542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.007677 \n",
      "\n",
      "loss: 1.004920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.005396 \n",
      "\n",
      "loss: 1.006964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.004952 \n",
      "\n",
      "loss: 1.009762  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.008076 \n",
      "\n",
      "loss: 1.011778  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.005624 \n",
      "\n",
      "loss: 1.006074  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.007266 \n",
      "\n",
      "loss: 1.004867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.006876 \n",
      "\n",
      "loss: 1.003691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.006779 \n",
      "\n",
      "loss: 1.007599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.003370 \n",
      "\n",
      "loss: 1.000026  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.006534 \n",
      "\n",
      "loss: 0.999601  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.007093 \n",
      "\n",
      "loss: 1.006760  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.004404 \n",
      "\n",
      "loss: 1.007148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.005811 \n",
      "\n",
      "loss: 1.008109  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.005405 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 34/500\n",
      "--------------------\n",
      "{'hl': [178], 'alpha': 0.004223341809737973, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.4323387319757047}\n",
      "loss: 1.007689  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.849047 \n",
      "\n",
      "loss: 0.870145  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.880222 \n",
      "\n",
      "loss: 0.743987  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.676667 \n",
      "\n",
      "loss: 0.695089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.894418 \n",
      "\n",
      "loss: 0.890248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.615342 \n",
      "\n",
      "loss: 0.739095  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.734734 \n",
      "\n",
      "loss: 0.688518  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.439431 \n",
      "\n",
      "loss: 1.267317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.562782 \n",
      "\n",
      "loss: 0.529066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.493561 \n",
      "\n",
      "loss: 0.488108  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.584826 \n",
      "\n",
      "loss: 0.591998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.452527 \n",
      "\n",
      "loss: 0.413687  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.566639 \n",
      "\n",
      "loss: 0.519766  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.616974 \n",
      "\n",
      "loss: 0.660662  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.529568 \n",
      "\n",
      "loss: 0.530766  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.608907 \n",
      "\n",
      "loss: 0.617727  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.469634 \n",
      "\n",
      "loss: 0.449524  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.647173 \n",
      "\n",
      "loss: 0.720648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.561879 \n",
      "\n",
      "loss: 0.574835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.606708 \n",
      "\n",
      "loss: 0.659733  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.439408 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 35/500\n",
      "--------------------\n",
      "{'hl': [176], 'alpha': 0.0032801407222894873, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.46326638497231076}\n",
      "loss: 1.124138  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 1.627396 \n",
      "\n",
      "loss: 1.674598  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 2.115476 \n",
      "\n",
      "loss: 2.200105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 2.218946 \n",
      "\n",
      "loss: 1.899060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.239289 \n",
      "\n",
      "loss: 1.282077  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 1.533750 \n",
      "\n",
      "loss: 1.694833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 1.840834 \n",
      "\n",
      "loss: 1.711335  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 1.837213 \n",
      "\n",
      "loss: 1.912566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.767512 \n",
      "\n",
      "loss: 0.783571  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 2.719019 \n",
      "\n",
      "loss: 2.694304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.995257 \n",
      "\n",
      "loss: 1.916160  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.704612 \n",
      "\n",
      "loss: 1.717038  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.664419 \n",
      "\n",
      "loss: 1.527820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 2.070508 \n",
      "\n",
      "loss: 2.019077  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 2.541144 \n",
      "\n",
      "loss: 2.415891  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.014371 \n",
      "\n",
      "loss: 0.979880  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 1.437605 \n",
      "\n",
      "loss: 1.355944  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 1.806905 \n",
      "\n",
      "loss: 1.733157  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 28.3%, Avg loss: 2.786260 \n",
      "\n",
      "loss: 2.786484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 1.663783 \n",
      "\n",
      "loss: 1.928740  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 1.055328 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 36/500\n",
      "--------------------\n",
      "{'hl': [300, 441], 'alpha': 0.06114571312293328, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.0950299438470918}\n",
      "loss: 1.087059  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.807428 \n",
      "\n",
      "loss: 1.881956  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.171499 \n",
      "\n",
      "loss: 1.207877  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.080430 \n",
      "\n",
      "loss: 1.160105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.006441 \n",
      "\n",
      "loss: 1.005796  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.927430 \n",
      "\n",
      "loss: 0.957753  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.997667 \n",
      "\n",
      "loss: 1.009037  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.043719 \n",
      "\n",
      "loss: 1.040193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.010924 \n",
      "\n",
      "loss: 1.007409  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.147707 \n",
      "\n",
      "loss: 1.136192  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.916392 \n",
      "\n",
      "loss: 0.924877  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.046965 \n",
      "\n",
      "loss: 1.082896  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.967077 \n",
      "\n",
      "loss: 0.964402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.988616 \n",
      "\n",
      "loss: 0.981056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.069877 \n",
      "\n",
      "loss: 1.032435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.941857 \n",
      "\n",
      "loss: 0.940453  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.034231 \n",
      "\n",
      "loss: 1.006003  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.974013 \n",
      "\n",
      "loss: 0.992545  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.974793 \n",
      "\n",
      "loss: 0.948113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.069475 \n",
      "\n",
      "loss: 1.043199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.038143 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 37/500\n",
      "--------------------\n",
      "{'hl': [67], 'alpha': 0.02073581756534931, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.02867691992645079}\n",
      "loss: 1.220601  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.445570 \n",
      "\n",
      "loss: 0.387432  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.434892 \n",
      "\n",
      "loss: 0.410914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.420140 \n",
      "\n",
      "loss: 0.447497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.424163 \n",
      "\n",
      "loss: 0.408835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.439243 \n",
      "\n",
      "loss: 0.447155  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.430639 \n",
      "\n",
      "loss: 0.409328  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.423406 \n",
      "\n",
      "loss: 0.428225  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.416523 \n",
      "\n",
      "loss: 0.413745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.423391 \n",
      "\n",
      "loss: 0.432477  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.414062 \n",
      "\n",
      "loss: 0.437121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.425753 \n",
      "\n",
      "loss: 0.403295  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.425142 \n",
      "\n",
      "loss: 0.425364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.427531 \n",
      "\n",
      "loss: 0.447124  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.412154 \n",
      "\n",
      "loss: 0.450595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.439944 \n",
      "\n",
      "loss: 0.427574  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.427378 \n",
      "\n",
      "loss: 0.440587  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.414118 \n",
      "\n",
      "loss: 0.414394  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.441536 \n",
      "\n",
      "loss: 0.388654  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.405310 \n",
      "\n",
      "loss: 0.411526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.415662 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 38/500\n",
      "--------------------\n",
      "{'hl': [496, 522, 551], 'alpha': 0.00042631529260520924, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.0343538142186258}\n",
      "loss: 1.114364  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.762008 \n",
      "\n",
      "loss: 0.760076  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.590037 \n",
      "\n",
      "loss: 0.568982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.554787 \n",
      "\n",
      "loss: 0.542498  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.506831 \n",
      "\n",
      "loss: 0.510260  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.497539 \n",
      "\n",
      "loss: 0.506239  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.483975 \n",
      "\n",
      "loss: 0.476813  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.470652 \n",
      "\n",
      "loss: 0.462063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.455478 \n",
      "\n",
      "loss: 0.462093  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.446771 \n",
      "\n",
      "loss: 0.459620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.446323 \n",
      "\n",
      "loss: 0.414542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.442124 \n",
      "\n",
      "loss: 0.403378  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.439540 \n",
      "\n",
      "loss: 0.435047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.416316 \n",
      "\n",
      "loss: 0.416279  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.412655 \n",
      "\n",
      "loss: 0.442092  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.400992 \n",
      "\n",
      "loss: 0.399205  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.388819 \n",
      "\n",
      "loss: 0.368467  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.409801 \n",
      "\n",
      "loss: 0.418688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.400392 \n",
      "\n",
      "loss: 0.402852  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.384736 \n",
      "\n",
      "loss: 0.401120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.374757 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 39/500\n",
      "--------------------\n",
      "{'hl': [699], 'alpha': 0.2800765885369556, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.47080390400182176}\n",
      "loss: 1.060750  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 1.905746 \n",
      "\n",
      "loss: 1.996075  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 8.702158 \n",
      "\n",
      "loss: 8.554601  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 5.953259 \n",
      "\n",
      "loss: 5.746136  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 22.870470 \n",
      "\n",
      "loss: 22.785019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 4.278309 \n",
      "\n",
      "loss: 3.829673  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 11.771928 \n",
      "\n",
      "loss: 11.857723  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 10.623667 \n",
      "\n",
      "loss: 11.029507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 18.111782 \n",
      "\n",
      "loss: 17.205803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 4.676852 \n",
      "\n",
      "loss: 4.956578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 9.054625 \n",
      "\n",
      "loss: 10.550010  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 14.493036 \n",
      "\n",
      "loss: 13.922458  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 10.986924 \n",
      "\n",
      "loss: 10.698034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 18.373409 \n",
      "\n",
      "loss: 18.158304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 14.012429 \n",
      "\n",
      "loss: 15.438030  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 15.574976 \n",
      "\n",
      "loss: 15.118791  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 19.406162 \n",
      "\n",
      "loss: 18.322922  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 11.995801 \n",
      "\n",
      "loss: 12.030557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 21.144599 \n",
      "\n",
      "loss: 21.310959  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 4.915751 \n",
      "\n",
      "loss: 4.844060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 2.405783 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 40/500\n",
      "--------------------\n",
      "{'hl': [260, 600, 616], 'alpha': 0.00014420046111883326, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.32872084491981396}\n",
      "loss: 1.104057  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.829567 \n",
      "\n",
      "loss: 0.822297  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.827310 \n",
      "\n",
      "loss: 0.794751  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809018 \n",
      "\n",
      "loss: 0.819107  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.823229 \n",
      "\n",
      "loss: 0.828264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.814150 \n",
      "\n",
      "loss: 0.787941  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819632 \n",
      "\n",
      "loss: 0.804865  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.822638 \n",
      "\n",
      "loss: 0.798606  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.818721 \n",
      "\n",
      "loss: 0.796589  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.848302 \n",
      "\n",
      "loss: 0.862031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.807988 \n",
      "\n",
      "loss: 0.827180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817721 \n",
      "\n",
      "loss: 0.799977  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.823276 \n",
      "\n",
      "loss: 0.814976  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.813751 \n",
      "\n",
      "loss: 0.836497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.816922 \n",
      "\n",
      "loss: 0.803369  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.818712 \n",
      "\n",
      "loss: 0.844829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.812711 \n",
      "\n",
      "loss: 0.822996  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.823280 \n",
      "\n",
      "loss: 0.820828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.810446 \n",
      "\n",
      "loss: 0.791937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.815077 \n",
      "\n",
      "loss: 0.828016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.814731 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 41/500\n",
      "--------------------\n",
      "{'hl': [543, 331, 275], 'alpha': 0.0006562008637298699, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.13288069481442377}\n",
      "loss: 1.105271  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.511862 \n",
      "\n",
      "loss: 0.476519  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.470384 \n",
      "\n",
      "loss: 0.465525  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.427413 \n",
      "\n",
      "loss: 0.402501  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.423646 \n",
      "\n",
      "loss: 0.444651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387956 \n",
      "\n",
      "loss: 0.385303  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.395039 \n",
      "\n",
      "loss: 0.375491  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.373590 \n",
      "\n",
      "loss: 0.386271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.358518 \n",
      "\n",
      "loss: 0.358265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.341247 \n",
      "\n",
      "loss: 0.373168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.345692 \n",
      "\n",
      "loss: 0.350949  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.330686 \n",
      "\n",
      "loss: 0.338265  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.340880 \n",
      "\n",
      "loss: 0.354775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.335892 \n",
      "\n",
      "loss: 0.313365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.327171 \n",
      "\n",
      "loss: 0.335106  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.322823 \n",
      "\n",
      "loss: 0.330205  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.323571 \n",
      "\n",
      "loss: 0.311951  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.326688 \n",
      "\n",
      "loss: 0.287046  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.332706 \n",
      "\n",
      "loss: 0.352993  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.381047 \n",
      "\n",
      "loss: 0.395145  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.301531 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 42/500\n",
      "--------------------\n",
      "{'hl': [695], 'alpha': 0.03819470458521908, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4645162640195865}\n",
      "loss: 1.141696  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 19.490608 \n",
      "\n",
      "loss: 19.916998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 9.478127 \n",
      "\n",
      "loss: 9.169645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 14.590620 \n",
      "\n",
      "loss: 13.634696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 18.680884 \n",
      "\n",
      "loss: 18.596914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 4.061105 \n",
      "\n",
      "loss: 3.882828  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 4.759052 \n",
      "\n",
      "loss: 4.205651  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 7.122416 \n",
      "\n",
      "loss: 6.493570  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 8.502758 \n",
      "\n",
      "loss: 9.165201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 7.793091 \n",
      "\n",
      "loss: 8.211347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 8.865385 \n",
      "\n",
      "loss: 8.840546  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 3.328849 \n",
      "\n",
      "loss: 3.086494  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 8.477846 \n",
      "\n",
      "loss: 6.778284  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 39.5%, Avg loss: 9.737988 \n",
      "\n",
      "loss: 9.303184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 4.998849 \n",
      "\n",
      "loss: 5.318487  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 5.757156 \n",
      "\n",
      "loss: 5.671499  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 8.339016 \n",
      "\n",
      "loss: 8.462821  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 3.916970 \n",
      "\n",
      "loss: 3.995413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 7.087388 \n",
      "\n",
      "loss: 8.281202  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 36.8%, Avg loss: 11.271827 \n",
      "\n",
      "loss: 10.448112  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 6.003753 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 43/500\n",
      "--------------------\n",
      "{'hl': [17], 'alpha': 0.006809921261265076, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2688634386104035}\n",
      "loss: 1.161471  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.466417 \n",
      "\n",
      "loss: 0.519512  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.445706 \n",
      "\n",
      "loss: 0.422978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.424871 \n",
      "\n",
      "loss: 0.420006  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.412345 \n",
      "\n",
      "loss: 0.414400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.404828 \n",
      "\n",
      "loss: 0.410460  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.392809 \n",
      "\n",
      "loss: 0.386135  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.404005 \n",
      "\n",
      "loss: 0.345956  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.384361 \n",
      "\n",
      "loss: 0.391537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.379576 \n",
      "\n",
      "loss: 0.387493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.364680 \n",
      "\n",
      "loss: 0.409052  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.369191 \n",
      "\n",
      "loss: 0.374824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.371793 \n",
      "\n",
      "loss: 0.382294  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.372486 \n",
      "\n",
      "loss: 0.335063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.369406 \n",
      "\n",
      "loss: 0.383576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.354354 \n",
      "\n",
      "loss: 0.366162  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.354814 \n",
      "\n",
      "loss: 0.340023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.368984 \n",
      "\n",
      "loss: 0.364395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.361657 \n",
      "\n",
      "loss: 0.332145  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.367993 \n",
      "\n",
      "loss: 0.370071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.354618 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 44/500\n",
      "--------------------\n",
      "{'hl': [279, 143, 365], 'alpha': 0.3337772212337715, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.14256519686920668}\n",
      "loss: 1.068478  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 1.909914 \n",
      "\n",
      "loss: 1.894166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.214540 \n",
      "\n",
      "loss: 2.253290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.727897 \n",
      "\n",
      "loss: 0.747669  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.706782 \n",
      "\n",
      "loss: 0.720650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.732041 \n",
      "\n",
      "loss: 0.756272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.693238 \n",
      "\n",
      "loss: 0.714515  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.729121 \n",
      "\n",
      "loss: 0.716443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.701136 \n",
      "\n",
      "loss: 0.723629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.809981 \n",
      "\n",
      "loss: 0.800381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.736305 \n",
      "\n",
      "loss: 0.752876  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.748724 \n",
      "\n",
      "loss: 0.744917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.743736 \n",
      "\n",
      "loss: 0.746937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.680648 \n",
      "\n",
      "loss: 0.678691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.779947 \n",
      "\n",
      "loss: 0.783464  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.737614 \n",
      "\n",
      "loss: 0.741015  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.766767 \n",
      "\n",
      "loss: 0.752072  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.767985 \n",
      "\n",
      "loss: 0.753219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.726802 \n",
      "\n",
      "loss: 0.724397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.737810 \n",
      "\n",
      "loss: 0.747759  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.730675 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 45/500\n",
      "--------------------\n",
      "{'hl': [564, 317], 'alpha': 0.027971197703783597, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4658848441140951}\n",
      "loss: 1.071624  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 1219.840074 \n",
      "\n",
      "loss: 1198.484741  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 13.247098 \n",
      "\n",
      "loss: 10.068005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 10.709196 \n",
      "\n",
      "loss: 11.401406  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 5.489051 \n",
      "\n",
      "loss: 5.522225  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.960421 \n",
      "\n",
      "loss: 0.898029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 1.542318 \n",
      "\n",
      "loss: 1.405221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 28.387423 \n",
      "\n",
      "loss: 27.593683  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 184.475299 \n",
      "\n",
      "loss: 184.642014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 20.141525 \n",
      "\n",
      "loss: 26.785654  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 5.765239 \n",
      "\n",
      "loss: 5.542707  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.357769 \n",
      "\n",
      "loss: 1.421843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.599208 \n",
      "\n",
      "loss: 0.593776  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.443322 \n",
      "\n",
      "loss: 0.415464  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.014136 \n",
      "\n",
      "loss: 1.012029  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 14.937215 \n",
      "\n",
      "loss: 14.469578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 258.213798 \n",
      "\n",
      "loss: 240.159546  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 8478.101074 \n",
      "\n",
      "loss: 7127.509277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 1012.764214 \n",
      "\n",
      "loss: 733.096375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 103.670197 \n",
      "\n",
      "loss: 26.023899  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 4.540140 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 46/500\n",
      "--------------------\n",
      "{'hl': [145], 'alpha': 0.0011425196704827312, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.13624687133617666}\n",
      "loss: 1.144664  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.503343 \n",
      "\n",
      "loss: 0.483835  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.474461 \n",
      "\n",
      "loss: 0.432942  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.445231 \n",
      "\n",
      "loss: 0.446710  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.415888 \n",
      "\n",
      "loss: 0.406545  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.408874 \n",
      "\n",
      "loss: 0.412524  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.401299 \n",
      "\n",
      "loss: 0.391571  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.402104 \n",
      "\n",
      "loss: 0.395570  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.396853 \n",
      "\n",
      "loss: 0.386494  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.383387 \n",
      "\n",
      "loss: 0.398945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.369229 \n",
      "\n",
      "loss: 0.373503  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.368117 \n",
      "\n",
      "loss: 0.367465  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.371381 \n",
      "\n",
      "loss: 0.386142  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.363830 \n",
      "\n",
      "loss: 0.372725  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.356484 \n",
      "\n",
      "loss: 0.385865  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347779 \n",
      "\n",
      "loss: 0.411151  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.348261 \n",
      "\n",
      "loss: 0.340955  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.367278 \n",
      "\n",
      "loss: 0.371618  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.366414 \n",
      "\n",
      "loss: 0.346226  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.345392 \n",
      "\n",
      "loss: 0.345154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.344482 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 47/500\n",
      "--------------------\n",
      "{'hl': [223, 359, 216], 'alpha': 0.05623264544297623, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.12563551390974007}\n",
      "loss: 1.095962  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 4.276125 \n",
      "\n",
      "loss: 3.525079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.007525 \n",
      "\n",
      "loss: 1.004775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.442898 \n",
      "\n",
      "loss: 0.445309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.431253 \n",
      "\n",
      "loss: 0.410404  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.429875 \n",
      "\n",
      "loss: 0.455877  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.436906 \n",
      "\n",
      "loss: 0.418733  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.430847 \n",
      "\n",
      "loss: 0.397217  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.428945 \n",
      "\n",
      "loss: 0.449324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.414930 \n",
      "\n",
      "loss: 0.417948  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.445657 \n",
      "\n",
      "loss: 0.442602  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.430298 \n",
      "\n",
      "loss: 0.435382  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.443857 \n",
      "\n",
      "loss: 0.379912  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.440081 \n",
      "\n",
      "loss: 0.461123  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.441205 \n",
      "\n",
      "loss: 0.459250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.431546 \n",
      "\n",
      "loss: 0.430769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.436957 \n",
      "\n",
      "loss: 0.402454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.453583 \n",
      "\n",
      "loss: 0.440342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.443207 \n",
      "\n",
      "loss: 0.456288  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.452866 \n",
      "\n",
      "loss: 0.482562  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.442076 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 48/500\n",
      "--------------------\n",
      "{'hl': [102], 'alpha': 0.034445920049578936, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.001872489974982372}\n",
      "loss: 1.123799  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 1.025093 \n",
      "\n",
      "loss: 1.028252  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.958901 \n",
      "\n",
      "loss: 0.958793  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.897087 \n",
      "\n",
      "loss: 0.902376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.858530 \n",
      "\n",
      "loss: 0.857921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.820355 \n",
      "\n",
      "loss: 0.821423  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.786690 \n",
      "\n",
      "loss: 0.762932  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.768560 \n",
      "\n",
      "loss: 0.755397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.738180 \n",
      "\n",
      "loss: 0.736362  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.722675 \n",
      "\n",
      "loss: 0.709579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.698843 \n",
      "\n",
      "loss: 0.705853  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.685744 \n",
      "\n",
      "loss: 0.697473  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.675548 \n",
      "\n",
      "loss: 0.667108  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.656101 \n",
      "\n",
      "loss: 0.653673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.649637 \n",
      "\n",
      "loss: 0.669848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.637160 \n",
      "\n",
      "loss: 0.627877  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.635926 \n",
      "\n",
      "loss: 0.635641  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.627855 \n",
      "\n",
      "loss: 0.623137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.621030 \n",
      "\n",
      "loss: 0.613314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.603999 \n",
      "\n",
      "loss: 0.627648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.594757 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 49/500\n",
      "--------------------\n",
      "{'hl': [660], 'alpha': 0.8302173695566964, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.275885042521083}\n",
      "loss: 1.130205  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.890953 \n",
      "\n",
      "loss: 0.909180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.756203 \n",
      "\n",
      "loss: 0.752020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.786971 \n",
      "\n",
      "loss: 0.803776  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.790973 \n",
      "\n",
      "loss: 0.800007  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.789053 \n",
      "\n",
      "loss: 0.789623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.777915 \n",
      "\n",
      "loss: 0.770146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.800609 \n",
      "\n",
      "loss: 0.806382  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.775756 \n",
      "\n",
      "loss: 0.758461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.745575 \n",
      "\n",
      "loss: 0.733194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.860037 \n",
      "\n",
      "loss: 0.851918  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.891457 \n",
      "\n",
      "loss: 0.884614  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 84.441761 \n",
      "\n",
      "loss: 86.075027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 40.133563 \n",
      "\n",
      "loss: 37.978973  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 25.5%, Avg loss: 17.510810 \n",
      "\n",
      "loss: 17.908613  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 28.9%, Avg loss: 8.527541 \n",
      "\n",
      "loss: 8.647460  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 4.561794 \n",
      "\n",
      "loss: 4.538777  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 15.947460 \n",
      "\n",
      "loss: 15.184263  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 5.834223 \n",
      "\n",
      "loss: 5.975926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 4.770380 \n",
      "\n",
      "loss: 4.764545  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 27.4%, Avg loss: 4.718843 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 50/500\n",
      "--------------------\n",
      "{'hl': [582, 17], 'alpha': 0.00028021767306463113, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.41731405044101977}\n",
      "loss: 1.164931  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.478496 \n",
      "\n",
      "loss: 0.469769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.460288 \n",
      "\n",
      "loss: 0.537247  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.417561 \n",
      "\n",
      "loss: 0.433178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.405085 \n",
      "\n",
      "loss: 0.471011  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.390379 \n",
      "\n",
      "loss: 0.407481  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.367027 \n",
      "\n",
      "loss: 0.388575  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.381268 \n",
      "\n",
      "loss: 0.369152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366025 \n",
      "\n",
      "loss: 0.371524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.349588 \n",
      "\n",
      "loss: 0.379896  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.339555 \n",
      "\n",
      "loss: 0.367997  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.362222 \n",
      "\n",
      "loss: 0.325354  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.367251 \n",
      "\n",
      "loss: 0.372966  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.356425 \n",
      "\n",
      "loss: 0.387205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.331174 \n",
      "\n",
      "loss: 0.312803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.331471 \n",
      "\n",
      "loss: 0.327586  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.332015 \n",
      "\n",
      "loss: 0.331304  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.371666 \n",
      "\n",
      "loss: 0.371565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.320820 \n",
      "\n",
      "loss: 0.298243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.326437 \n",
      "\n",
      "loss: 0.308582  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.315322 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 51/500\n",
      "--------------------\n",
      "{'hl': [573, 159, 448], 'alpha': 0.00032343132290925733, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.44950084622242076}\n",
      "loss: 1.112299  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 10660.488824 \n",
      "\n",
      "loss: 6485.172852  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 6079.467719 \n",
      "\n",
      "loss: 6139.460449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 2973.089193 \n",
      "\n",
      "loss: 2937.246582  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 1839.180718 \n",
      "\n",
      "loss: 2161.107178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 656.067552 \n",
      "\n",
      "loss: 657.454956  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 1868.643934 \n",
      "\n",
      "loss: 1630.158691  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 1099.364543 \n",
      "\n",
      "loss: 1149.588135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1054.784593 \n",
      "\n",
      "loss: 916.074707  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 367.098151 \n",
      "\n",
      "loss: 365.726105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 132.009405 \n",
      "\n",
      "loss: 126.989983  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 1198.466010 \n",
      "\n",
      "loss: 1167.784912  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 148.459454 \n",
      "\n",
      "loss: 118.553795  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 197.406996 \n",
      "\n",
      "loss: 226.428741  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 93.178276 \n",
      "\n",
      "loss: 89.577835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 72.010507 \n",
      "\n",
      "loss: 69.879898  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 7305.655979 \n",
      "\n",
      "loss: 6695.475586  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 2025.762736 \n",
      "\n",
      "loss: 2014.889404  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 440.897342 \n",
      "\n",
      "loss: 424.272644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 5513.220893 \n",
      "\n",
      "loss: 4783.457520  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 736321.673611 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 52/500\n",
      "--------------------\n",
      "{'hl': [374], 'alpha': 0.000692318845063847, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.1769039494438477}\n",
      "loss: 1.121732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.498385 \n",
      "\n",
      "loss: 0.485826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.481547 \n",
      "\n",
      "loss: 0.484419  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.451070 \n",
      "\n",
      "loss: 0.450983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.436334 \n",
      "\n",
      "loss: 0.449313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.423461 \n",
      "\n",
      "loss: 0.450479  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.416931 \n",
      "\n",
      "loss: 0.423550  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.429218 \n",
      "\n",
      "loss: 0.418218  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.416365 \n",
      "\n",
      "loss: 0.422256  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.413737 \n",
      "\n",
      "loss: 0.373850  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.399220 \n",
      "\n",
      "loss: 0.389421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.399990 \n",
      "\n",
      "loss: 0.400998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.398187 \n",
      "\n",
      "loss: 0.389760  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.418095 \n",
      "\n",
      "loss: 0.457789  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.387638 \n",
      "\n",
      "loss: 0.369909  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.385750 \n",
      "\n",
      "loss: 0.412730  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.379904 \n",
      "\n",
      "loss: 0.347077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.397554 \n",
      "\n",
      "loss: 0.442105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.386261 \n",
      "\n",
      "loss: 0.384161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.370238 \n",
      "\n",
      "loss: 0.408919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.362122 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 53/500\n",
      "--------------------\n",
      "{'hl': [424, 643, 166], 'alpha': 0.5047255503711399, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.4881053958621883}\n",
      "loss: 1.108267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.961940 \n",
      "\n",
      "loss: 0.966101  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.963228 \n",
      "\n",
      "loss: 0.962539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.962373 \n",
      "\n",
      "loss: 0.964891  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.960737 \n",
      "\n",
      "loss: 0.964722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.960723 \n",
      "\n",
      "loss: 0.957498  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.964500 \n",
      "\n",
      "loss: 0.958557  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.962183 \n",
      "\n",
      "loss: 0.968021  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.963117 \n",
      "\n",
      "loss: 0.968397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.959601 \n",
      "\n",
      "loss: 0.965948  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.961833 \n",
      "\n",
      "loss: 0.969262  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.961369 \n",
      "\n",
      "loss: 0.957937  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.961274 \n",
      "\n",
      "loss: 0.959379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.959558 \n",
      "\n",
      "loss: 0.953848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.960348 \n",
      "\n",
      "loss: 0.960495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962632 \n",
      "\n",
      "loss: 0.962473  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.961586 \n",
      "\n",
      "loss: 0.965606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.964621 \n",
      "\n",
      "loss: 0.962461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.961977 \n",
      "\n",
      "loss: 0.962460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.961619 \n",
      "\n",
      "loss: 0.962602  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.960315 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 54/500\n",
      "--------------------\n",
      "{'hl': [430], 'alpha': 0.0001256450685433316, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.40113734595467576}\n",
      "loss: 1.126270  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 79.315087 \n",
      "\n",
      "loss: 65.512535  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 20.451145 \n",
      "\n",
      "loss: 28.624260  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 13.117366 \n",
      "\n",
      "loss: 7.179391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 4.180438 \n",
      "\n",
      "loss: 3.438999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 2.407714 \n",
      "\n",
      "loss: 1.619719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.677799 \n",
      "\n",
      "loss: 0.450583  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.555551 \n",
      "\n",
      "loss: 0.461493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.455224 \n",
      "\n",
      "loss: 0.468304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.557656 \n",
      "\n",
      "loss: 0.650869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.466894 \n",
      "\n",
      "loss: 0.357099  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.430389 \n",
      "\n",
      "loss: 0.504652  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.540309 \n",
      "\n",
      "loss: 0.903894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.403677 \n",
      "\n",
      "loss: 0.369110  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.434113 \n",
      "\n",
      "loss: 0.458983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.594979 \n",
      "\n",
      "loss: 0.493225  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.574800 \n",
      "\n",
      "loss: 0.557740  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.477587 \n",
      "\n",
      "loss: 0.527904  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.386526 \n",
      "\n",
      "loss: 0.372723  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.379840 \n",
      "\n",
      "loss: 0.390997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.342962 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 55/500\n",
      "--------------------\n",
      "{'hl': [262, 281, 171], 'alpha': 0.14109058576968314, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.43609617477475426}\n",
      "loss: 1.104871  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.052743 \n",
      "\n",
      "loss: 0.881258  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 1.679947 \n",
      "\n",
      "loss: 1.110718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.101860 \n",
      "\n",
      "loss: 1.224441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 0.971109 \n",
      "\n",
      "loss: 1.003351  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.224659 \n",
      "\n",
      "loss: 1.131415  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.735298 \n",
      "\n",
      "loss: 0.704618  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.693670 \n",
      "\n",
      "loss: 0.744182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.854395 \n",
      "\n",
      "loss: 1.776808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.611510 \n",
      "\n",
      "loss: 0.587983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.498820 \n",
      "\n",
      "loss: 0.487493  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.446364 \n",
      "\n",
      "loss: 0.395668  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.673474 \n",
      "\n",
      "loss: 0.681168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.518746 \n",
      "\n",
      "loss: 0.511724  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.823775 \n",
      "\n",
      "loss: 0.866713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.577474 \n",
      "\n",
      "loss: 4.545641  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1228.268623 \n",
      "\n",
      "loss: 1171.236328  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 60.530834 \n",
      "\n",
      "loss: 75.052963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.868552 \n",
      "\n",
      "loss: 0.855771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.882999 \n",
      "\n",
      "loss: 0.871535  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.753770 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 56/500\n",
      "--------------------\n",
      "{'hl': [235, 212], 'alpha': 0.1846487714264064, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.15266491458256642}\n",
      "loss: 1.033165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.317611 \n",
      "\n",
      "loss: 2.277396  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.884280 \n",
      "\n",
      "loss: 0.867843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.819515 \n",
      "\n",
      "loss: 0.832283  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.825819 \n",
      "\n",
      "loss: 0.834019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.851330 \n",
      "\n",
      "loss: 0.869082  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.842511 \n",
      "\n",
      "loss: 0.838917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.826210 \n",
      "\n",
      "loss: 0.813276  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 3.013166 \n",
      "\n",
      "loss: 2.817087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.941525 \n",
      "\n",
      "loss: 3.791084  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.334165 \n",
      "\n",
      "loss: 2.444327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.085741 \n",
      "\n",
      "loss: 2.784875  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.962665 \n",
      "\n",
      "loss: 0.978053  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.837120 \n",
      "\n",
      "loss: 0.850050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.425006 \n",
      "\n",
      "loss: 5.388459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.989598 \n",
      "\n",
      "loss: 0.968427  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.815692 \n",
      "\n",
      "loss: 0.828705  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.852439 \n",
      "\n",
      "loss: 0.816535  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.829000 \n",
      "\n",
      "loss: 0.837582  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.813206 \n",
      "\n",
      "loss: 0.809804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.869524 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 57/500\n",
      "--------------------\n",
      "{'hl': [236], 'alpha': 0.00012435342141911755, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.16419814940373348}\n",
      "loss: 1.258528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.863435 \n",
      "\n",
      "loss: 0.798942  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.735408 \n",
      "\n",
      "loss: 0.735143  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.486813 \n",
      "\n",
      "loss: 0.531425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.397795 \n",
      "\n",
      "loss: 0.371045  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.459407 \n",
      "\n",
      "loss: 0.469064  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.457798 \n",
      "\n",
      "loss: 0.424223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.481292 \n",
      "\n",
      "loss: 0.457821  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.549967 \n",
      "\n",
      "loss: 0.592991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.553236 \n",
      "\n",
      "loss: 0.557315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.460513 \n",
      "\n",
      "loss: 0.506826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.741572 \n",
      "\n",
      "loss: 0.791332  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.631431 \n",
      "\n",
      "loss: 0.518945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.911292 \n",
      "\n",
      "loss: 0.802243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.716445 \n",
      "\n",
      "loss: 0.661947  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.484589 \n",
      "\n",
      "loss: 0.426545  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.643197 \n",
      "\n",
      "loss: 0.587249  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.571678 \n",
      "\n",
      "loss: 0.480923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.461511 \n",
      "\n",
      "loss: 0.441614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.586222 \n",
      "\n",
      "loss: 0.609704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.648532 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 58/500\n",
      "--------------------\n",
      "{'hl': [293], 'alpha': 0.002538542953699146, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4696246464483254}\n",
      "loss: 1.248116  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 3.062453 \n",
      "\n",
      "loss: 2.714261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 3.766849 \n",
      "\n",
      "loss: 3.733381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 3.279711 \n",
      "\n",
      "loss: 3.309348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 2.325663 \n",
      "\n",
      "loss: 2.270187  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 2.118895 \n",
      "\n",
      "loss: 2.183029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 4.687761 \n",
      "\n",
      "loss: 4.849574  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.372245 \n",
      "\n",
      "loss: 3.110353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 2.486730 \n",
      "\n",
      "loss: 2.742199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 4.677647 \n",
      "\n",
      "loss: 4.405259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 1.892654 \n",
      "\n",
      "loss: 2.043559  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 1.115281 \n",
      "\n",
      "loss: 1.062384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 2.443339 \n",
      "\n",
      "loss: 1.871380  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 4.363822 \n",
      "\n",
      "loss: 4.159251  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 2.950542 \n",
      "\n",
      "loss: 2.619052  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 5.439265 \n",
      "\n",
      "loss: 5.723471  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 2.906492 \n",
      "\n",
      "loss: 2.784871  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 1.132354 \n",
      "\n",
      "loss: 1.205646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 4.288391 \n",
      "\n",
      "loss: 4.552602  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 2.389276 \n",
      "\n",
      "loss: 2.392365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 5.153797 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 59/500\n",
      "--------------------\n",
      "{'hl': [275], 'alpha': 0.00051793023535997, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.05429043335263408}\n",
      "loss: 1.026619  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.544091 \n",
      "\n",
      "loss: 0.513794  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.506019 \n",
      "\n",
      "loss: 0.533418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.480645 \n",
      "\n",
      "loss: 0.466255  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.475380 \n",
      "\n",
      "loss: 0.459181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.458619 \n",
      "\n",
      "loss: 0.475214  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.443711 \n",
      "\n",
      "loss: 0.444505  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.437846 \n",
      "\n",
      "loss: 0.470249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.437109 \n",
      "\n",
      "loss: 0.442468  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.429573 \n",
      "\n",
      "loss: 0.429909  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.409717 \n",
      "\n",
      "loss: 0.392870  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.403988 \n",
      "\n",
      "loss: 0.401319  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.400883 \n",
      "\n",
      "loss: 0.414567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.411655 \n",
      "\n",
      "loss: 0.383384  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.393948 \n",
      "\n",
      "loss: 0.382041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.389394 \n",
      "\n",
      "loss: 0.417061  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.387712 \n",
      "\n",
      "loss: 0.377335  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.394542 \n",
      "\n",
      "loss: 0.378960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.392921 \n",
      "\n",
      "loss: 0.391186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.381986 \n",
      "\n",
      "loss: 0.414340  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.373329 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 60/500\n",
      "--------------------\n",
      "{'hl': [361, 329], 'alpha': 0.005566414407461407, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.44976241598230865}\n",
      "loss: 1.098896  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 2273.205214 \n",
      "\n",
      "loss: 2768.080566  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 864.607510 \n",
      "\n",
      "loss: 526.469666  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 64.890358 \n",
      "\n",
      "loss: 44.068268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 21.104998 \n",
      "\n",
      "loss: 13.519524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 12.298205 \n",
      "\n",
      "loss: 5.012985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 7.922279 \n",
      "\n",
      "loss: 5.712295  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 12.038580 \n",
      "\n",
      "loss: 11.598742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 4.085571 \n",
      "\n",
      "loss: 8.703967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 1.891050 \n",
      "\n",
      "loss: 1.569721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 2.643105 \n",
      "\n",
      "loss: 2.310738  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.747808 \n",
      "\n",
      "loss: 0.649112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.747981 \n",
      "\n",
      "loss: 1.015674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.825854 \n",
      "\n",
      "loss: 0.680064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.503550 \n",
      "\n",
      "loss: 0.586696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.014376 \n",
      "\n",
      "loss: 0.864569  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.539135 \n",
      "\n",
      "loss: 0.485078  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.497823 \n",
      "\n",
      "loss: 0.367832  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.460570 \n",
      "\n",
      "loss: 0.395736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.457689 \n",
      "\n",
      "loss: 0.404080  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.421958 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 61/500\n",
      "--------------------\n",
      "{'hl': [268], 'alpha': 0.00015050333891418452, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.260008182248436}\n",
      "loss: 0.981113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.964201 \n",
      "\n",
      "loss: 0.934451  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.305129 \n",
      "\n",
      "loss: 1.349220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.635408 \n",
      "\n",
      "loss: 1.616641  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.664239 \n",
      "\n",
      "loss: 0.626368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.728755 \n",
      "\n",
      "loss: 0.750747  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.553987 \n",
      "\n",
      "loss: 0.575722  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.527062 \n",
      "\n",
      "loss: 0.495691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.679616 \n",
      "\n",
      "loss: 0.752133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.779179 \n",
      "\n",
      "loss: 0.768028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.578340 \n",
      "\n",
      "loss: 0.548927  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.784450 \n",
      "\n",
      "loss: 0.796329  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.861875 \n",
      "\n",
      "loss: 0.898203  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.661305 \n",
      "\n",
      "loss: 0.677110  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.670433 \n",
      "\n",
      "loss: 0.729573  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.658189 \n",
      "\n",
      "loss: 0.673235  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.691908 \n",
      "\n",
      "loss: 0.712772  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.523941 \n",
      "\n",
      "loss: 0.528413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.457220 \n",
      "\n",
      "loss: 0.457599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.460336 \n",
      "\n",
      "loss: 0.501031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.509451 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 62/500\n",
      "--------------------\n",
      "{'hl': [711, 694, 209], 'alpha': 0.002863425492818866, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.31161538943220995}\n",
      "loss: 1.083312  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 0.907640 \n",
      "\n",
      "loss: 0.854204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.831059 \n",
      "\n",
      "loss: 0.805964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 0.808655 \n",
      "\n",
      "loss: 0.818630  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.970815 \n",
      "\n",
      "loss: 0.814575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.810666 \n",
      "\n",
      "loss: 0.790430  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.814753 \n",
      "\n",
      "loss: 0.831509  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 0.823402 \n",
      "\n",
      "loss: 0.805151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809267 \n",
      "\n",
      "loss: 0.809469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.810035 \n",
      "\n",
      "loss: 0.823336  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813442 \n",
      "\n",
      "loss: 0.839552  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817779 \n",
      "\n",
      "loss: 0.842592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.823497 \n",
      "\n",
      "loss: 0.824988  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.813409 \n",
      "\n",
      "loss: 0.816591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.813926 \n",
      "\n",
      "loss: 0.842112  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.815673 \n",
      "\n",
      "loss: 0.798676  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820413 \n",
      "\n",
      "loss: 0.793592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.830184 \n",
      "\n",
      "loss: 0.828784  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.812281 \n",
      "\n",
      "loss: 0.800779  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.811690 \n",
      "\n",
      "loss: 0.802845  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.810601 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 63/500\n",
      "--------------------\n",
      "{'hl': [135, 315, 527], 'alpha': 0.0017263889549728464, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.20125995349015655}\n",
      "loss: 1.176389  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.564347 \n",
      "\n",
      "loss: 3.224462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.958468 \n",
      "\n",
      "loss: 7.142617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 9.774865 \n",
      "\n",
      "loss: 9.755859  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.845709 \n",
      "\n",
      "loss: 2.241387  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.662002 \n",
      "\n",
      "loss: 5.257736  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 6.470151 \n",
      "\n",
      "loss: 6.803196  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.986730 \n",
      "\n",
      "loss: 4.032892  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 6.793866 \n",
      "\n",
      "loss: 7.092405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 15.015370 \n",
      "\n",
      "loss: 16.010744  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 5.931490 \n",
      "\n",
      "loss: 5.184987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.368280 \n",
      "\n",
      "loss: 11.424396  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 4.617872 \n",
      "\n",
      "loss: 4.619335  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 10.372346 \n",
      "\n",
      "loss: 10.204866  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 15.608805 \n",
      "\n",
      "loss: 15.633772  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.906969 \n",
      "\n",
      "loss: 5.126688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.620129 \n",
      "\n",
      "loss: 5.987104  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 12.238667 \n",
      "\n",
      "loss: 11.085125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.716117 \n",
      "\n",
      "loss: 1.715228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 5.470768 \n",
      "\n",
      "loss: 5.077998  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 17.920920 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 64/500\n",
      "--------------------\n",
      "{'hl': [575, 138], 'alpha': 0.0005852755367983987, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3077959064840951}\n",
      "loss: 1.201338  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.780807 \n",
      "\n",
      "loss: 0.753164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.702922 \n",
      "\n",
      "loss: 0.705411  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.540710 \n",
      "\n",
      "loss: 0.551238  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.527992 \n",
      "\n",
      "loss: 0.517864  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.510615 \n",
      "\n",
      "loss: 0.469731  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.530540 \n",
      "\n",
      "loss: 0.515233  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.509203 \n",
      "\n",
      "loss: 0.489641  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.533932 \n",
      "\n",
      "loss: 0.519257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.500495 \n",
      "\n",
      "loss: 0.534276  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.483970 \n",
      "\n",
      "loss: 0.474784  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.483358 \n",
      "\n",
      "loss: 0.476409  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.490892 \n",
      "\n",
      "loss: 0.461915  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.528756 \n",
      "\n",
      "loss: 0.541034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.466155 \n",
      "\n",
      "loss: 0.432263  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.482854 \n",
      "\n",
      "loss: 0.476861  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.461655 \n",
      "\n",
      "loss: 0.445303  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.482223 \n",
      "\n",
      "loss: 0.460534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.482375 \n",
      "\n",
      "loss: 0.431110  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.472419 \n",
      "\n",
      "loss: 0.518163  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.472075 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 65/500\n",
      "--------------------\n",
      "{'hl': [423, 569], 'alpha': 0.21622239683688615, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.1051703241728327}\n",
      "loss: 1.095276  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 167.864558 \n",
      "\n",
      "loss: 157.230789  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 5.181940 \n",
      "\n",
      "loss: 4.882016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.560024 \n",
      "\n",
      "loss: 0.564541  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.548071 \n",
      "\n",
      "loss: 0.535959  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.559055 \n",
      "\n",
      "loss: 0.560074  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.606146 \n",
      "\n",
      "loss: 0.578166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.601545 \n",
      "\n",
      "loss: 0.585026  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.591510 \n",
      "\n",
      "loss: 0.602782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.608457 \n",
      "\n",
      "loss: 0.602348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.615251 \n",
      "\n",
      "loss: 0.610195  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.613510 \n",
      "\n",
      "loss: 0.608777  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.618565 \n",
      "\n",
      "loss: 0.613743  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.625961 \n",
      "\n",
      "loss: 0.621846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.625841 \n",
      "\n",
      "loss: 0.622393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.612485 \n",
      "\n",
      "loss: 0.626438  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.612602 \n",
      "\n",
      "loss: 0.607843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.612210 \n",
      "\n",
      "loss: 0.579423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.627476 \n",
      "\n",
      "loss: 0.647503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.616558 \n",
      "\n",
      "loss: 0.641937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.626540 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 66/500\n",
      "--------------------\n",
      "{'hl': [629, 678, 337], 'alpha': 0.007243571661245992, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.2556358810376061}\n",
      "loss: 1.146971  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.827568 \n",
      "\n",
      "loss: 0.834944  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.838753 \n",
      "\n",
      "loss: 0.820407  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.816848 \n",
      "\n",
      "loss: 0.841935  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.812556 \n",
      "\n",
      "loss: 0.818955  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.808861 \n",
      "\n",
      "loss: 0.817432  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.816335 \n",
      "\n",
      "loss: 0.817118  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.840547 \n",
      "\n",
      "loss: 0.836208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.816379 \n",
      "\n",
      "loss: 0.815607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.834804 \n",
      "\n",
      "loss: 0.839134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.808395 \n",
      "\n",
      "loss: 0.813636  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819214 \n",
      "\n",
      "loss: 0.798943  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.865940 \n",
      "\n",
      "loss: 0.864377  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815333 \n",
      "\n",
      "loss: 0.819614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.817918 \n",
      "\n",
      "loss: 0.821158  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.842938 \n",
      "\n",
      "loss: 0.807358  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.821740 \n",
      "\n",
      "loss: 0.813204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.829873 \n",
      "\n",
      "loss: 0.851963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.828050 \n",
      "\n",
      "loss: 0.841841  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.816846 \n",
      "\n",
      "loss: 0.831602  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.839398 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 67/500\n",
      "--------------------\n",
      "{'hl': [181, 682, 94], 'alpha': 0.001365040761275302, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4092298899218785}\n",
      "loss: 1.081718  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.458327 \n",
      "\n",
      "loss: 0.406692  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.409439 \n",
      "\n",
      "loss: 0.402834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.379997 \n",
      "\n",
      "loss: 0.358019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.376235 \n",
      "\n",
      "loss: 0.350393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.353392 \n",
      "\n",
      "loss: 0.379505  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.385151 \n",
      "\n",
      "loss: 0.431825  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.375416 \n",
      "\n",
      "loss: 0.350075  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.356099 \n",
      "\n",
      "loss: 0.354537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.348805 \n",
      "\n",
      "loss: 0.369869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.311976 \n",
      "\n",
      "loss: 0.296090  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.324889 \n",
      "\n",
      "loss: 0.318352  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.325126 \n",
      "\n",
      "loss: 0.352569  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.337649 \n",
      "\n",
      "loss: 0.353555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.366500 \n",
      "\n",
      "loss: 0.361622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.291451 \n",
      "\n",
      "loss: 0.309897  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.325672 \n",
      "\n",
      "loss: 0.334936  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.302332 \n",
      "\n",
      "loss: 0.276167  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.323803 \n",
      "\n",
      "loss: 0.297085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.304424 \n",
      "\n",
      "loss: 0.299416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.275917 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 68/500\n",
      "--------------------\n",
      "{'hl': [696], 'alpha': 0.0017445276498531924, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.012310251324640488}\n",
      "loss: 1.097062  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.651518 \n",
      "\n",
      "loss: 0.639709  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.595021 \n",
      "\n",
      "loss: 0.568923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.558667 \n",
      "\n",
      "loss: 0.555581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.536260 \n",
      "\n",
      "loss: 0.546826  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.542927 \n",
      "\n",
      "loss: 0.538459  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.526116 \n",
      "\n",
      "loss: 0.513588  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.503837 \n",
      "\n",
      "loss: 0.512737  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.513392 \n",
      "\n",
      "loss: 0.510449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.499113 \n",
      "\n",
      "loss: 0.479868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.495759 \n",
      "\n",
      "loss: 0.497982  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.491383 \n",
      "\n",
      "loss: 0.488702  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.499230 \n",
      "\n",
      "loss: 0.514983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.493455 \n",
      "\n",
      "loss: 0.486985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.480692 \n",
      "\n",
      "loss: 0.480581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.472059 \n",
      "\n",
      "loss: 0.515995  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.476896 \n",
      "\n",
      "loss: 0.459366  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.479026 \n",
      "\n",
      "loss: 0.488014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.488383 \n",
      "\n",
      "loss: 0.485452  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.467184 \n",
      "\n",
      "loss: 0.467659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.461007 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 69/500\n",
      "--------------------\n",
      "{'hl': [494], 'alpha': 0.0278673641223968, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.2072790613977599}\n",
      "loss: 1.121409  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 13.058540 \n",
      "\n",
      "loss: 14.052334  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 12.490014 \n",
      "\n",
      "loss: 11.313914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 1.202531 \n",
      "\n",
      "loss: 1.314347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.493809 \n",
      "\n",
      "loss: 0.596410  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.456765 \n",
      "\n",
      "loss: 0.471414  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.469692 \n",
      "\n",
      "loss: 0.461605  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.466928 \n",
      "\n",
      "loss: 0.468792  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.448172 \n",
      "\n",
      "loss: 0.445717  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.445573 \n",
      "\n",
      "loss: 0.382584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.460427 \n",
      "\n",
      "loss: 0.480732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.444319 \n",
      "\n",
      "loss: 0.439467  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.452798 \n",
      "\n",
      "loss: 0.468455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.454286 \n",
      "\n",
      "loss: 0.428864  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.453087 \n",
      "\n",
      "loss: 0.490769  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.481122 \n",
      "\n",
      "loss: 0.464873  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.459573 \n",
      "\n",
      "loss: 0.461338  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.450848 \n",
      "\n",
      "loss: 0.445051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.457548 \n",
      "\n",
      "loss: 0.481276  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.479649 \n",
      "\n",
      "loss: 0.449045  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.450738 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 70/500\n",
      "--------------------\n",
      "{'hl': [597, 207, 401], 'alpha': 0.009495299680809186, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3280633997547809}\n",
      "loss: 1.139820  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.477149 \n",
      "\n",
      "loss: 0.452042  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.470245 \n",
      "\n",
      "loss: 0.428869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.479769 \n",
      "\n",
      "loss: 0.463853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.443483 \n",
      "\n",
      "loss: 0.472665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.464055 \n",
      "\n",
      "loss: 0.440462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.449298 \n",
      "\n",
      "loss: 0.466218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.452849 \n",
      "\n",
      "loss: 0.422249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.428383 \n",
      "\n",
      "loss: 0.410797  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.441003 \n",
      "\n",
      "loss: 0.455678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.412787 \n",
      "\n",
      "loss: 0.417120  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.416425 \n",
      "\n",
      "loss: 0.412742  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.461843 \n",
      "\n",
      "loss: 0.461027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.419752 \n",
      "\n",
      "loss: 0.391214  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.454263 \n",
      "\n",
      "loss: 0.469647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.402932 \n",
      "\n",
      "loss: 0.408701  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.417805 \n",
      "\n",
      "loss: 0.419072  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.442970 \n",
      "\n",
      "loss: 0.427706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.400692 \n",
      "\n",
      "loss: 0.364239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.413894 \n",
      "\n",
      "loss: 0.431211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.420390 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 71/500\n",
      "--------------------\n",
      "{'hl': [117], 'alpha': 0.12992167980004077, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.4020745171009542}\n",
      "loss: 1.161217  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.556936 \n",
      "\n",
      "loss: 0.546023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.552976 \n",
      "\n",
      "loss: 0.531757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.544843 \n",
      "\n",
      "loss: 0.547245  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.545010 \n",
      "\n",
      "loss: 0.537439  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.549119 \n",
      "\n",
      "loss: 0.539186  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.539775 \n",
      "\n",
      "loss: 0.534747  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.558449 \n",
      "\n",
      "loss: 0.567931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.549943 \n",
      "\n",
      "loss: 0.536470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.537451 \n",
      "\n",
      "loss: 0.549627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.557023 \n",
      "\n",
      "loss: 0.528954  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.548445 \n",
      "\n",
      "loss: 0.533826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.553262 \n",
      "\n",
      "loss: 0.557539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.544365 \n",
      "\n",
      "loss: 0.538923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.536939 \n",
      "\n",
      "loss: 0.580619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.555869 \n",
      "\n",
      "loss: 0.573858  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.544171 \n",
      "\n",
      "loss: 0.544954  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.553821 \n",
      "\n",
      "loss: 0.538614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.554111 \n",
      "\n",
      "loss: 0.572574  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.545808 \n",
      "\n",
      "loss: 0.528555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.550226 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 72/500\n",
      "--------------------\n",
      "{'hl': [538, 483, 59], 'alpha': 0.016967707781364503, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.06675621886795874}\n",
      "loss: 1.144448  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.754705 \n",
      "\n",
      "loss: 0.771240  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.837608 \n",
      "\n",
      "loss: 0.831916  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.667905 \n",
      "\n",
      "loss: 0.632972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.631266 \n",
      "\n",
      "loss: 0.646309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.510576 \n",
      "\n",
      "loss: 0.466163  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.428305 \n",
      "\n",
      "loss: 0.412552  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.454038 \n",
      "\n",
      "loss: 0.412059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 0.809424 \n",
      "\n",
      "loss: 0.803027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.820064 \n",
      "\n",
      "loss: 0.818700  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.455829 \n",
      "\n",
      "loss: 0.438729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.462978 \n",
      "\n",
      "loss: 0.522550  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.440600 \n",
      "\n",
      "loss: 0.455885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.464202 \n",
      "\n",
      "loss: 0.423165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.443597 \n",
      "\n",
      "loss: 0.412339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.457013 \n",
      "\n",
      "loss: 0.459485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 7.302187 \n",
      "\n",
      "loss: 7.155592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.832570 \n",
      "\n",
      "loss: 0.833017  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.827314 \n",
      "\n",
      "loss: 0.813306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.834315 \n",
      "\n",
      "loss: 0.804794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.553290 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 73/500\n",
      "--------------------\n",
      "{'hl': [691, 551], 'alpha': 0.8944783065857831, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.30636489614860524}\n",
      "loss: 1.130437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 971.076762 \n",
      "\n",
      "loss: 1053.960449  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 532.977871 \n",
      "\n",
      "loss: 538.327087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 44.352447 \n",
      "\n",
      "loss: 54.280647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.941164 \n",
      "\n",
      "loss: 1.531196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 0.720787 \n",
      "\n",
      "loss: 0.725773  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.767118 \n",
      "\n",
      "loss: 0.778984  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.814035 \n",
      "\n",
      "loss: 0.819779  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.856000 \n",
      "\n",
      "loss: 0.861331  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.935213 \n",
      "\n",
      "loss: 0.938722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.977846 \n",
      "\n",
      "loss: 0.980242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.992187 \n",
      "\n",
      "loss: 0.994453  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.995425 \n",
      "\n",
      "loss: 0.996113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.000755 \n",
      "\n",
      "loss: 0.999248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.998956 \n",
      "\n",
      "loss: 0.998578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.001248 \n",
      "\n",
      "loss: 1.004709  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.000315 \n",
      "\n",
      "loss: 0.999338  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.006139 \n",
      "\n",
      "loss: 1.006847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.000411 \n",
      "\n",
      "loss: 1.001680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.000653 \n",
      "\n",
      "loss: 1.000436  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.000506 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 74/500\n",
      "--------------------\n",
      "{'hl': [524, 444, 569], 'alpha': 0.006076513237068075, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.22508987164772937}\n",
      "loss: 1.075924  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 6.256984 \n",
      "\n",
      "loss: 6.749233  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 5.940269 \n",
      "\n",
      "loss: 6.489088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 3.576223 \n",
      "\n",
      "loss: 3.756665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 3.547282 \n",
      "\n",
      "loss: 3.748682  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 30.6%, Avg loss: 16.554227 \n",
      "\n",
      "loss: 16.186392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 9.335551 \n",
      "\n",
      "loss: 10.115413  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 13.668643 \n",
      "\n",
      "loss: 12.851866  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 6.919229 \n",
      "\n",
      "loss: 6.731920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 2.744912 \n",
      "\n",
      "loss: 2.649109  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 6.694006 \n",
      "\n",
      "loss: 6.480963  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 8.077619 \n",
      "\n",
      "loss: 8.191634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 8.552435 \n",
      "\n",
      "loss: 9.088594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 3.389156 \n",
      "\n",
      "loss: 3.364711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.648956 \n",
      "\n",
      "loss: 2.390275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.4%, Avg loss: 7.209067 \n",
      "\n",
      "loss: 6.683873  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 6.354494 \n",
      "\n",
      "loss: 6.041910  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 4.615246 \n",
      "\n",
      "loss: 4.735107  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 6.433972 \n",
      "\n",
      "loss: 6.299204  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 6.729124 \n",
      "\n",
      "loss: 7.143344  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 6.779729 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 75/500\n",
      "--------------------\n",
      "{'hl': [660], 'alpha': 0.0012860131591111031, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.13737126371407737}\n",
      "loss: 1.330164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.857001 \n",
      "\n",
      "loss: 0.876550  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.294752 \n",
      "\n",
      "loss: 1.274496  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.858739 \n",
      "\n",
      "loss: 0.772284  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.968910 \n",
      "\n",
      "loss: 1.041729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.963904 \n",
      "\n",
      "loss: 0.991662  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.972991 \n",
      "\n",
      "loss: 0.909363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 1.155194 \n",
      "\n",
      "loss: 1.045454  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.273264 \n",
      "\n",
      "loss: 1.265010  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 1.642888 \n",
      "\n",
      "loss: 1.792369  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.608044 \n",
      "\n",
      "loss: 0.599055  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.716010 \n",
      "\n",
      "loss: 0.715606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.638078 \n",
      "\n",
      "loss: 0.651391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 1.024320 \n",
      "\n",
      "loss: 1.022395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.620232 \n",
      "\n",
      "loss: 0.674588  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.591374 \n",
      "\n",
      "loss: 0.632961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.208686 \n",
      "\n",
      "loss: 1.247598  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.759113 \n",
      "\n",
      "loss: 0.688771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.581607 \n",
      "\n",
      "loss: 0.605668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.717223 \n",
      "\n",
      "loss: 0.799424  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.676211 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 76/500\n",
      "--------------------\n",
      "{'hl': [300], 'alpha': 0.0008669105976319265, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.4465241137118794}\n",
      "loss: 1.170949  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 50.065208 \n",
      "\n",
      "loss: 53.993553  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 11.725404 \n",
      "\n",
      "loss: 11.971500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 4.450112 \n",
      "\n",
      "loss: 5.851233  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.962925 \n",
      "\n",
      "loss: 1.347751  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.902088 \n",
      "\n",
      "loss: 0.807984  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.444001 \n",
      "\n",
      "loss: 0.498815  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.396558 \n",
      "\n",
      "loss: 0.382278  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.380665 \n",
      "\n",
      "loss: 0.385655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.372949 \n",
      "\n",
      "loss: 0.394562  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.388986 \n",
      "\n",
      "loss: 0.363011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.389182 \n",
      "\n",
      "loss: 0.354234  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.413297 \n",
      "\n",
      "loss: 0.405349  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.409751 \n",
      "\n",
      "loss: 0.362179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.407417 \n",
      "\n",
      "loss: 0.397853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.387892 \n",
      "\n",
      "loss: 0.436588  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.390042 \n",
      "\n",
      "loss: 0.374247  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.443729 \n",
      "\n",
      "loss: 0.421300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.407262 \n",
      "\n",
      "loss: 0.386126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.425463 \n",
      "\n",
      "loss: 0.416040  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.384252 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 77/500\n",
      "--------------------\n",
      "{'hl': [149], 'alpha': 0.00040116462724591934, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.35323892893310666}\n",
      "loss: 1.146394  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.723860 \n",
      "\n",
      "loss: 0.692493  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.597369 \n",
      "\n",
      "loss: 0.597645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.527125 \n",
      "\n",
      "loss: 0.536038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.596081 \n",
      "\n",
      "loss: 0.642231  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510886 \n",
      "\n",
      "loss: 0.497443  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.508389 \n",
      "\n",
      "loss: 0.577533  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.552600 \n",
      "\n",
      "loss: 0.584203  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.474369 \n",
      "\n",
      "loss: 0.496300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.523439 \n",
      "\n",
      "loss: 0.550745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.447910 \n",
      "\n",
      "loss: 0.432821  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.442064 \n",
      "\n",
      "loss: 0.393861  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.504789 \n",
      "\n",
      "loss: 0.482885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.544346 \n",
      "\n",
      "loss: 0.546717  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.444169 \n",
      "\n",
      "loss: 0.410828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.481170 \n",
      "\n",
      "loss: 0.517278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.474610 \n",
      "\n",
      "loss: 0.485443  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.484715 \n",
      "\n",
      "loss: 0.468926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.443792 \n",
      "\n",
      "loss: 0.424617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.438749 \n",
      "\n",
      "loss: 0.460292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.427670 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 78/500\n",
      "--------------------\n",
      "{'hl': [432], 'alpha': 0.004269701152294204, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.0312266287207343}\n",
      "loss: 1.302381  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.611402 \n",
      "\n",
      "loss: 0.623562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.498020 \n",
      "\n",
      "loss: 0.475480  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.519262 \n",
      "\n",
      "loss: 0.507565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.503334 \n",
      "\n",
      "loss: 0.487128  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.478471 \n",
      "\n",
      "loss: 0.473000  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.464014 \n",
      "\n",
      "loss: 0.486083  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.481150 \n",
      "\n",
      "loss: 0.482581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.474008 \n",
      "\n",
      "loss: 0.490323  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.456731 \n",
      "\n",
      "loss: 0.439459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.466592 \n",
      "\n",
      "loss: 0.431270  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.488589 \n",
      "\n",
      "loss: 0.463908  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.462418 \n",
      "\n",
      "loss: 0.435388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.436299 \n",
      "\n",
      "loss: 0.407867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.444370 \n",
      "\n",
      "loss: 0.468197  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.450182 \n",
      "\n",
      "loss: 0.453206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.424809 \n",
      "\n",
      "loss: 0.383498  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.444537 \n",
      "\n",
      "loss: 0.428152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.466703 \n",
      "\n",
      "loss: 0.472914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.494791 \n",
      "\n",
      "loss: 0.517819  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.426494 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 79/500\n",
      "--------------------\n",
      "{'hl': [406, 606], 'alpha': 0.6084825587823092, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.2385421683054227}\n",
      "loss: 1.069082  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 585.414029 \n",
      "\n",
      "loss: 617.976868  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 332.949365 \n",
      "\n",
      "loss: 377.428223  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 18.773934 \n",
      "\n",
      "loss: 19.115564  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.014628 \n",
      "\n",
      "loss: 2.136623  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.674974 \n",
      "\n",
      "loss: 0.661058  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.825965 \n",
      "\n",
      "loss: 0.829038  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.891510 \n",
      "\n",
      "loss: 0.891786  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.943316 \n",
      "\n",
      "loss: 0.950185  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.971714 \n",
      "\n",
      "loss: 0.971463  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.972337 \n",
      "\n",
      "loss: 0.969407  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.980386 \n",
      "\n",
      "loss: 0.983368  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.977466 \n",
      "\n",
      "loss: 0.975585  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.970768 \n",
      "\n",
      "loss: 0.982079  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.972437 \n",
      "\n",
      "loss: 0.972750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.973143 \n",
      "\n",
      "loss: 0.974094  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.973896 \n",
      "\n",
      "loss: 0.972769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.976717 \n",
      "\n",
      "loss: 0.978492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.974928 \n",
      "\n",
      "loss: 0.974127  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.977238 \n",
      "\n",
      "loss: 0.976649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.978610 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 80/500\n",
      "--------------------\n",
      "{'hl': [313, 407], 'alpha': 0.25929360288039055, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.2441659158273702}\n",
      "loss: 1.107986  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.736002 \n",
      "\n",
      "loss: 1.707747  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.652442 \n",
      "\n",
      "loss: 2.761918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.407835 \n",
      "\n",
      "loss: 2.276651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.467817 \n",
      "\n",
      "loss: 2.466140  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.558720 \n",
      "\n",
      "loss: 1.604967  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.374329 \n",
      "\n",
      "loss: 2.328596  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.847437 \n",
      "\n",
      "loss: 1.903484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.522875 \n",
      "\n",
      "loss: 2.412701  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.457979 \n",
      "\n",
      "loss: 1.387856  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.293300 \n",
      "\n",
      "loss: 2.143652  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.849409 \n",
      "\n",
      "loss: 1.904452  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.263626 \n",
      "\n",
      "loss: 2.073917  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.569805 \n",
      "\n",
      "loss: 1.559671  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.369166 \n",
      "\n",
      "loss: 2.427928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.648818 \n",
      "\n",
      "loss: 1.613553  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.767430 \n",
      "\n",
      "loss: 2.824136  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.537156 \n",
      "\n",
      "loss: 1.565555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.190293 \n",
      "\n",
      "loss: 2.155097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.624373 \n",
      "\n",
      "loss: 1.551310  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.469865 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 81/500\n",
      "--------------------\n",
      "{'hl': [454, 505], 'alpha': 0.00013064695131338397, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.36211827067588165}\n",
      "loss: 1.163909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 1014.811754 \n",
      "\n",
      "loss: 852.556458  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 164.730142 \n",
      "\n",
      "loss: 166.160736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 71.189480 \n",
      "\n",
      "loss: 74.706146  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 71.698284 \n",
      "\n",
      "loss: 68.546837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 7.353812 \n",
      "\n",
      "loss: 6.827957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 20.285996 \n",
      "\n",
      "loss: 16.118296  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 3.249719 \n",
      "\n",
      "loss: 3.800216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 1.392981 \n",
      "\n",
      "loss: 1.123915  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 1.467835 \n",
      "\n",
      "loss: 1.839323  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 2.289354 \n",
      "\n",
      "loss: 2.328351  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 1.249270 \n",
      "\n",
      "loss: 0.749227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 1.331180 \n",
      "\n",
      "loss: 1.595115  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 1.813900 \n",
      "\n",
      "loss: 1.463041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 2.087862 \n",
      "\n",
      "loss: 1.996704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 1.177544 \n",
      "\n",
      "loss: 1.038381  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 1.265836 \n",
      "\n",
      "loss: 1.072650  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.852532 \n",
      "\n",
      "loss: 0.727156  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.945577 \n",
      "\n",
      "loss: 0.900203  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.842793 \n",
      "\n",
      "loss: 1.008276  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.623007 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 82/500\n",
      "--------------------\n",
      "{'hl': [138, 645], 'alpha': 0.013692871044938467, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.04206533633478391}\n",
      "loss: 1.101078  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.180895 \n",
      "\n",
      "loss: 1.228867  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.568439 \n",
      "\n",
      "loss: 1.505218  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.325214 \n",
      "\n",
      "loss: 1.309331  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.330416 \n",
      "\n",
      "loss: 1.366047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.173015 \n",
      "\n",
      "loss: 1.160366  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.018489 \n",
      "\n",
      "loss: 1.044112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.130105 \n",
      "\n",
      "loss: 1.147298  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.921994 \n",
      "\n",
      "loss: 0.943328  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.708890 \n",
      "\n",
      "loss: 0.739494  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.584155 \n",
      "\n",
      "loss: 0.597118  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.581968 \n",
      "\n",
      "loss: 0.593079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.596073 \n",
      "\n",
      "loss: 0.582235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.601711 \n",
      "\n",
      "loss: 0.611793  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.560350 \n",
      "\n",
      "loss: 0.564176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.546033 \n",
      "\n",
      "loss: 0.540643  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.542432 \n",
      "\n",
      "loss: 0.546036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.556505 \n",
      "\n",
      "loss: 0.559558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.542953 \n",
      "\n",
      "loss: 0.541165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.542840 \n",
      "\n",
      "loss: 0.531833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.540542 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 83/500\n",
      "--------------------\n",
      "{'hl': [146, 480], 'alpha': 0.000533231879562746, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.16374359820417295}\n",
      "loss: 1.093929  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 81.030415 \n",
      "\n",
      "loss: 44.516800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 22.517715 \n",
      "\n",
      "loss: 22.256199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 3.238288 \n",
      "\n",
      "loss: 3.720943  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 2.039924 \n",
      "\n",
      "loss: 2.228536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.594895 \n",
      "\n",
      "loss: 0.620042  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.925101 \n",
      "\n",
      "loss: 0.753377  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 1.025441 \n",
      "\n",
      "loss: 1.413559  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.464418 \n",
      "\n",
      "loss: 0.385794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.473516 \n",
      "\n",
      "loss: 0.531299  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.401375 \n",
      "\n",
      "loss: 0.451041  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.501153 \n",
      "\n",
      "loss: 0.526941  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382956 \n",
      "\n",
      "loss: 0.344626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.591985 \n",
      "\n",
      "loss: 0.541651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.396355 \n",
      "\n",
      "loss: 0.346569  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.374738 \n",
      "\n",
      "loss: 0.409081  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346800 \n",
      "\n",
      "loss: 0.316386  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 1.080266 \n",
      "\n",
      "loss: 0.941560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.378201 \n",
      "\n",
      "loss: 0.373672  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.383226 \n",
      "\n",
      "loss: 0.365064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.347204 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 84/500\n",
      "--------------------\n",
      "{'hl': [342, 353], 'alpha': 0.1108967532962774, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.37602971079503694}\n",
      "loss: 1.061123  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 9.367207 \n",
      "\n",
      "loss: 9.350953  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 7.700053 \n",
      "\n",
      "loss: 8.246501  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 10.794993 \n",
      "\n",
      "loss: 10.631937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 17.878897 \n",
      "\n",
      "loss: 18.264753  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.652500 \n",
      "\n",
      "loss: 4.752754  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 6.362415 \n",
      "\n",
      "loss: 6.313075  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 11.235759 \n",
      "\n",
      "loss: 10.541963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 3.309331 \n",
      "\n",
      "loss: 3.144461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 12.981507 \n",
      "\n",
      "loss: 13.573439  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 31.234697 \n",
      "\n",
      "loss: 30.203440  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 18.242801 \n",
      "\n",
      "loss: 17.154676  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.561031 \n",
      "\n",
      "loss: 7.893349  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.299705 \n",
      "\n",
      "loss: 2.471425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.616719 \n",
      "\n",
      "loss: 6.691410  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 34.773727 \n",
      "\n",
      "loss: 35.684658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 14.312624 \n",
      "\n",
      "loss: 13.620033  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.619999 \n",
      "\n",
      "loss: 7.656219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 3.653222 \n",
      "\n",
      "loss: 3.378230  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 19.012246 \n",
      "\n",
      "loss: 18.648134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 18.622767 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 85/500\n",
      "--------------------\n",
      "{'hl': [266, 91], 'alpha': 0.007607243973944348, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.11218866064330212}\n",
      "loss: 1.093112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 9.269480 \n",
      "\n",
      "loss: 9.359701  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 3.169434 \n",
      "\n",
      "loss: 3.127826  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 1.040443 \n",
      "\n",
      "loss: 1.219449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.432544 \n",
      "\n",
      "loss: 0.401215  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.376509 \n",
      "\n",
      "loss: 0.415167  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.405062 \n",
      "\n",
      "loss: 0.372385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.389182 \n",
      "\n",
      "loss: 0.342161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.381106 \n",
      "\n",
      "loss: 0.350373  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.390497 \n",
      "\n",
      "loss: 0.355747  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.398089 \n",
      "\n",
      "loss: 0.342965  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.412548 \n",
      "\n",
      "loss: 0.432840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.439249 \n",
      "\n",
      "loss: 0.410159  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.414707 \n",
      "\n",
      "loss: 0.385252  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.398403 \n",
      "\n",
      "loss: 0.398902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.389773 \n",
      "\n",
      "loss: 0.406006  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.404516 \n",
      "\n",
      "loss: 0.400507  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.402288 \n",
      "\n",
      "loss: 0.394586  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.395587 \n",
      "\n",
      "loss: 0.364114  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.420390 \n",
      "\n",
      "loss: 0.420808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.383125 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 86/500\n",
      "--------------------\n",
      "{'hl': [675], 'alpha': 0.00014488804423694272, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.0997604051130302}\n",
      "loss: 1.105078  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.490402 \n",
      "\n",
      "loss: 0.496100  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.462459 \n",
      "\n",
      "loss: 0.429680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.435805 \n",
      "\n",
      "loss: 0.459452  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.415816 \n",
      "\n",
      "loss: 0.451706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.410580 \n",
      "\n",
      "loss: 0.408570  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.395306 \n",
      "\n",
      "loss: 0.400798  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.400445 \n",
      "\n",
      "loss: 0.415689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.383644 \n",
      "\n",
      "loss: 0.379105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.385906 \n",
      "\n",
      "loss: 0.422774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.368988 \n",
      "\n",
      "loss: 0.397380  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.365559 \n",
      "\n",
      "loss: 0.359662  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.375471 \n",
      "\n",
      "loss: 0.329877  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.368730 \n",
      "\n",
      "loss: 0.382120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.373200 \n",
      "\n",
      "loss: 0.397354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.359675 \n",
      "\n",
      "loss: 0.349594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.361837 \n",
      "\n",
      "loss: 0.330223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355868 \n",
      "\n",
      "loss: 0.351291  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.350405 \n",
      "\n",
      "loss: 0.324692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.353462 \n",
      "\n",
      "loss: 0.351566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.329381 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 87/500\n",
      "--------------------\n",
      "{'hl': [644], 'alpha': 0.0004069390652266971, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.33476247642549334}\n",
      "loss: 1.056816  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 4.425655 \n",
      "\n",
      "loss: 4.086833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 3.536963 \n",
      "\n",
      "loss: 3.006996  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 6.381461 \n",
      "\n",
      "loss: 6.267417  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 2.402684 \n",
      "\n",
      "loss: 2.542946  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 3.424444 \n",
      "\n",
      "loss: 3.631543  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 3.660676 \n",
      "\n",
      "loss: 3.323329  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 3.978502 \n",
      "\n",
      "loss: 4.328135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 3.457941 \n",
      "\n",
      "loss: 3.500658  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 5.768746 \n",
      "\n",
      "loss: 5.438668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.458123 \n",
      "\n",
      "loss: 2.277085  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 2.812136 \n",
      "\n",
      "loss: 2.623348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 4.043279 \n",
      "\n",
      "loss: 4.326105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 3.508462 \n",
      "\n",
      "loss: 3.265868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 2.801478 \n",
      "\n",
      "loss: 2.750351  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 2.146248 \n",
      "\n",
      "loss: 2.245208  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 2.856068 \n",
      "\n",
      "loss: 2.641011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 4.297069 \n",
      "\n",
      "loss: 3.823560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 4.730747 \n",
      "\n",
      "loss: 4.891942  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 6.451516 \n",
      "\n",
      "loss: 5.682449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 5.654130 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 88/500\n",
      "--------------------\n",
      "{'hl': [231, 484, 270], 'alpha': 0.11684022736719947, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3889181638990988}\n",
      "loss: 1.067932  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.557608 \n",
      "\n",
      "loss: 0.537727  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.558078 \n",
      "\n",
      "loss: 0.537875  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.546391 \n",
      "\n",
      "loss: 0.509180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.541473 \n",
      "\n",
      "loss: 0.577874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.550693 \n",
      "\n",
      "loss: 0.564652  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.555020 \n",
      "\n",
      "loss: 0.575967  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.563735 \n",
      "\n",
      "loss: 0.578721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.552975 \n",
      "\n",
      "loss: 0.538919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.555377 \n",
      "\n",
      "loss: 0.475663  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.560525 \n",
      "\n",
      "loss: 0.549014  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.549105 \n",
      "\n",
      "loss: 0.565988  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.547257 \n",
      "\n",
      "loss: 0.535447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.554883 \n",
      "\n",
      "loss: 0.546100  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.550603 \n",
      "\n",
      "loss: 0.578884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.556325 \n",
      "\n",
      "loss: 0.547924  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.553788 \n",
      "\n",
      "loss: 0.569302  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.548830 \n",
      "\n",
      "loss: 0.533413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.555358 \n",
      "\n",
      "loss: 0.555838  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.548002 \n",
      "\n",
      "loss: 0.545281  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.555986 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 89/500\n",
      "--------------------\n",
      "{'hl': [326], 'alpha': 0.00027064187815264556, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.2879407845333658}\n",
      "loss: 1.180224  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 36.847007 \n",
      "\n",
      "loss: 31.392954  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 7.501611 \n",
      "\n",
      "loss: 5.809904  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 2.335692 \n",
      "\n",
      "loss: 2.642072  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 1.036168 \n",
      "\n",
      "loss: 0.915929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.946417 \n",
      "\n",
      "loss: 0.711241  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.460197 \n",
      "\n",
      "loss: 0.524003  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.374313 \n",
      "\n",
      "loss: 0.309495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.439892 \n",
      "\n",
      "loss: 0.397432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.371238 \n",
      "\n",
      "loss: 0.349265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.351866 \n",
      "\n",
      "loss: 0.332110  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.480191 \n",
      "\n",
      "loss: 0.376943  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.400427 \n",
      "\n",
      "loss: 0.313365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.359331 \n",
      "\n",
      "loss: 0.368141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.353655 \n",
      "\n",
      "loss: 0.322057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.341107 \n",
      "\n",
      "loss: 0.313735  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.363437 \n",
      "\n",
      "loss: 0.367115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.368973 \n",
      "\n",
      "loss: 0.318835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.348048 \n",
      "\n",
      "loss: 0.290027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.357159 \n",
      "\n",
      "loss: 0.292409  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.340165 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 90/500\n",
      "--------------------\n",
      "{'hl': [414, 211], 'alpha': 0.00020136589251751541, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3486267819476365}\n",
      "loss: 1.120752  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.468440 \n",
      "\n",
      "loss: 0.458623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.459122 \n",
      "\n",
      "loss: 0.463474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.441551 \n",
      "\n",
      "loss: 0.442713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.427694 \n",
      "\n",
      "loss: 0.421738  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.433583 \n",
      "\n",
      "loss: 0.405546  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.412541 \n",
      "\n",
      "loss: 0.396293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.426972 \n",
      "\n",
      "loss: 0.402237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.390410 \n",
      "\n",
      "loss: 0.403225  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.380911 \n",
      "\n",
      "loss: 0.353023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.396325 \n",
      "\n",
      "loss: 0.401514  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.466564 \n",
      "\n",
      "loss: 0.422174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.383425 \n",
      "\n",
      "loss: 0.371004  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.366262 \n",
      "\n",
      "loss: 0.378165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.362343 \n",
      "\n",
      "loss: 0.369687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.374829 \n",
      "\n",
      "loss: 0.381875  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.347056 \n",
      "\n",
      "loss: 0.353649  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.374499 \n",
      "\n",
      "loss: 0.363096  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.340912 \n",
      "\n",
      "loss: 0.324034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.355646 \n",
      "\n",
      "loss: 0.343899  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.326435 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 91/500\n",
      "--------------------\n",
      "{'hl': [708, 622], 'alpha': 0.1667676675208129, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.2664193481307191}\n",
      "loss: 1.098968  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 595.908949 \n",
      "\n",
      "loss: 469.008118  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1071.844021 \n",
      "\n",
      "loss: 1060.883911  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 125.952381 \n",
      "\n",
      "loss: 139.740707  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 69.986755 \n",
      "\n",
      "loss: 71.346237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 111.113538 \n",
      "\n",
      "loss: 102.119957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 11.741965 \n",
      "\n",
      "loss: 10.783246  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.161066 \n",
      "\n",
      "loss: 2.105041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.514970 \n",
      "\n",
      "loss: 0.555431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.443655 \n",
      "\n",
      "loss: 0.510325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.449504 \n",
      "\n",
      "loss: 0.447509  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.454409 \n",
      "\n",
      "loss: 0.504105  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.453137 \n",
      "\n",
      "loss: 0.515379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.446224 \n",
      "\n",
      "loss: 0.407091  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.460617 \n",
      "\n",
      "loss: 0.422388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.475850 \n",
      "\n",
      "loss: 0.483647  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.457505 \n",
      "\n",
      "loss: 0.489861  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.484708 \n",
      "\n",
      "loss: 0.498650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.465261 \n",
      "\n",
      "loss: 0.465472  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.499030 \n",
      "\n",
      "loss: 0.504221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.469942 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 92/500\n",
      "--------------------\n",
      "{'hl': [387, 78, 526], 'alpha': 0.03892001654599977, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.41118322595322004}\n",
      "loss: 1.076407  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 8.268975 \n",
      "\n",
      "loss: 8.842528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 25.884454 \n",
      "\n",
      "loss: 25.751539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 8.977051 \n",
      "\n",
      "loss: 9.258839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 9.316528 \n",
      "\n",
      "loss: 8.136041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 8.482664 \n",
      "\n",
      "loss: 2.935344  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 15.075526 \n",
      "\n",
      "loss: 14.812541  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 8.266093 \n",
      "\n",
      "loss: 8.281515  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.065078 \n",
      "\n",
      "loss: 1.046913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.821489 \n",
      "\n",
      "loss: 5.863630  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 13.259850 \n",
      "\n",
      "loss: 13.560179  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.842851 \n",
      "\n",
      "loss: 0.850340  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 1.664336 \n",
      "\n",
      "loss: 1.592528  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.984099 \n",
      "\n",
      "loss: 0.993171  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 1.162049 \n",
      "\n",
      "loss: 1.234462  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.273879 \n",
      "\n",
      "loss: 1.263826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.810830 \n",
      "\n",
      "loss: 0.813027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 1.320354 \n",
      "\n",
      "loss: 1.241534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.134090 \n",
      "\n",
      "loss: 1.166977  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.063760 \n",
      "\n",
      "loss: 2.082860  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.393327 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 93/500\n",
      "--------------------\n",
      "{'hl': [451], 'alpha': 0.6968675933498937, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.21780002378933774}\n",
      "loss: 1.188745  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 9.188365 \n",
      "\n",
      "loss: 9.091392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 3.397818 \n",
      "\n",
      "loss: 3.571845  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 8.589536 \n",
      "\n",
      "loss: 8.300675  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.999429 \n",
      "\n",
      "loss: 4.814556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 10.203320 \n",
      "\n",
      "loss: 10.445518  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.646105 \n",
      "\n",
      "loss: 2.477060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 9.457570 \n",
      "\n",
      "loss: 9.514301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 4.346197 \n",
      "\n",
      "loss: 4.353962  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 9.237851 \n",
      "\n",
      "loss: 9.133088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.404201 \n",
      "\n",
      "loss: 2.346495  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 9.419861 \n",
      "\n",
      "loss: 9.444448  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.717093 \n",
      "\n",
      "loss: 1.721020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 9.962099 \n",
      "\n",
      "loss: 9.813897  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.581930 \n",
      "\n",
      "loss: 5.910668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 8.875510 \n",
      "\n",
      "loss: 9.364997  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.048312 \n",
      "\n",
      "loss: 2.969221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 10.108923 \n",
      "\n",
      "loss: 9.506742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 3.017693 \n",
      "\n",
      "loss: 3.070771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 9.651925 \n",
      "\n",
      "loss: 9.328688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.226895 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 94/500\n",
      "--------------------\n",
      "{'hl': [542, 674, 284], 'alpha': 0.029083683927172584, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.21784368905264676}\n",
      "loss: 1.152627  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.479769 \n",
      "\n",
      "loss: 5.807392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.644722 \n",
      "\n",
      "loss: 2.631223  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.659651 \n",
      "\n",
      "loss: 1.619246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.157755 \n",
      "\n",
      "loss: 1.086056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 3.378218 \n",
      "\n",
      "loss: 3.496107  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.589136 \n",
      "\n",
      "loss: 2.744190  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.290249 \n",
      "\n",
      "loss: 1.582335  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.226335 \n",
      "\n",
      "loss: 1.156357  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 5.686785 \n",
      "\n",
      "loss: 5.482222  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.826148 \n",
      "\n",
      "loss: 3.428700  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.970862 \n",
      "\n",
      "loss: 2.833027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.608370 \n",
      "\n",
      "loss: 5.492627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 4.319375 \n",
      "\n",
      "loss: 4.133012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 7.151138 \n",
      "\n",
      "loss: 6.987273  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 8.541529 \n",
      "\n",
      "loss: 8.566736  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.197479 \n",
      "\n",
      "loss: 2.182213  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 4.163537 \n",
      "\n",
      "loss: 3.968690  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.617515 \n",
      "\n",
      "loss: 3.735043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.155755 \n",
      "\n",
      "loss: 4.360873  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 5.566604 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 95/500\n",
      "--------------------\n",
      "{'hl': [614, 282, 338], 'alpha': 0.25518352956745854, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4408274288829857}\n",
      "loss: 1.069595  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 10518.758247 \n",
      "\n",
      "loss: 8602.775391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 2.116263 \n",
      "\n",
      "loss: 0.918236  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 2.000790 \n",
      "\n",
      "loss: 1.094275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 2.048191 \n",
      "\n",
      "loss: 2.700655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.998498 \n",
      "\n",
      "loss: 0.892593  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.191530 \n",
      "\n",
      "loss: 1.021398  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.399641 \n",
      "\n",
      "loss: 1.855376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.771617 \n",
      "\n",
      "loss: 0.759338  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.775852 \n",
      "\n",
      "loss: 0.540664  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.547729 \n",
      "\n",
      "loss: 0.834285  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.530514 \n",
      "\n",
      "loss: 0.507511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.487624 \n",
      "\n",
      "loss: 0.477953  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.516067 \n",
      "\n",
      "loss: 0.497018  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.509037 \n",
      "\n",
      "loss: 0.476553  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.538414 \n",
      "\n",
      "loss: 0.498104  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.651782 \n",
      "\n",
      "loss: 0.553661  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.578976 \n",
      "\n",
      "loss: 0.562027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.518849 \n",
      "\n",
      "loss: 0.520979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.441713 \n",
      "\n",
      "loss: 0.435700  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.433267 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 96/500\n",
      "--------------------\n",
      "{'hl': [483], 'alpha': 0.019028238170646312, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.014447128885267781}\n",
      "loss: 0.991578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.554903 \n",
      "\n",
      "loss: 0.541741  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.520459 \n",
      "\n",
      "loss: 0.511181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.510038 \n",
      "\n",
      "loss: 0.494982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.511599 \n",
      "\n",
      "loss: 0.513386  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.504709 \n",
      "\n",
      "loss: 0.520421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.503706 \n",
      "\n",
      "loss: 0.550767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.528641 \n",
      "\n",
      "loss: 0.508817  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.536273 \n",
      "\n",
      "loss: 0.551360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.506216 \n",
      "\n",
      "loss: 0.547969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.506387 \n",
      "\n",
      "loss: 0.470687  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.540522 \n",
      "\n",
      "loss: 0.502135  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.531048 \n",
      "\n",
      "loss: 0.542080  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.530813 \n",
      "\n",
      "loss: 0.521028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.509471 \n",
      "\n",
      "loss: 0.498151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.511363 \n",
      "\n",
      "loss: 0.509815  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.511328 \n",
      "\n",
      "loss: 0.505883  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.534835 \n",
      "\n",
      "loss: 0.533552  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.507116 \n",
      "\n",
      "loss: 0.458665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.494926 \n",
      "\n",
      "loss: 0.476792  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.520477 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 97/500\n",
      "--------------------\n",
      "{'hl': [194, 507], 'alpha': 0.0007054713816224794, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.1399012781699892}\n",
      "loss: 1.143104  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 12.942801 \n",
      "\n",
      "loss: 10.533228  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 4.879470 \n",
      "\n",
      "loss: 5.095557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 1.813639 \n",
      "\n",
      "loss: 2.092116  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 1.628096 \n",
      "\n",
      "loss: 1.558570  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.697000 \n",
      "\n",
      "loss: 0.630957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 1.197310 \n",
      "\n",
      "loss: 0.661185  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.648329 \n",
      "\n",
      "loss: 0.496052  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.393870 \n",
      "\n",
      "loss: 0.440517  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.387678 \n",
      "\n",
      "loss: 0.375551  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.372677 \n",
      "\n",
      "loss: 0.387462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.358375 \n",
      "\n",
      "loss: 0.368995  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.366561 \n",
      "\n",
      "loss: 0.343088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.353119 \n",
      "\n",
      "loss: 0.362888  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.806196 \n",
      "\n",
      "loss: 1.584913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.446970 \n",
      "\n",
      "loss: 0.472204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.387359 \n",
      "\n",
      "loss: 0.358688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.375088 \n",
      "\n",
      "loss: 0.329849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.345680 \n",
      "\n",
      "loss: 0.302145  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.337662 \n",
      "\n",
      "loss: 0.322596  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.341369 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 98/500\n",
      "--------------------\n",
      "{'hl': [290, 577, 18], 'alpha': 0.011654912217800571, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.1207538895813027}\n",
      "loss: 1.154836  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.542983 \n",
      "\n",
      "loss: 0.538410  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.497644 \n",
      "\n",
      "loss: 0.482666  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.484486 \n",
      "\n",
      "loss: 0.461349  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.467625 \n",
      "\n",
      "loss: 0.445175  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.456263 \n",
      "\n",
      "loss: 0.445424  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.457642 \n",
      "\n",
      "loss: 0.466629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.454587 \n",
      "\n",
      "loss: 0.467936  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.442159 \n",
      "\n",
      "loss: 0.466653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.435234 \n",
      "\n",
      "loss: 0.465617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.423273 \n",
      "\n",
      "loss: 0.435987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.431748 \n",
      "\n",
      "loss: 0.432896  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.433160 \n",
      "\n",
      "loss: 0.429707  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.428186 \n",
      "\n",
      "loss: 0.429379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.426401 \n",
      "\n",
      "loss: 0.411974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.416105 \n",
      "\n",
      "loss: 0.421449  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.417766 \n",
      "\n",
      "loss: 0.381160  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.426090 \n",
      "\n",
      "loss: 0.408931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.421232 \n",
      "\n",
      "loss: 0.442464  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.414257 \n",
      "\n",
      "loss: 0.433478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.407958 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 99/500\n",
      "--------------------\n",
      "{'hl': [508, 576], 'alpha': 0.10780989273231839, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.22414245733832672}\n",
      "loss: 1.120536  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.395888 \n",
      "\n",
      "loss: 2.702516  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.678531 \n",
      "\n",
      "loss: 3.451887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.811835 \n",
      "\n",
      "loss: 2.711742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.650025 \n",
      "\n",
      "loss: 3.633864  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 10.025573 \n",
      "\n",
      "loss: 9.870770  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 14.823170 \n",
      "\n",
      "loss: 15.288116  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 17.915045 \n",
      "\n",
      "loss: 18.488390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 20.288175 \n",
      "\n",
      "loss: 20.569956  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 15.764816 \n",
      "\n",
      "loss: 15.592470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.432256 \n",
      "\n",
      "loss: 2.375057  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.965904 \n",
      "\n",
      "loss: 3.065592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 17.030920 \n",
      "\n",
      "loss: 16.252516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 6.158670 \n",
      "\n",
      "loss: 5.905934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.373349 \n",
      "\n",
      "loss: 3.196661  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 12.472243 \n",
      "\n",
      "loss: 12.451869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 13.615260 \n",
      "\n",
      "loss: 13.776029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 13.660499 \n",
      "\n",
      "loss: 13.973023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 12.576224 \n",
      "\n",
      "loss: 13.520802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 6.657258 \n",
      "\n",
      "loss: 6.618757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.351398 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 100/500\n",
      "--------------------\n",
      "{'hl': [103], 'alpha': 0.0015029423606692399, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.15317239446203118}\n",
      "loss: 1.159583  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.575568 \n",
      "\n",
      "loss: 0.572720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.540177 \n",
      "\n",
      "loss: 0.548582  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.521698 \n",
      "\n",
      "loss: 0.526717  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.493386 \n",
      "\n",
      "loss: 0.532655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.508103 \n",
      "\n",
      "loss: 0.474857  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.500328 \n",
      "\n",
      "loss: 0.476200  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.502575 \n",
      "\n",
      "loss: 0.477988  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.497128 \n",
      "\n",
      "loss: 0.478361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.484948 \n",
      "\n",
      "loss: 0.468268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.490632 \n",
      "\n",
      "loss: 0.451371  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.485105 \n",
      "\n",
      "loss: 0.487465  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.498139 \n",
      "\n",
      "loss: 0.463770  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.480297 \n",
      "\n",
      "loss: 0.491564  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.470681 \n",
      "\n",
      "loss: 0.465527  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.468606 \n",
      "\n",
      "loss: 0.478450  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.460987 \n",
      "\n",
      "loss: 0.490230  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.481627 \n",
      "\n",
      "loss: 0.493930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.462993 \n",
      "\n",
      "loss: 0.507713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.474214 \n",
      "\n",
      "loss: 0.451084  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.469894 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 101/500\n",
      "--------------------\n",
      "{'hl': [385, 492, 574], 'alpha': 0.013294981109286128, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.17597008275432274}\n",
      "loss: 1.036092  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 6.088885 \n",
      "\n",
      "loss: 6.482485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 11.477403 \n",
      "\n",
      "loss: 11.085311  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 6.161594 \n",
      "\n",
      "loss: 6.639426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.499342 \n",
      "\n",
      "loss: 4.755185  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.732206 \n",
      "\n",
      "loss: 2.781032  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 10.713054 \n",
      "\n",
      "loss: 11.300505  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.155578 \n",
      "\n",
      "loss: 7.549478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.532656 \n",
      "\n",
      "loss: 1.438822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 8.281185 \n",
      "\n",
      "loss: 8.656674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.582871 \n",
      "\n",
      "loss: 2.866750  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 7.661423 \n",
      "\n",
      "loss: 7.727566  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.764366 \n",
      "\n",
      "loss: 5.270650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 8.159803 \n",
      "\n",
      "loss: 9.110065  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 8.817728 \n",
      "\n",
      "loss: 9.183947  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 8.037830 \n",
      "\n",
      "loss: 8.414492  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.652965 \n",
      "\n",
      "loss: 1.940883  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 4.306130 \n",
      "\n",
      "loss: 4.116392  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 5.695709 \n",
      "\n",
      "loss: 6.136997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 11.383745 \n",
      "\n",
      "loss: 11.557694  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.775684 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 102/500\n",
      "--------------------\n",
      "{'hl': [285, 321], 'alpha': 0.0010130122678245611, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.15784241720859266}\n",
      "loss: 1.115667  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.492507 \n",
      "\n",
      "loss: 0.460468  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.454473 \n",
      "\n",
      "loss: 0.475151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.432094 \n",
      "\n",
      "loss: 0.428846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.404555 \n",
      "\n",
      "loss: 0.416749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.393131 \n",
      "\n",
      "loss: 0.373565  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.380711 \n",
      "\n",
      "loss: 0.424224  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.391709 \n",
      "\n",
      "loss: 0.355570  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.372971 \n",
      "\n",
      "loss: 0.375500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.362219 \n",
      "\n",
      "loss: 0.342645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.347925 \n",
      "\n",
      "loss: 0.320938  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.339485 \n",
      "\n",
      "loss: 0.325521  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.362698 \n",
      "\n",
      "loss: 0.362937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.353857 \n",
      "\n",
      "loss: 0.355874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.335382 \n",
      "\n",
      "loss: 0.366774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.329063 \n",
      "\n",
      "loss: 0.322435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.323878 \n",
      "\n",
      "loss: 0.331312  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.346286 \n",
      "\n",
      "loss: 0.301325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.323775 \n",
      "\n",
      "loss: 0.277537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.339294 \n",
      "\n",
      "loss: 0.354937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.305657 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 103/500\n",
      "--------------------\n",
      "{'hl': [556, 714, 197], 'alpha': 0.0005836653236377698, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3623200420464165}\n",
      "loss: 1.117147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 4.215420 \n",
      "\n",
      "loss: 3.961856  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.923121 \n",
      "\n",
      "loss: 1.854350  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 4.066891 \n",
      "\n",
      "loss: 3.804847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.021859 \n",
      "\n",
      "loss: 1.991539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.183374 \n",
      "\n",
      "loss: 2.386430  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 5.029643 \n",
      "\n",
      "loss: 5.067346  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 10.954074 \n",
      "\n",
      "loss: 11.113392  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.588577 \n",
      "\n",
      "loss: 4.053266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.762431 \n",
      "\n",
      "loss: 5.484085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 5.176786 \n",
      "\n",
      "loss: 5.528151  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.666909 \n",
      "\n",
      "loss: 4.872570  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.111289 \n",
      "\n",
      "loss: 4.901228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.897473 \n",
      "\n",
      "loss: 0.892864  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.401602 \n",
      "\n",
      "loss: 3.107691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.837832 \n",
      "\n",
      "loss: 2.784047  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 18.065288 \n",
      "\n",
      "loss: 18.037985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.458104 \n",
      "\n",
      "loss: 6.317442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 5.905358 \n",
      "\n",
      "loss: 5.701804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 7.475256 \n",
      "\n",
      "loss: 7.038688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.088484 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 104/500\n",
      "--------------------\n",
      "{'hl': [619, 297, 110], 'alpha': 0.21404912325700817, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.18050444646777827}\n",
      "loss: 1.122803  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 0.870041 \n",
      "\n",
      "loss: 0.863504  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.903042 \n",
      "\n",
      "loss: 0.897056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.899036 \n",
      "\n",
      "loss: 0.898141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.899689 \n",
      "\n",
      "loss: 0.911611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.904673 \n",
      "\n",
      "loss: 0.905638  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.902395 \n",
      "\n",
      "loss: 0.899690  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.907086 \n",
      "\n",
      "loss: 0.909998  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.902372 \n",
      "\n",
      "loss: 0.897352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.903240 \n",
      "\n",
      "loss: 0.902001  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.903719 \n",
      "\n",
      "loss: 0.902054  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.906396 \n",
      "\n",
      "loss: 0.903945  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.907766 \n",
      "\n",
      "loss: 0.904753  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.903659 \n",
      "\n",
      "loss: 0.893646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.903520 \n",
      "\n",
      "loss: 0.913822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.898732 \n",
      "\n",
      "loss: 0.907239  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.903732 \n",
      "\n",
      "loss: 0.897284  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.906507 \n",
      "\n",
      "loss: 0.915639  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.901850 \n",
      "\n",
      "loss: 0.898222  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.903420 \n",
      "\n",
      "loss: 0.908451  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.900366 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 105/500\n",
      "--------------------\n",
      "{'hl': [22, 554], 'alpha': 0.0003208720134020975, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2767241475026243}\n",
      "loss: 1.077723  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.449127 \n",
      "\n",
      "loss: 0.462278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.415337 \n",
      "\n",
      "loss: 0.447520  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.401185 \n",
      "\n",
      "loss: 0.420346  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.379658 \n",
      "\n",
      "loss: 0.375628  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.374457 \n",
      "\n",
      "loss: 0.415515  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.357788 \n",
      "\n",
      "loss: 0.334577  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.360221 \n",
      "\n",
      "loss: 0.344527  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.355116 \n",
      "\n",
      "loss: 0.345087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.351133 \n",
      "\n",
      "loss: 0.342637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.329572 \n",
      "\n",
      "loss: 0.367129  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.334233 \n",
      "\n",
      "loss: 0.311597  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.349704 \n",
      "\n",
      "loss: 0.363937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.336742 \n",
      "\n",
      "loss: 0.305839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.339676 \n",
      "\n",
      "loss: 0.337889  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.321276 \n",
      "\n",
      "loss: 0.348278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.324166 \n",
      "\n",
      "loss: 0.318704  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.330538 \n",
      "\n",
      "loss: 0.285764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.352571 \n",
      "\n",
      "loss: 0.305863  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.327223 \n",
      "\n",
      "loss: 0.324019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.355001 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 106/500\n",
      "--------------------\n",
      "{'hl': [137, 661, 510], 'alpha': 0.00025724715898508947, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.23475153277076205}\n",
      "loss: 1.070053  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 227.213340 \n",
      "\n",
      "loss: 202.099411  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.830336 \n",
      "\n",
      "loss: 0.806118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.821738 \n",
      "\n",
      "loss: 0.848205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814793 \n",
      "\n",
      "loss: 0.834192  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.802580 \n",
      "\n",
      "loss: 0.794336  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819856 \n",
      "\n",
      "loss: 0.823406  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.855595 \n",
      "\n",
      "loss: 0.866900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.827208 \n",
      "\n",
      "loss: 0.843689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.806649 \n",
      "\n",
      "loss: 0.822025  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813863 \n",
      "\n",
      "loss: 0.828354  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817934 \n",
      "\n",
      "loss: 0.814310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.827239 \n",
      "\n",
      "loss: 0.822746  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.816486 \n",
      "\n",
      "loss: 0.809879  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.820757 \n",
      "\n",
      "loss: 0.817294  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.811079 \n",
      "\n",
      "loss: 0.834833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817450 \n",
      "\n",
      "loss: 0.827683  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824667 \n",
      "\n",
      "loss: 0.808466  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.808888 \n",
      "\n",
      "loss: 0.822207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.813520 \n",
      "\n",
      "loss: 0.835082  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.816541 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 107/500\n",
      "--------------------\n",
      "{'hl': [356, 196], 'alpha': 0.7277640064292673, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.05713216164838978}\n",
      "loss: 1.072498  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.986331 \n",
      "\n",
      "loss: 0.980662  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.986990 \n",
      "\n",
      "loss: 0.982301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.983584 \n",
      "\n",
      "loss: 0.982480  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.984742 \n",
      "\n",
      "loss: 0.986990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.987278 \n",
      "\n",
      "loss: 0.986448  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.986921 \n",
      "\n",
      "loss: 0.988223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.987032 \n",
      "\n",
      "loss: 0.990324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.983581 \n",
      "\n",
      "loss: 0.986286  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.982643 \n",
      "\n",
      "loss: 0.987688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.988375 \n",
      "\n",
      "loss: 0.985532  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.985709 \n",
      "\n",
      "loss: 0.981887  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.993234 \n",
      "\n",
      "loss: 0.986926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.984328 \n",
      "\n",
      "loss: 0.983272  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.991219 \n",
      "\n",
      "loss: 0.991145  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.980337 \n",
      "\n",
      "loss: 0.983859  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.987746 \n",
      "\n",
      "loss: 0.992194  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.990014 \n",
      "\n",
      "loss: 0.993402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.987743 \n",
      "\n",
      "loss: 0.987208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.983458 \n",
      "\n",
      "loss: 0.979019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.986046 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 108/500\n",
      "--------------------\n",
      "{'hl': [418], 'alpha': 0.009268004610507398, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.07468387247838022}\n",
      "loss: 1.144863  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.529523 \n",
      "\n",
      "loss: 0.465158  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.488731 \n",
      "\n",
      "loss: 0.453148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.463374 \n",
      "\n",
      "loss: 0.469221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.450379 \n",
      "\n",
      "loss: 0.435987  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.435284 \n",
      "\n",
      "loss: 0.429939  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.435973 \n",
      "\n",
      "loss: 0.411873  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.432866 \n",
      "\n",
      "loss: 0.418655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.418965 \n",
      "\n",
      "loss: 0.433326  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.407117 \n",
      "\n",
      "loss: 0.429846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.394581 \n",
      "\n",
      "loss: 0.393072  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.404242 \n",
      "\n",
      "loss: 0.390055  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.403797 \n",
      "\n",
      "loss: 0.401775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.401715 \n",
      "\n",
      "loss: 0.419328  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.396013 \n",
      "\n",
      "loss: 0.343042  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.375591 \n",
      "\n",
      "loss: 0.389121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.386811 \n",
      "\n",
      "loss: 0.408049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.398882 \n",
      "\n",
      "loss: 0.382716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.382158 \n",
      "\n",
      "loss: 0.373085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.380703 \n",
      "\n",
      "loss: 0.366652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.369608 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 109/500\n",
      "--------------------\n",
      "{'hl': [319, 95, 262], 'alpha': 0.00029771879246687694, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.38786920049513884}\n",
      "loss: 1.213372  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.824669 \n",
      "\n",
      "loss: 0.818242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.846728 \n",
      "\n",
      "loss: 0.849005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.824726 \n",
      "\n",
      "loss: 0.828840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.807905 \n",
      "\n",
      "loss: 0.800472  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.810993 \n",
      "\n",
      "loss: 0.795438  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.812900 \n",
      "\n",
      "loss: 0.802774  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.810517 \n",
      "\n",
      "loss: 0.805047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.777299 \n",
      "\n",
      "loss: 0.797239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.835402 \n",
      "\n",
      "loss: 0.808284  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.663373 \n",
      "\n",
      "loss: 0.658008  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.558021 \n",
      "\n",
      "loss: 0.554967  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.529042 \n",
      "\n",
      "loss: 0.526325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.520579 \n",
      "\n",
      "loss: 0.524943  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.515074 \n",
      "\n",
      "loss: 0.476455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.540401 \n",
      "\n",
      "loss: 0.499578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.506044 \n",
      "\n",
      "loss: 0.499217  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.508507 \n",
      "\n",
      "loss: 0.522647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.520182 \n",
      "\n",
      "loss: 0.504644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.487760 \n",
      "\n",
      "loss: 0.547400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.525308 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 110/500\n",
      "--------------------\n",
      "{'hl': [469, 461], 'alpha': 0.0015467229518100884, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.28435787236505417}\n",
      "loss: 1.057365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 4.029187 \n",
      "\n",
      "loss: 4.350291  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 1.140838 \n",
      "\n",
      "loss: 1.131747  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 6.137792 \n",
      "\n",
      "loss: 6.275705  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.521223 \n",
      "\n",
      "loss: 4.581824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 4.540583 \n",
      "\n",
      "loss: 4.763391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.335311 \n",
      "\n",
      "loss: 1.436272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 3.891832 \n",
      "\n",
      "loss: 3.981269  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 2.531043 \n",
      "\n",
      "loss: 2.397930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 4.959771 \n",
      "\n",
      "loss: 4.438367  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.455992 \n",
      "\n",
      "loss: 4.951000  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 1.689811 \n",
      "\n",
      "loss: 1.610589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 8.596896 \n",
      "\n",
      "loss: 5.801246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 27.9%, Avg loss: 3.949354 \n",
      "\n",
      "loss: 3.945497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.783454 \n",
      "\n",
      "loss: 1.785774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 9.478679 \n",
      "\n",
      "loss: 9.459162  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 7.726774 \n",
      "\n",
      "loss: 7.422738  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.530767 \n",
      "\n",
      "loss: 5.508542  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.001730 \n",
      "\n",
      "loss: 1.071726  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 4.431911 \n",
      "\n",
      "loss: 4.932521  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.407434 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 111/500\n",
      "--------------------\n",
      "{'hl': [632], 'alpha': 0.6925244479226677, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.31279496370026094}\n",
      "loss: 1.096745  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.783519 \n",
      "\n",
      "loss: 0.778829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.783574 \n",
      "\n",
      "loss: 0.782898  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.786965 \n",
      "\n",
      "loss: 0.779022  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.785801 \n",
      "\n",
      "loss: 0.786413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.794141 \n",
      "\n",
      "loss: 0.791445  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.782700 \n",
      "\n",
      "loss: 0.783041  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.791673 \n",
      "\n",
      "loss: 0.774161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.792880 \n",
      "\n",
      "loss: 0.777243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.799078 \n",
      "\n",
      "loss: 0.801015  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.779695 \n",
      "\n",
      "loss: 0.778821  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.784200 \n",
      "\n",
      "loss: 0.772286  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.781978 \n",
      "\n",
      "loss: 0.777023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.783590 \n",
      "\n",
      "loss: 0.795298  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.788162 \n",
      "\n",
      "loss: 0.781645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.778590 \n",
      "\n",
      "loss: 0.782291  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.788117 \n",
      "\n",
      "loss: 0.788781  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.782202 \n",
      "\n",
      "loss: 0.780820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.773952 \n",
      "\n",
      "loss: 0.782514  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.768290 \n",
      "\n",
      "loss: 0.781971  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.778911 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 112/500\n",
      "--------------------\n",
      "{'hl': [684, 91], 'alpha': 0.0004248429086370303, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.07835065446002475}\n",
      "loss: 1.097448  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.539270 \n",
      "\n",
      "loss: 0.555608  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.497349 \n",
      "\n",
      "loss: 0.512175  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.486830 \n",
      "\n",
      "loss: 0.467519  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.460335 \n",
      "\n",
      "loss: 0.516327  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.453840 \n",
      "\n",
      "loss: 0.444471  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.444400 \n",
      "\n",
      "loss: 0.444846  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.445859 \n",
      "\n",
      "loss: 0.448722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.444702 \n",
      "\n",
      "loss: 0.480709  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.428904 \n",
      "\n",
      "loss: 0.476928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.411162 \n",
      "\n",
      "loss: 0.432804  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.423350 \n",
      "\n",
      "loss: 0.460022  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.430628 \n",
      "\n",
      "loss: 0.422250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.414212 \n",
      "\n",
      "loss: 0.433851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.413467 \n",
      "\n",
      "loss: 0.415603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.403976 \n",
      "\n",
      "loss: 0.406713  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.405430 \n",
      "\n",
      "loss: 0.427859  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.426088 \n",
      "\n",
      "loss: 0.419756  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.401189 \n",
      "\n",
      "loss: 0.404788  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.402571 \n",
      "\n",
      "loss: 0.380029  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.392051 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 113/500\n",
      "--------------------\n",
      "{'hl': [469, 713], 'alpha': 0.023727106547322248, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.11581496965455733}\n",
      "loss: 1.121363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.525339 \n",
      "\n",
      "loss: 0.554764  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.471938 \n",
      "\n",
      "loss: 0.447500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.455195 \n",
      "\n",
      "loss: 0.500931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.435983 \n",
      "\n",
      "loss: 0.456191  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.429689 \n",
      "\n",
      "loss: 0.373437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.431385 \n",
      "\n",
      "loss: 0.411442  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.416911 \n",
      "\n",
      "loss: 0.403395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.408943 \n",
      "\n",
      "loss: 0.417023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.409914 \n",
      "\n",
      "loss: 0.440480  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.386004 \n",
      "\n",
      "loss: 0.383663  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.390425 \n",
      "\n",
      "loss: 0.402891  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.395333 \n",
      "\n",
      "loss: 0.419372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.382379 \n",
      "\n",
      "loss: 0.389462  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.395470 \n",
      "\n",
      "loss: 0.410442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.378317 \n",
      "\n",
      "loss: 0.433637  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.383840 \n",
      "\n",
      "loss: 0.393024  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.390319 \n",
      "\n",
      "loss: 0.383926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.379505 \n",
      "\n",
      "loss: 0.411433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.384150 \n",
      "\n",
      "loss: 0.391306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.374153 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 114/500\n",
      "--------------------\n",
      "{'hl': [297, 472, 80], 'alpha': 0.0561745601152029, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.2126269691554954}\n",
      "loss: 1.102280  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.520695 \n",
      "\n",
      "loss: 0.522623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.483549 \n",
      "\n",
      "loss: 0.481992  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.475513 \n",
      "\n",
      "loss: 0.456264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.451951 \n",
      "\n",
      "loss: 0.443336  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.449044 \n",
      "\n",
      "loss: 0.480591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.445800 \n",
      "\n",
      "loss: 0.443243  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.453743 \n",
      "\n",
      "loss: 0.438715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.442647 \n",
      "\n",
      "loss: 0.413351  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.442613 \n",
      "\n",
      "loss: 0.484535  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.435982 \n",
      "\n",
      "loss: 0.435795  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.444800 \n",
      "\n",
      "loss: 0.439211  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.443807 \n",
      "\n",
      "loss: 0.449077  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.443386 \n",
      "\n",
      "loss: 0.438727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.441341 \n",
      "\n",
      "loss: 0.476575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.441420 \n",
      "\n",
      "loss: 0.458761  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.439596 \n",
      "\n",
      "loss: 0.453332  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.436941 \n",
      "\n",
      "loss: 0.398601  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.448929 \n",
      "\n",
      "loss: 0.434468  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.437069 \n",
      "\n",
      "loss: 0.451271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.430589 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 115/500\n",
      "--------------------\n",
      "{'hl': [238, 671, 160], 'alpha': 0.43017560765429, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.029913055952972143}\n",
      "loss: 1.093327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.853413 \n",
      "\n",
      "loss: 0.869685  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.845080 \n",
      "\n",
      "loss: 0.850639  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.859663 \n",
      "\n",
      "loss: 0.861627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.882887 \n",
      "\n",
      "loss: 0.876476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.906433 \n",
      "\n",
      "loss: 0.906536  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 0.929730 \n",
      "\n",
      "loss: 0.933842  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.946488 \n",
      "\n",
      "loss: 0.943817  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.946985 \n",
      "\n",
      "loss: 0.951696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.949659 \n",
      "\n",
      "loss: 0.949827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.949684 \n",
      "\n",
      "loss: 0.956105  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.951543 \n",
      "\n",
      "loss: 0.946343  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.951738 \n",
      "\n",
      "loss: 0.949082  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.948915 \n",
      "\n",
      "loss: 0.957505  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.950313 \n",
      "\n",
      "loss: 0.947605  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.948427 \n",
      "\n",
      "loss: 0.944613  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.950233 \n",
      "\n",
      "loss: 0.947692  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.951271 \n",
      "\n",
      "loss: 0.952654  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.947755 \n",
      "\n",
      "loss: 0.946595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.949620 \n",
      "\n",
      "loss: 0.943451  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.949724 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 116/500\n",
      "--------------------\n",
      "{'hl': [617, 590], 'alpha': 0.48391614952232304, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.23440211534105332}\n",
      "loss: 1.188906  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.950574 \n",
      "\n",
      "loss: 1.991165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.605297 \n",
      "\n",
      "loss: 3.477791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.390172 \n",
      "\n",
      "loss: 2.322633  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.853448 \n",
      "\n",
      "loss: 2.741534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.182005 \n",
      "\n",
      "loss: 2.160485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.091681 \n",
      "\n",
      "loss: 3.010833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.297589 \n",
      "\n",
      "loss: 2.305967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.499189 \n",
      "\n",
      "loss: 2.407095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.277071 \n",
      "\n",
      "loss: 2.412762  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.559605 \n",
      "\n",
      "loss: 3.623112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.851053 \n",
      "\n",
      "loss: 1.878713  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.435919 \n",
      "\n",
      "loss: 3.435933  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.033242 \n",
      "\n",
      "loss: 2.027024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.258129 \n",
      "\n",
      "loss: 3.305164  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.699826 \n",
      "\n",
      "loss: 1.587719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.307034 \n",
      "\n",
      "loss: 3.282209  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.933367 \n",
      "\n",
      "loss: 1.962875  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.505802 \n",
      "\n",
      "loss: 3.586576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.799046 \n",
      "\n",
      "loss: 1.814257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.883395 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 117/500\n",
      "--------------------\n",
      "{'hl': [420, 286], 'alpha': 0.010043583822130614, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.04031288176446056}\n",
      "loss: 1.285039  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.597958 \n",
      "\n",
      "loss: 0.624451  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.589400 \n",
      "\n",
      "loss: 0.574522  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.611908 \n",
      "\n",
      "loss: 0.578068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.611467 \n",
      "\n",
      "loss: 0.569081  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.566930 \n",
      "\n",
      "loss: 0.570843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.537046 \n",
      "\n",
      "loss: 0.513911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.542076 \n",
      "\n",
      "loss: 0.566422  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.533457 \n",
      "\n",
      "loss: 0.556492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.546863 \n",
      "\n",
      "loss: 0.532322  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.548429 \n",
      "\n",
      "loss: 0.545421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.525139 \n",
      "\n",
      "loss: 0.553585  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.534218 \n",
      "\n",
      "loss: 0.581882  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.631742 \n",
      "\n",
      "loss: 0.637871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.774524 \n",
      "\n",
      "loss: 0.837190  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.951350 \n",
      "\n",
      "loss: 2.886421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 1.011609 \n",
      "\n",
      "loss: 0.779693  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.705344 \n",
      "\n",
      "loss: 0.615152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.788020 \n",
      "\n",
      "loss: 0.821343  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.723762 \n",
      "\n",
      "loss: 0.753951  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.520402 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 118/500\n",
      "--------------------\n",
      "{'hl': [450], 'alpha': 0.0867232795989235, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.045754310626829504}\n",
      "loss: 1.029903  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.548247 \n",
      "\n",
      "loss: 0.540697  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.517862 \n",
      "\n",
      "loss: 0.483952  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.507486 \n",
      "\n",
      "loss: 0.487087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.504248 \n",
      "\n",
      "loss: 0.474066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.485892 \n",
      "\n",
      "loss: 0.483148  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.492235 \n",
      "\n",
      "loss: 0.490512  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.499032 \n",
      "\n",
      "loss: 0.500791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.496940 \n",
      "\n",
      "loss: 0.516720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.485594 \n",
      "\n",
      "loss: 0.501072  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.487096 \n",
      "\n",
      "loss: 0.482219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.479080 \n",
      "\n",
      "loss: 0.518957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.491231 \n",
      "\n",
      "loss: 0.454441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.497606 \n",
      "\n",
      "loss: 0.458579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.480326 \n",
      "\n",
      "loss: 0.472137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.481715 \n",
      "\n",
      "loss: 0.503491  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.479067 \n",
      "\n",
      "loss: 0.485995  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.488658 \n",
      "\n",
      "loss: 0.463231  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.481976 \n",
      "\n",
      "loss: 0.477444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.473466 \n",
      "\n",
      "loss: 0.475248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.478976 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 119/500\n",
      "--------------------\n",
      "{'hl': [597, 609, 29], 'alpha': 0.9960695583891345, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.38157819118543557}\n",
      "loss: 1.098916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.006885 \n",
      "\n",
      "loss: 1.006902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.006492 \n",
      "\n",
      "loss: 1.003898  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.005028 \n",
      "\n",
      "loss: 1.004848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.005485 \n",
      "\n",
      "loss: 1.005462  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.007674 \n",
      "\n",
      "loss: 1.004868  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.007319 \n",
      "\n",
      "loss: 1.011772  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.006803 \n",
      "\n",
      "loss: 1.006151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.007563 \n",
      "\n",
      "loss: 1.005913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.005790 \n",
      "\n",
      "loss: 1.006439  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.006719 \n",
      "\n",
      "loss: 1.005664  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.004994 \n",
      "\n",
      "loss: 1.007843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.007978 \n",
      "\n",
      "loss: 1.009271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.005029 \n",
      "\n",
      "loss: 1.007237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.008767 \n",
      "\n",
      "loss: 1.009044  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.007107 \n",
      "\n",
      "loss: 1.005946  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.004186 \n",
      "\n",
      "loss: 1.005279  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.008179 \n",
      "\n",
      "loss: 1.006878  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.006845 \n",
      "\n",
      "loss: 1.005759  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.006792 \n",
      "\n",
      "loss: 1.008336  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.006729 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 120/500\n",
      "--------------------\n",
      "{'hl': [489], 'alpha': 0.011908453466421673, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.09082642469684066}\n",
      "loss: 0.976902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.810050 \n",
      "\n",
      "loss: 0.796202  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.770792 \n",
      "\n",
      "loss: 0.806673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.725435 \n",
      "\n",
      "loss: 0.627883  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.561106 \n",
      "\n",
      "loss: 0.591137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.649925 \n",
      "\n",
      "loss: 0.618167  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 1.009882 \n",
      "\n",
      "loss: 0.997607  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 2.654880 \n",
      "\n",
      "loss: 2.048547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 2.148620 \n",
      "\n",
      "loss: 2.361584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.936342 \n",
      "\n",
      "loss: 0.931129  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.632407 \n",
      "\n",
      "loss: 0.661812  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.510630 \n",
      "\n",
      "loss: 0.534298  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.510999 \n",
      "\n",
      "loss: 0.484151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.517546 \n",
      "\n",
      "loss: 0.522371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.571722 \n",
      "\n",
      "loss: 0.567250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.656215 \n",
      "\n",
      "loss: 0.615442  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.593161 \n",
      "\n",
      "loss: 0.646592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.594352 \n",
      "\n",
      "loss: 0.641452  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 1.424850 \n",
      "\n",
      "loss: 1.631063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 1.501050 \n",
      "\n",
      "loss: 1.486098  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.248315 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 121/500\n",
      "--------------------\n",
      "{'hl': [454, 658, 511], 'alpha': 0.7520053741623683, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.20423321190566465}\n",
      "loss: 1.034644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 8.509769 \n",
      "\n",
      "loss: 8.662411  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.248216 \n",
      "\n",
      "loss: 5.580893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 1.902300 \n",
      "\n",
      "loss: 1.913201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.964322 \n",
      "\n",
      "loss: 1.963968  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.832739 \n",
      "\n",
      "loss: 1.725903  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.385237 \n",
      "\n",
      "loss: 5.270943  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 1.114693 \n",
      "\n",
      "loss: 1.116824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 11.556901 \n",
      "\n",
      "loss: 11.613843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 5.722462 \n",
      "\n",
      "loss: 5.926051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 11.471777 \n",
      "\n",
      "loss: 11.649045  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.342010 \n",
      "\n",
      "loss: 1.490012  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.833404 \n",
      "\n",
      "loss: 2.983001  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 3.975344 \n",
      "\n",
      "loss: 3.919936  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 5.290325 \n",
      "\n",
      "loss: 5.499655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 10.393016 \n",
      "\n",
      "loss: 10.301131  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 4.045748 \n",
      "\n",
      "loss: 3.978571  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 15.452454 \n",
      "\n",
      "loss: 15.197392  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 16.119792 \n",
      "\n",
      "loss: 15.948450  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 16.507569 \n",
      "\n",
      "loss: 17.189537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.307088 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 122/500\n",
      "--------------------\n",
      "{'hl': [694, 115], 'alpha': 0.2697319410047761, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.3468674696243179}\n",
      "loss: 1.105574  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 356.994025 \n",
      "\n",
      "loss: 371.495972  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 68.316530 \n",
      "\n",
      "loss: 74.804047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 47.501571 \n",
      "\n",
      "loss: 50.996532  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 7.093294 \n",
      "\n",
      "loss: 6.971929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.922089 \n",
      "\n",
      "loss: 0.792698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.500482 \n",
      "\n",
      "loss: 0.509393  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.533563 \n",
      "\n",
      "loss: 0.504135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.498069 \n",
      "\n",
      "loss: 0.500129  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.501087 \n",
      "\n",
      "loss: 0.527578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.539747 \n",
      "\n",
      "loss: 0.545113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.522704 \n",
      "\n",
      "loss: 0.502059  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.550898 \n",
      "\n",
      "loss: 0.524949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.522833 \n",
      "\n",
      "loss: 0.526607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.523217 \n",
      "\n",
      "loss: 0.539461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.543351 \n",
      "\n",
      "loss: 0.503195  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.568965 \n",
      "\n",
      "loss: 0.593049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.578902 \n",
      "\n",
      "loss: 0.559258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.574354 \n",
      "\n",
      "loss: 0.585926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.584476 \n",
      "\n",
      "loss: 0.612373  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.578671 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 123/500\n",
      "--------------------\n",
      "{'hl': [686, 418], 'alpha': 0.17958255201676637, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.04412109040861671}\n",
      "loss: 1.107398  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.150200 \n",
      "\n",
      "loss: 1.128782  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.581111 \n",
      "\n",
      "loss: 0.562497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.583255 \n",
      "\n",
      "loss: 0.572577  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.571248 \n",
      "\n",
      "loss: 0.579461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.602553 \n",
      "\n",
      "loss: 0.636511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.572264 \n",
      "\n",
      "loss: 0.584417  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.590633 \n",
      "\n",
      "loss: 0.593057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.591800 \n",
      "\n",
      "loss: 0.582352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.571517 \n",
      "\n",
      "loss: 0.579761  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.592388 \n",
      "\n",
      "loss: 0.602281  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.579928 \n",
      "\n",
      "loss: 0.580852  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.616284 \n",
      "\n",
      "loss: 0.614235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.598480 \n",
      "\n",
      "loss: 0.568815  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.581771 \n",
      "\n",
      "loss: 0.576874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.571259 \n",
      "\n",
      "loss: 0.575983  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.578346 \n",
      "\n",
      "loss: 0.569489  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.601321 \n",
      "\n",
      "loss: 0.576113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.593846 \n",
      "\n",
      "loss: 0.609538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.584381 \n",
      "\n",
      "loss: 0.603063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.591828 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 124/500\n",
      "--------------------\n",
      "{'hl': [339, 126], 'alpha': 0.7598693150444088, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.32886442720291614}\n",
      "loss: 1.202892  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.745663 \n",
      "\n",
      "loss: 1.748324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.446920 \n",
      "\n",
      "loss: 1.471413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.608320 \n",
      "\n",
      "loss: 1.564978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.488882 \n",
      "\n",
      "loss: 1.512811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.450172 \n",
      "\n",
      "loss: 1.461147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.423534 \n",
      "\n",
      "loss: 1.438046  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.527571 \n",
      "\n",
      "loss: 1.453150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.473330 \n",
      "\n",
      "loss: 1.401973  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.571394 \n",
      "\n",
      "loss: 1.561990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.517826 \n",
      "\n",
      "loss: 1.555628  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.673174 \n",
      "\n",
      "loss: 1.767396  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.404935 \n",
      "\n",
      "loss: 1.401825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.518165 \n",
      "\n",
      "loss: 1.536074  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.341311 \n",
      "\n",
      "loss: 1.355994  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.522707 \n",
      "\n",
      "loss: 1.525847  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.416416 \n",
      "\n",
      "loss: 1.408427  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.449708 \n",
      "\n",
      "loss: 1.306969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.539247 \n",
      "\n",
      "loss: 1.549432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.436326 \n",
      "\n",
      "loss: 1.468839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.218138 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 125/500\n",
      "--------------------\n",
      "{'hl': [481, 431, 63], 'alpha': 0.0005627689989211745, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.31274183019829}\n",
      "loss: 1.091219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 403.025682 \n",
      "\n",
      "loss: 402.125885  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 107.434642 \n",
      "\n",
      "loss: 131.753067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 111.187637 \n",
      "\n",
      "loss: 93.967865  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 55.102051 \n",
      "\n",
      "loss: 56.493053  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 19.054780 \n",
      "\n",
      "loss: 22.740057  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 37.342976 \n",
      "\n",
      "loss: 37.234573  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 13.786374 \n",
      "\n",
      "loss: 12.600313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 93.353699 \n",
      "\n",
      "loss: 70.003006  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 14.878109 \n",
      "\n",
      "loss: 14.196965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 18.894858 \n",
      "\n",
      "loss: 16.387550  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 12.751352 \n",
      "\n",
      "loss: 11.986198  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 5.634734 \n",
      "\n",
      "loss: 5.740386  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 11.272925 \n",
      "\n",
      "loss: 12.567855  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 8.239477 \n",
      "\n",
      "loss: 5.434306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 4.147873 \n",
      "\n",
      "loss: 3.807219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 10.299538 \n",
      "\n",
      "loss: 8.188961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 2.363011 \n",
      "\n",
      "loss: 2.344607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 2.443916 \n",
      "\n",
      "loss: 2.792149  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 4.876131 \n",
      "\n",
      "loss: 4.606544  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 1.457143 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 126/500\n",
      "--------------------\n",
      "{'hl': [216], 'alpha': 0.0011701053177848137, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.2191142359266819}\n",
      "loss: 1.119029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 1.718617 \n",
      "\n",
      "loss: 1.544194  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.596233 \n",
      "\n",
      "loss: 0.652656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.634110 \n",
      "\n",
      "loss: 0.591998  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.750910 \n",
      "\n",
      "loss: 0.844302  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.628261 \n",
      "\n",
      "loss: 0.638168  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 1.295092 \n",
      "\n",
      "loss: 1.161935  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.699494 \n",
      "\n",
      "loss: 0.697895  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.569831 \n",
      "\n",
      "loss: 1.604158  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.610955 \n",
      "\n",
      "loss: 0.594232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 1.802660 \n",
      "\n",
      "loss: 1.771376  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.752647 \n",
      "\n",
      "loss: 0.662159  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.917839 \n",
      "\n",
      "loss: 0.818669  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.657300 \n",
      "\n",
      "loss: 0.646747  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.130085 \n",
      "\n",
      "loss: 1.275825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 3.081004 \n",
      "\n",
      "loss: 3.125108  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.836409 \n",
      "\n",
      "loss: 0.847184  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.851978 \n",
      "\n",
      "loss: 0.804097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.771868 \n",
      "\n",
      "loss: 0.767494  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.853369 \n",
      "\n",
      "loss: 0.896085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.736781 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 127/500\n",
      "--------------------\n",
      "{'hl': [504, 132, 37], 'alpha': 0.7808853285573472, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.1554439941828282}\n",
      "loss: 1.092510  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991599 \n",
      "\n",
      "loss: 0.989090  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.992135 \n",
      "\n",
      "loss: 0.987184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.991099 \n",
      "\n",
      "loss: 0.990560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.991230 \n",
      "\n",
      "loss: 0.992220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.990804 \n",
      "\n",
      "loss: 0.988111  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991609 \n",
      "\n",
      "loss: 0.991192  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.993766 \n",
      "\n",
      "loss: 0.996023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.989410 \n",
      "\n",
      "loss: 0.989206  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.992139 \n",
      "\n",
      "loss: 0.991181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.990215 \n",
      "\n",
      "loss: 0.992709  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.993342 \n",
      "\n",
      "loss: 0.989396  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.992871 \n",
      "\n",
      "loss: 0.990649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.991107 \n",
      "\n",
      "loss: 0.991214  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.990145 \n",
      "\n",
      "loss: 0.991486  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.989949 \n",
      "\n",
      "loss: 0.988260  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991919 \n",
      "\n",
      "loss: 0.991555  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.993623 \n",
      "\n",
      "loss: 0.992752  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.990226 \n",
      "\n",
      "loss: 0.991560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.991733 \n",
      "\n",
      "loss: 0.994531  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.991878 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 128/500\n",
      "--------------------\n",
      "{'hl': [573], 'alpha': 0.004285117639831068, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.23077780229997383}\n",
      "loss: 1.165834  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.474842 \n",
      "\n",
      "loss: 0.478617  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.474867 \n",
      "\n",
      "loss: 0.445413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.452422 \n",
      "\n",
      "loss: 0.473064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.444352 \n",
      "\n",
      "loss: 0.438437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.454168 \n",
      "\n",
      "loss: 0.397166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.418672 \n",
      "\n",
      "loss: 0.416940  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.426616 \n",
      "\n",
      "loss: 0.456287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.420749 \n",
      "\n",
      "loss: 0.419005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.416082 \n",
      "\n",
      "loss: 0.406966  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.389979 \n",
      "\n",
      "loss: 0.382261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.418382 \n",
      "\n",
      "loss: 0.454027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.423822 \n",
      "\n",
      "loss: 0.457890  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.399297 \n",
      "\n",
      "loss: 0.423240  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.396981 \n",
      "\n",
      "loss: 0.427231  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.386219 \n",
      "\n",
      "loss: 0.390225  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.389074 \n",
      "\n",
      "loss: 0.411583  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.416094 \n",
      "\n",
      "loss: 0.421908  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.396628 \n",
      "\n",
      "loss: 0.387656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.394303 \n",
      "\n",
      "loss: 0.388745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.370801 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 129/500\n",
      "--------------------\n",
      "{'hl': [671], 'alpha': 0.2130947229697725, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.25448512033324894}\n",
      "loss: 1.038671  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 5.672078 \n",
      "\n",
      "loss: 5.718600  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.684935 \n",
      "\n",
      "loss: 5.750403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 3.124592 \n",
      "\n",
      "loss: 3.016674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 8.510916 \n",
      "\n",
      "loss: 8.431945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 30.1%, Avg loss: 4.805052 \n",
      "\n",
      "loss: 4.499395  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 8.052554 \n",
      "\n",
      "loss: 8.140390  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 9.031792 \n",
      "\n",
      "loss: 8.907526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 3.490657 \n",
      "\n",
      "loss: 3.532301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 13.811441 \n",
      "\n",
      "loss: 13.284174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 8.341307 \n",
      "\n",
      "loss: 8.247467  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 6.497249 \n",
      "\n",
      "loss: 6.382604  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.054953 \n",
      "\n",
      "loss: 1.133250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 3.931912 \n",
      "\n",
      "loss: 3.691620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.806626 \n",
      "\n",
      "loss: 1.777706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 6.294020 \n",
      "\n",
      "loss: 6.417588  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 8.184490 \n",
      "\n",
      "loss: 8.784023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 5.029346 \n",
      "\n",
      "loss: 4.712184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 3.716192 \n",
      "\n",
      "loss: 3.658903  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.337363 \n",
      "\n",
      "loss: 4.356932  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 9.375187 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 130/500\n",
      "--------------------\n",
      "{'hl': [433, 502], 'alpha': 0.8336399721505842, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.2756774119325468}\n",
      "loss: 1.072144  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 25.5%, Avg loss: 3.335912 \n",
      "\n",
      "loss: 3.228538  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 39.9%, Avg loss: 20.655696 \n",
      "\n",
      "loss: 21.495972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 12.179972 \n",
      "\n",
      "loss: 12.455637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 3.784967 \n",
      "\n",
      "loss: 4.097204  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 10.389848 \n",
      "\n",
      "loss: 10.196898  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 27.8%, Avg loss: 4.871125 \n",
      "\n",
      "loss: 4.812382  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 11.228136 \n",
      "\n",
      "loss: 10.757120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 7.089355 \n",
      "\n",
      "loss: 7.020568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 22.046366 \n",
      "\n",
      "loss: 21.229660  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 7.798007 \n",
      "\n",
      "loss: 7.542298  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 7.539683 \n",
      "\n",
      "loss: 7.128284  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 30.9%, Avg loss: 4.718138 \n",
      "\n",
      "loss: 4.721287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 12.403005 \n",
      "\n",
      "loss: 11.183830  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 2.378352 \n",
      "\n",
      "loss: 2.620938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 33.0%, Avg loss: 32.926450 \n",
      "\n",
      "loss: 31.867998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 5.986523 \n",
      "\n",
      "loss: 5.884945  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 9.883456 \n",
      "\n",
      "loss: 9.792467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 5.847935 \n",
      "\n",
      "loss: 5.540207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 16.1%, Avg loss: 16.395391 \n",
      "\n",
      "loss: 16.520102  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 29.9%, Avg loss: 11.600721 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 131/500\n",
      "--------------------\n",
      "{'hl': [203, 621], 'alpha': 0.010788562115354372, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.13819607667073827}\n",
      "loss: 1.143675  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.517801 \n",
      "\n",
      "loss: 0.518052  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.496070 \n",
      "\n",
      "loss: 0.519083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.490743 \n",
      "\n",
      "loss: 0.462794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.449744 \n",
      "\n",
      "loss: 0.458543  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.448724 \n",
      "\n",
      "loss: 0.442461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.451165 \n",
      "\n",
      "loss: 0.497110  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.446085 \n",
      "\n",
      "loss: 0.447028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.443776 \n",
      "\n",
      "loss: 0.429150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.432090 \n",
      "\n",
      "loss: 0.389834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.419609 \n",
      "\n",
      "loss: 0.445293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.439267 \n",
      "\n",
      "loss: 0.467065  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.421069 \n",
      "\n",
      "loss: 0.385614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.423198 \n",
      "\n",
      "loss: 0.421620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.410769 \n",
      "\n",
      "loss: 0.414776  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.402792 \n",
      "\n",
      "loss: 0.395164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.404167 \n",
      "\n",
      "loss: 0.399548  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.407506 \n",
      "\n",
      "loss: 0.336277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.408606 \n",
      "\n",
      "loss: 0.385436  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.411807 \n",
      "\n",
      "loss: 0.389884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.396472 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 132/500\n",
      "--------------------\n",
      "{'hl': [356, 527], 'alpha': 0.0011713607087002625, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.3630528862085049}\n",
      "loss: 1.151222  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 759.034841 \n",
      "\n",
      "loss: 802.052856  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 200.067904 \n",
      "\n",
      "loss: 198.507339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 12.572220 \n",
      "\n",
      "loss: 14.065487  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 18.584173 \n",
      "\n",
      "loss: 0.705181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 12.599556 \n",
      "\n",
      "loss: 2.250376  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.815612 \n",
      "\n",
      "loss: 3.602157  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 3.470387 \n",
      "\n",
      "loss: 2.719429  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.707553 \n",
      "\n",
      "loss: 0.855558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 0.703801 \n",
      "\n",
      "loss: 1.192446  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.592029 \n",
      "\n",
      "loss: 0.612388  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.667574 \n",
      "\n",
      "loss: 0.887121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 22.034450 \n",
      "\n",
      "loss: 21.866465  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.711357 \n",
      "\n",
      "loss: 0.778363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 21.942400 \n",
      "\n",
      "loss: 19.323826  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.608477 \n",
      "\n",
      "loss: 0.604937  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.822085 \n",
      "\n",
      "loss: 1.106127  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.669593 \n",
      "\n",
      "loss: 0.629237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.842701 \n",
      "\n",
      "loss: 0.662423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.785889 \n",
      "\n",
      "loss: 0.571249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.576409 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 133/500\n",
      "--------------------\n",
      "{'hl': [601, 683, 509], 'alpha': 0.2890961970970559, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.17262745845233446}\n",
      "loss: 1.130350  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 9.574887 \n",
      "\n",
      "loss: 9.691242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.980755 \n",
      "\n",
      "loss: 6.010678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 24.828594 \n",
      "\n",
      "loss: 24.147652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.377248 \n",
      "\n",
      "loss: 5.886814  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 16.539065 \n",
      "\n",
      "loss: 16.472775  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 12.957922 \n",
      "\n",
      "loss: 12.872755  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.891785 \n",
      "\n",
      "loss: 2.560673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.214131 \n",
      "\n",
      "loss: 1.245112  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.970973 \n",
      "\n",
      "loss: 0.950420  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 14.936293 \n",
      "\n",
      "loss: 15.107219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 7.236440 \n",
      "\n",
      "loss: 6.513092  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 10.685887 \n",
      "\n",
      "loss: 10.507811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 12.616928 \n",
      "\n",
      "loss: 12.418961  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.176841 \n",
      "\n",
      "loss: 2.122962  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.146645 \n",
      "\n",
      "loss: 6.250718  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.209435 \n",
      "\n",
      "loss: 5.765043  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.796641 \n",
      "\n",
      "loss: 3.803138  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 12.903039 \n",
      "\n",
      "loss: 13.403183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.213330 \n",
      "\n",
      "loss: 1.218166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 7.129855 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 134/500\n",
      "--------------------\n",
      "{'hl': [564, 394, 474], 'alpha': 0.5387769691484441, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.28594164122825205}\n",
      "loss: 1.116164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.966477 \n",
      "\n",
      "loss: 0.967720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.967378 \n",
      "\n",
      "loss: 0.963408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.965382 \n",
      "\n",
      "loss: 0.966718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.963949 \n",
      "\n",
      "loss: 0.959158  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.965195 \n",
      "\n",
      "loss: 0.963750  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.967103 \n",
      "\n",
      "loss: 0.965562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.969191 \n",
      "\n",
      "loss: 0.960395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.965865 \n",
      "\n",
      "loss: 0.958504  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.966250 \n",
      "\n",
      "loss: 0.969828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.963789 \n",
      "\n",
      "loss: 0.971761  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.966673 \n",
      "\n",
      "loss: 0.966502  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.968715 \n",
      "\n",
      "loss: 0.967235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.963244 \n",
      "\n",
      "loss: 0.963543  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.964520 \n",
      "\n",
      "loss: 0.965950  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.964974 \n",
      "\n",
      "loss: 0.964578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.965358 \n",
      "\n",
      "loss: 0.965377  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.968550 \n",
      "\n",
      "loss: 0.964157  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.966215 \n",
      "\n",
      "loss: 0.959573  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.966786 \n",
      "\n",
      "loss: 0.958030  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.963004 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 135/500\n",
      "--------------------\n",
      "{'hl': [428], 'alpha': 0.00014948210205850638, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.19310076837024207}\n",
      "loss: 1.269929  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 1.580935 \n",
      "\n",
      "loss: 1.715202  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.700537 \n",
      "\n",
      "loss: 0.658058  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 1.201165 \n",
      "\n",
      "loss: 1.213373  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 1.320487 \n",
      "\n",
      "loss: 1.315067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.940267 \n",
      "\n",
      "loss: 1.023551  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.491519 \n",
      "\n",
      "loss: 0.455222  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.404419 \n",
      "\n",
      "loss: 1.529492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.578481 \n",
      "\n",
      "loss: 0.567357  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.678644 \n",
      "\n",
      "loss: 0.711934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.089482 \n",
      "\n",
      "loss: 1.124326  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 1.261432 \n",
      "\n",
      "loss: 1.299563  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 1.051069 \n",
      "\n",
      "loss: 1.173359  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.703665 \n",
      "\n",
      "loss: 0.588821  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.876223 \n",
      "\n",
      "loss: 0.758533  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 1.131751 \n",
      "\n",
      "loss: 0.942985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.581791 \n",
      "\n",
      "loss: 0.597221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.667704 \n",
      "\n",
      "loss: 0.696715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.694293 \n",
      "\n",
      "loss: 0.725093  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 2.679330 \n",
      "\n",
      "loss: 2.837763  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.696059 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 136/500\n",
      "--------------------\n",
      "{'hl': [675, 163, 515], 'alpha': 0.7232655064629204, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.43486318664977147}\n",
      "loss: 1.102509  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 15.248209 \n",
      "\n",
      "loss: 15.927457  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 38.1%, Avg loss: 5.939439 \n",
      "\n",
      "loss: 6.172324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 7.438961 \n",
      "\n",
      "loss: 7.482636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 46.564615 \n",
      "\n",
      "loss: 47.322113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 20.5%, Avg loss: 26.042736 \n",
      "\n",
      "loss: 26.652050  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 18.3%, Avg loss: 25.595001 \n",
      "\n",
      "loss: 26.563972  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 12.2%, Avg loss: 49.321298 \n",
      "\n",
      "loss: 48.926247  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 52.423556 \n",
      "\n",
      "loss: 52.149731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 14.9%, Avg loss: 41.407995 \n",
      "\n",
      "loss: 40.172508  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 32.3%, Avg loss: 8.259776 \n",
      "\n",
      "loss: 8.013131  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 20.2%, Avg loss: 47.823964 \n",
      "\n",
      "loss: 47.732319  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 12.9%, Avg loss: 41.075336 \n",
      "\n",
      "loss: 41.261211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 11.385249 \n",
      "\n",
      "loss: 12.342259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 16.0%, Avg loss: 44.775528 \n",
      "\n",
      "loss: 45.790714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 37.9%, Avg loss: 11.758735 \n",
      "\n",
      "loss: 11.251648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 24.5%, Avg loss: 40.105445 \n",
      "\n",
      "loss: 38.534855  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 30.3%, Avg loss: 21.027548 \n",
      "\n",
      "loss: 20.620623  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 27.173469 \n",
      "\n",
      "loss: 27.353491  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 36.971880 \n",
      "\n",
      "loss: 36.760948  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 13.056331 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 137/500\n",
      "--------------------\n",
      "{'hl': [110, 546], 'alpha': 0.43829519625774976, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.20504831201120755}\n",
      "loss: 1.091998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.912755 \n",
      "\n",
      "loss: 0.917556  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.950887 \n",
      "\n",
      "loss: 0.949150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.951485 \n",
      "\n",
      "loss: 0.949709  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.952569 \n",
      "\n",
      "loss: 0.946465  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.949069 \n",
      "\n",
      "loss: 0.950659  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.950698 \n",
      "\n",
      "loss: 0.947392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.954097 \n",
      "\n",
      "loss: 0.953944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.949088 \n",
      "\n",
      "loss: 0.954675  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.950028 \n",
      "\n",
      "loss: 0.948204  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.951503 \n",
      "\n",
      "loss: 0.947656  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.952915 \n",
      "\n",
      "loss: 0.949773  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.954569 \n",
      "\n",
      "loss: 0.949157  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.950474 \n",
      "\n",
      "loss: 0.953572  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.950186 \n",
      "\n",
      "loss: 0.948610  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.949824 \n",
      "\n",
      "loss: 0.954917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.950939 \n",
      "\n",
      "loss: 0.946240  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.952130 \n",
      "\n",
      "loss: 0.947449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.948456 \n",
      "\n",
      "loss: 0.953777  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.950099 \n",
      "\n",
      "loss: 0.959357  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.950110 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 138/500\n",
      "--------------------\n",
      "{'hl': [166, 84, 488], 'alpha': 0.13369069010198215, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.3116673743209468}\n",
      "loss: 1.105581  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 4192.168349 \n",
      "\n",
      "loss: 4048.645020  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 87.782497 \n",
      "\n",
      "loss: 99.262939  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 5.684365 \n",
      "\n",
      "loss: 5.775822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.592686 \n",
      "\n",
      "loss: 0.663126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.617437 \n",
      "\n",
      "loss: 0.561324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.678578 \n",
      "\n",
      "loss: 0.592004  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.512147 \n",
      "\n",
      "loss: 0.521011  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.504952 \n",
      "\n",
      "loss: 0.528231  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.518185 \n",
      "\n",
      "loss: 0.486476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.534483 \n",
      "\n",
      "loss: 0.508712  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.566898 \n",
      "\n",
      "loss: 0.576576  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.475939 \n",
      "\n",
      "loss: 0.462271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.485221 \n",
      "\n",
      "loss: 0.407359  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.500186 \n",
      "\n",
      "loss: 0.561101  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.495353 \n",
      "\n",
      "loss: 0.461431  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.445842 \n",
      "\n",
      "loss: 0.431610  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.449835 \n",
      "\n",
      "loss: 0.458388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.479518 \n",
      "\n",
      "loss: 0.458780  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.445263 \n",
      "\n",
      "loss: 0.407877  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.421077 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 139/500\n",
      "--------------------\n",
      "{'hl': [673, 90], 'alpha': 0.2553060870230347, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3134369095860931}\n",
      "loss: 1.098385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.777749 \n",
      "\n",
      "loss: 1.768204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.950174 \n",
      "\n",
      "loss: 0.943074  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.845516 \n",
      "\n",
      "loss: 0.841575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.830572 \n",
      "\n",
      "loss: 0.841138  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.847443 \n",
      "\n",
      "loss: 0.838713  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.864837 \n",
      "\n",
      "loss: 0.859780  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.881353 \n",
      "\n",
      "loss: 0.874711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.938982 \n",
      "\n",
      "loss: 0.938315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 10.053787 \n",
      "\n",
      "loss: 10.461359  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 12.326561 \n",
      "\n",
      "loss: 12.363317  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 6.009052 \n",
      "\n",
      "loss: 6.112562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.248201 \n",
      "\n",
      "loss: 7.066874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.891659 \n",
      "\n",
      "loss: 3.894788  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.032292 \n",
      "\n",
      "loss: 4.065934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.122726 \n",
      "\n",
      "loss: 1.125439  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.491930 \n",
      "\n",
      "loss: 3.666165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.890991 \n",
      "\n",
      "loss: 0.897803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.239103 \n",
      "\n",
      "loss: 1.227719  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.567018 \n",
      "\n",
      "loss: 2.688395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.139524 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 140/500\n",
      "--------------------\n",
      "{'hl': [562, 44], 'alpha': 0.029501075321691463, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.49871321888581205}\n",
      "loss: 1.167312  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 3.019814 \n",
      "\n",
      "loss: 2.852827  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 2.455851 \n",
      "\n",
      "loss: 2.568139  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 1.987144 \n",
      "\n",
      "loss: 2.043199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.948059 \n",
      "\n",
      "loss: 2.070672  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 1.201500 \n",
      "\n",
      "loss: 1.212744  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.092571 \n",
      "\n",
      "loss: 1.114680  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 2.348877 \n",
      "\n",
      "loss: 2.256247  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 2.094932 \n",
      "\n",
      "loss: 2.154430  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.044174 \n",
      "\n",
      "loss: 1.001523  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.869136 \n",
      "\n",
      "loss: 0.936962  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.895543 \n",
      "\n",
      "loss: 1.909400  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 2.636745 \n",
      "\n",
      "loss: 2.630886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.962484 \n",
      "\n",
      "loss: 1.042426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 1.401666 \n",
      "\n",
      "loss: 1.451716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.4%, Avg loss: 1.769182 \n",
      "\n",
      "loss: 1.614666  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 3.310296 \n",
      "\n",
      "loss: 3.295384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 1.210135 \n",
      "\n",
      "loss: 1.028818  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.241588 \n",
      "\n",
      "loss: 1.213080  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.362504 \n",
      "\n",
      "loss: 1.459880  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 1.088731 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 141/500\n",
      "--------------------\n",
      "{'hl': [100, 452, 108], 'alpha': 0.11002180660603876, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.08326575688593967}\n",
      "loss: 1.113844  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.729441 \n",
      "\n",
      "loss: 2.931236  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 3.664061 \n",
      "\n",
      "loss: 3.537034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.614214 \n",
      "\n",
      "loss: 0.594427  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 0.830049 \n",
      "\n",
      "loss: 0.824083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 6.567589 \n",
      "\n",
      "loss: 5.953672  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.916670 \n",
      "\n",
      "loss: 0.914615  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 18.511653 \n",
      "\n",
      "loss: 18.238266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.952803 \n",
      "\n",
      "loss: 0.921985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 8.431911 \n",
      "\n",
      "loss: 8.970607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 35.901583 \n",
      "\n",
      "loss: 32.441185  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 0.932100 \n",
      "\n",
      "loss: 0.931151  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.528112 \n",
      "\n",
      "loss: 0.573516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.469164 \n",
      "\n",
      "loss: 0.432487  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.448479 \n",
      "\n",
      "loss: 0.428360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.474017 \n",
      "\n",
      "loss: 0.484296  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.463843 \n",
      "\n",
      "loss: 0.429267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.495521 \n",
      "\n",
      "loss: 0.488208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.503343 \n",
      "\n",
      "loss: 0.466076  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.488245 \n",
      "\n",
      "loss: 0.492379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.492087 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 142/500\n",
      "--------------------\n",
      "{'hl': [37, 55], 'alpha': 0.001983803568419695, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.1792958248159517}\n",
      "loss: 1.136711  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.640373 \n",
      "\n",
      "loss: 0.628384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.509327 \n",
      "\n",
      "loss: 0.482956  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.635152 \n",
      "\n",
      "loss: 0.708894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.511677 \n",
      "\n",
      "loss: 0.524455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.468271 \n",
      "\n",
      "loss: 0.486154  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.428378 \n",
      "\n",
      "loss: 0.449174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.387980 \n",
      "\n",
      "loss: 0.367908  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.419432 \n",
      "\n",
      "loss: 0.419741  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.442838 \n",
      "\n",
      "loss: 0.405834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.428918 \n",
      "\n",
      "loss: 0.407316  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.406461 \n",
      "\n",
      "loss: 0.408489  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.424532 \n",
      "\n",
      "loss: 0.414487  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.392757 \n",
      "\n",
      "loss: 0.353371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.388057 \n",
      "\n",
      "loss: 0.374348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.391977 \n",
      "\n",
      "loss: 0.428665  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.398842 \n",
      "\n",
      "loss: 0.377931  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.417909 \n",
      "\n",
      "loss: 0.419803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.391227 \n",
      "\n",
      "loss: 0.430277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.390775 \n",
      "\n",
      "loss: 0.460611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.411225 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 143/500\n",
      "--------------------\n",
      "{'hl': [157, 258], 'alpha': 0.013324940320570246, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.087617170595946}\n",
      "loss: 1.060970  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.540609 \n",
      "\n",
      "loss: 0.549901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.505050 \n",
      "\n",
      "loss: 0.486758  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.490415 \n",
      "\n",
      "loss: 0.491304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.477861 \n",
      "\n",
      "loss: 0.511684  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.477825 \n",
      "\n",
      "loss: 0.481798  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.467832 \n",
      "\n",
      "loss: 0.426648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.470684 \n",
      "\n",
      "loss: 0.445425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.463853 \n",
      "\n",
      "loss: 0.467607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.451084 \n",
      "\n",
      "loss: 0.437870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.445968 \n",
      "\n",
      "loss: 0.423391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.459351 \n",
      "\n",
      "loss: 0.428591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.440804 \n",
      "\n",
      "loss: 0.408248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.441746 \n",
      "\n",
      "loss: 0.419508  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.435680 \n",
      "\n",
      "loss: 0.461763  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.435918 \n",
      "\n",
      "loss: 0.441086  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.428806 \n",
      "\n",
      "loss: 0.415673  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.442877 \n",
      "\n",
      "loss: 0.411571  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.419267 \n",
      "\n",
      "loss: 0.432434  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.422529 \n",
      "\n",
      "loss: 0.469427  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.422047 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 144/500\n",
      "--------------------\n",
      "{'hl': [399, 642, 707], 'alpha': 0.0009190077364881501, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.23062884168616327}\n",
      "loss: 1.102035  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.480953 \n",
      "\n",
      "loss: 0.512416  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.461451 \n",
      "\n",
      "loss: 0.506415  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.438600 \n",
      "\n",
      "loss: 0.442842  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.441078 \n",
      "\n",
      "loss: 0.414629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.432915 \n",
      "\n",
      "loss: 0.426359  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.411709 \n",
      "\n",
      "loss: 0.414638  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.434557 \n",
      "\n",
      "loss: 0.444292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.413419 \n",
      "\n",
      "loss: 0.391413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.434462 \n",
      "\n",
      "loss: 0.423106  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.421507 \n",
      "\n",
      "loss: 0.444502  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.428971 \n",
      "\n",
      "loss: 0.432695  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.387398 \n",
      "\n",
      "loss: 0.361911  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.396147 \n",
      "\n",
      "loss: 0.367648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.391265 \n",
      "\n",
      "loss: 0.365264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364931 \n",
      "\n",
      "loss: 0.395756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.361155 \n",
      "\n",
      "loss: 0.393640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.368547 \n",
      "\n",
      "loss: 0.396911  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.358970 \n",
      "\n",
      "loss: 0.350720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.452186 \n",
      "\n",
      "loss: 0.426961  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.354810 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 145/500\n",
      "--------------------\n",
      "{'hl': [478, 269], 'alpha': 0.04649035570660109, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.33883768176096984}\n",
      "loss: 1.041607  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 10.290478 \n",
      "\n",
      "loss: 10.054569  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.837259 \n",
      "\n",
      "loss: 6.270924  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.034283 \n",
      "\n",
      "loss: 1.953772  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 7.530441 \n",
      "\n",
      "loss: 7.397918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.336022 \n",
      "\n",
      "loss: 4.546283  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 4.397311 \n",
      "\n",
      "loss: 4.495272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 12.911503 \n",
      "\n",
      "loss: 13.037937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 30.658278 \n",
      "\n",
      "loss: 31.062361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 4.524106 \n",
      "\n",
      "loss: 4.352894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.210372 \n",
      "\n",
      "loss: 6.477098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.492605 \n",
      "\n",
      "loss: 3.328016  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.942027 \n",
      "\n",
      "loss: 5.794556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 18.486225 \n",
      "\n",
      "loss: 17.844597  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.000349 \n",
      "\n",
      "loss: 2.900297  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.733033 \n",
      "\n",
      "loss: 2.413515  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 12.789578 \n",
      "\n",
      "loss: 12.642797  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 4.654439 \n",
      "\n",
      "loss: 4.522203  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 8.585746 \n",
      "\n",
      "loss: 8.664500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.377853 \n",
      "\n",
      "loss: 3.690758  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.941955 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 146/500\n",
      "--------------------\n",
      "{'hl': [83], 'alpha': 0.005846812064319847, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.3195054573097701}\n",
      "loss: 1.088667  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 7.470611 \n",
      "\n",
      "loss: 7.377049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 2.545809 \n",
      "\n",
      "loss: 2.049241  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.679560 \n",
      "\n",
      "loss: 0.644600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.579417 \n",
      "\n",
      "loss: 0.549321  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.432138 \n",
      "\n",
      "loss: 0.471485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.403200 \n",
      "\n",
      "loss: 0.409756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.438500 \n",
      "\n",
      "loss: 0.464281  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.435507 \n",
      "\n",
      "loss: 0.399872  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.430773 \n",
      "\n",
      "loss: 0.459497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.398716 \n",
      "\n",
      "loss: 0.406221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.429670 \n",
      "\n",
      "loss: 0.434018  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.418715 \n",
      "\n",
      "loss: 0.439232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.418732 \n",
      "\n",
      "loss: 0.448486  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.440202 \n",
      "\n",
      "loss: 0.446879  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.423746 \n",
      "\n",
      "loss: 0.395581  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.406163 \n",
      "\n",
      "loss: 0.403162  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.431683 \n",
      "\n",
      "loss: 0.381704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.437074 \n",
      "\n",
      "loss: 0.425843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.472757 \n",
      "\n",
      "loss: 0.420349  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.425608 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 147/500\n",
      "--------------------\n",
      "{'hl': [714, 264], 'alpha': 0.0067195973580600555, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4996868453935396}\n",
      "loss: 1.084156  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.440009 \n",
      "\n",
      "loss: 0.389520  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.416899 \n",
      "\n",
      "loss: 0.366393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.393791 \n",
      "\n",
      "loss: 0.404088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.365479 \n",
      "\n",
      "loss: 0.366418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.351511 \n",
      "\n",
      "loss: 0.361229  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.380952 \n",
      "\n",
      "loss: 0.368146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.362104 \n",
      "\n",
      "loss: 0.365032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.425170 \n",
      "\n",
      "loss: 0.425949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.351605 \n",
      "\n",
      "loss: 0.372521  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.342284 \n",
      "\n",
      "loss: 0.341354  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.336148 \n",
      "\n",
      "loss: 0.315298  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.355306 \n",
      "\n",
      "loss: 0.342922  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.360464 \n",
      "\n",
      "loss: 0.302611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.353894 \n",
      "\n",
      "loss: 0.400497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.337760 \n",
      "\n",
      "loss: 0.339659  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.334972 \n",
      "\n",
      "loss: 0.361487  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.348775 \n",
      "\n",
      "loss: 0.370629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.336942 \n",
      "\n",
      "loss: 0.355422  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.429646 \n",
      "\n",
      "loss: 0.425442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.334976 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 148/500\n",
      "--------------------\n",
      "{'hl': [117, 250], 'alpha': 0.0033531824975850167, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.49634675260908606}\n",
      "loss: 1.105428  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 434.984036 \n",
      "\n",
      "loss: 425.891205  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 91.526777 \n",
      "\n",
      "loss: 80.713600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 16.661802 \n",
      "\n",
      "loss: 18.304256  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 8.233014 \n",
      "\n",
      "loss: 7.389472  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 2.492651 \n",
      "\n",
      "loss: 3.133580  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 3.607990 \n",
      "\n",
      "loss: 3.673414  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 2.470657 \n",
      "\n",
      "loss: 2.088084  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.743998 \n",
      "\n",
      "loss: 0.587608  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.675841 \n",
      "\n",
      "loss: 0.740903  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 7.095645 \n",
      "\n",
      "loss: 6.607138  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.781354 \n",
      "\n",
      "loss: 0.513749  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.492893 \n",
      "\n",
      "loss: 0.431685  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.415643 \n",
      "\n",
      "loss: 0.419317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 1.279146 \n",
      "\n",
      "loss: 0.862008  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.378374 \n",
      "\n",
      "loss: 0.414785  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.365659 \n",
      "\n",
      "loss: 0.347162  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.369642 \n",
      "\n",
      "loss: 0.407443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.361359 \n",
      "\n",
      "loss: 0.381606  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.349456 \n",
      "\n",
      "loss: 0.342508  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.349430 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 149/500\n",
      "--------------------\n",
      "{'hl': [30, 682], 'alpha': 0.0038302133323041827, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.4553174151639834}\n",
      "loss: 1.098615  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.442399 \n",
      "\n",
      "loss: 0.439791  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.413640 \n",
      "\n",
      "loss: 0.343073  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.402352 \n",
      "\n",
      "loss: 0.417041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.372797 \n",
      "\n",
      "loss: 0.400049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.357571 \n",
      "\n",
      "loss: 0.343003  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.362340 \n",
      "\n",
      "loss: 0.372378  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.398922 \n",
      "\n",
      "loss: 0.371411  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.347716 \n",
      "\n",
      "loss: 0.338154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.364674 \n",
      "\n",
      "loss: 0.363248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.333560 \n",
      "\n",
      "loss: 0.323231  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.353549 \n",
      "\n",
      "loss: 0.316530  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.354169 \n",
      "\n",
      "loss: 0.347529  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.335020 \n",
      "\n",
      "loss: 0.355989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.339774 \n",
      "\n",
      "loss: 0.349995  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.310509 \n",
      "\n",
      "loss: 0.310486  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.321895 \n",
      "\n",
      "loss: 0.354485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.342831 \n",
      "\n",
      "loss: 0.327195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.331619 \n",
      "\n",
      "loss: 0.344169  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.339960 \n",
      "\n",
      "loss: 0.353502  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.353658 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 150/500\n",
      "--------------------\n",
      "{'hl': [516, 301, 243], 'alpha': 0.02680772703099211, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.31834527721514533}\n",
      "loss: 1.102001  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.485139 \n",
      "\n",
      "loss: 0.471528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.446148 \n",
      "\n",
      "loss: 0.431314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.444331 \n",
      "\n",
      "loss: 0.439416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.410954 \n",
      "\n",
      "loss: 0.415871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.389338 \n",
      "\n",
      "loss: 0.368424  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.409755 \n",
      "\n",
      "loss: 0.397418  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.402608 \n",
      "\n",
      "loss: 0.387027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.415297 \n",
      "\n",
      "loss: 0.406845  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.397549 \n",
      "\n",
      "loss: 0.404180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.383794 \n",
      "\n",
      "loss: 0.373338  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.402411 \n",
      "\n",
      "loss: 0.360710  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.403879 \n",
      "\n",
      "loss: 0.399361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.381232 \n",
      "\n",
      "loss: 0.373941  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.389442 \n",
      "\n",
      "loss: 0.363815  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.373948 \n",
      "\n",
      "loss: 0.375499  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.387028 \n",
      "\n",
      "loss: 0.364479  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.395638 \n",
      "\n",
      "loss: 0.387802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.388944 \n",
      "\n",
      "loss: 0.359767  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.386001 \n",
      "\n",
      "loss: 0.395666  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.382095 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 151/500\n",
      "--------------------\n",
      "{'hl': [264, 702, 683], 'alpha': 0.05289570096799692, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.45171151166607665}\n",
      "loss: 1.108765  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.515443 \n",
      "\n",
      "loss: 0.539417  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.534912 \n",
      "\n",
      "loss: 0.563056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.512325 \n",
      "\n",
      "loss: 0.525738  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.507233 \n",
      "\n",
      "loss: 0.503443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.510136 \n",
      "\n",
      "loss: 0.483149  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.503980 \n",
      "\n",
      "loss: 0.487948  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.508711 \n",
      "\n",
      "loss: 0.497181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.533443 \n",
      "\n",
      "loss: 0.538056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.504573 \n",
      "\n",
      "loss: 0.521071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.501454 \n",
      "\n",
      "loss: 0.435633  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.501230 \n",
      "\n",
      "loss: 0.508986  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.502697 \n",
      "\n",
      "loss: 0.517971  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.500350 \n",
      "\n",
      "loss: 0.492736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.498515 \n",
      "\n",
      "loss: 0.512046  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.504352 \n",
      "\n",
      "loss: 0.499036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.490832 \n",
      "\n",
      "loss: 0.516496  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.503939 \n",
      "\n",
      "loss: 0.494385  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.493647 \n",
      "\n",
      "loss: 0.484561  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.500672 \n",
      "\n",
      "loss: 0.524824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.501234 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 152/500\n",
      "--------------------\n",
      "{'hl': [48, 324, 459], 'alpha': 0.0001359747049077527, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.04515767453553485}\n",
      "loss: 1.106128  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.707722 \n",
      "\n",
      "loss: 0.703883  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.554556 \n",
      "\n",
      "loss: 0.587828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.513365 \n",
      "\n",
      "loss: 0.531921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.490060 \n",
      "\n",
      "loss: 0.510890  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.481416 \n",
      "\n",
      "loss: 0.506088  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.465475 \n",
      "\n",
      "loss: 0.437136  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.458902 \n",
      "\n",
      "loss: 0.435484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.439034 \n",
      "\n",
      "loss: 0.403428  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.435777 \n",
      "\n",
      "loss: 0.456568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.421107 \n",
      "\n",
      "loss: 0.421383  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.417896 \n",
      "\n",
      "loss: 0.371002  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.413364 \n",
      "\n",
      "loss: 0.408846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.404501 \n",
      "\n",
      "loss: 0.373141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.398189 \n",
      "\n",
      "loss: 0.408983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.390180 \n",
      "\n",
      "loss: 0.393311  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.404148 \n",
      "\n",
      "loss: 0.396799  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.387796 \n",
      "\n",
      "loss: 0.380016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.387488 \n",
      "\n",
      "loss: 0.383443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.373231 \n",
      "\n",
      "loss: 0.386134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.376062 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 153/500\n",
      "--------------------\n",
      "{'hl': [342, 433], 'alpha': 0.0005041505923255805, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.2654731016140222}\n",
      "loss: 1.117551  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 2.486724 \n",
      "\n",
      "loss: 2.320752  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 2.417417 \n",
      "\n",
      "loss: 2.449766  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 2.099264 \n",
      "\n",
      "loss: 2.256655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 2.463771 \n",
      "\n",
      "loss: 2.804352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 2.035493 \n",
      "\n",
      "loss: 2.282025  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.535623 \n",
      "\n",
      "loss: 1.647406  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 1.835163 \n",
      "\n",
      "loss: 1.915089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 3.208915 \n",
      "\n",
      "loss: 2.964881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 3.059805 \n",
      "\n",
      "loss: 2.552239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 5.380042 \n",
      "\n",
      "loss: 5.732728  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 1.508415 \n",
      "\n",
      "loss: 1.781372  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.679668 \n",
      "\n",
      "loss: 1.791182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 2.325420 \n",
      "\n",
      "loss: 2.253864  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 3.578670 \n",
      "\n",
      "loss: 3.883928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 2.832645 \n",
      "\n",
      "loss: 2.947088  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 2.142518 \n",
      "\n",
      "loss: 1.998469  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 3.806624 \n",
      "\n",
      "loss: 3.807362  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.993267 \n",
      "\n",
      "loss: 1.000431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 1.700355 \n",
      "\n",
      "loss: 1.753775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 2.751484 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 154/500\n",
      "--------------------\n",
      "{'hl': [176, 271], 'alpha': 0.45310182784051356, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3733050194234508}\n",
      "loss: 1.227319  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.220497 \n",
      "\n",
      "loss: 11.145920  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.443905 \n",
      "\n",
      "loss: 1.421087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.564765 \n",
      "\n",
      "loss: 1.699619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.159576 \n",
      "\n",
      "loss: 1.198554  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.402733 \n",
      "\n",
      "loss: 1.547578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 6.655967 \n",
      "\n",
      "loss: 6.759851  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.350934 \n",
      "\n",
      "loss: 7.048212  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 2.266515 \n",
      "\n",
      "loss: 1.842507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 9.452883 \n",
      "\n",
      "loss: 8.832376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.571643 \n",
      "\n",
      "loss: 4.760946  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.408039 \n",
      "\n",
      "loss: 1.341961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 3.928343 \n",
      "\n",
      "loss: 3.963578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 6.194011 \n",
      "\n",
      "loss: 6.604804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 9.028725 \n",
      "\n",
      "loss: 9.069958  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.416169 \n",
      "\n",
      "loss: 1.544404  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 12.191682 \n",
      "\n",
      "loss: 12.553494  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 6.585012 \n",
      "\n",
      "loss: 6.456332  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 10.101134 \n",
      "\n",
      "loss: 10.979529  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.506451 \n",
      "\n",
      "loss: 5.472561  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 3.776939 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 155/500\n",
      "--------------------\n",
      "{'hl': [125, 487], 'alpha': 0.7105148699856632, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.430084284389721}\n",
      "loss: 1.059533  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.986001 \n",
      "\n",
      "loss: 0.987769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.986911 \n",
      "\n",
      "loss: 0.987375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.983181 \n",
      "\n",
      "loss: 0.983432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.985472 \n",
      "\n",
      "loss: 0.989169  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.983494 \n",
      "\n",
      "loss: 0.985495  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.986675 \n",
      "\n",
      "loss: 0.989272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.988090 \n",
      "\n",
      "loss: 0.986374  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.982808 \n",
      "\n",
      "loss: 0.987941  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.983460 \n",
      "\n",
      "loss: 0.984964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.981859 \n",
      "\n",
      "loss: 0.980284  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.985303 \n",
      "\n",
      "loss: 0.981117  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.987055 \n",
      "\n",
      "loss: 0.987035  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.983218 \n",
      "\n",
      "loss: 0.981550  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.985998 \n",
      "\n",
      "loss: 0.986476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.985878 \n",
      "\n",
      "loss: 0.987107  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.985566 \n",
      "\n",
      "loss: 0.978901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.988415 \n",
      "\n",
      "loss: 0.982995  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.984479 \n",
      "\n",
      "loss: 0.988240  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.983270 \n",
      "\n",
      "loss: 0.983085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.982555 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 156/500\n",
      "--------------------\n",
      "{'hl': [698, 414, 578], 'alpha': 0.0029046927291390377, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.13230284331837666}\n",
      "loss: 1.085799  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.151254 \n",
      "\n",
      "loss: 1.149361  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.840123 \n",
      "\n",
      "loss: 0.836101  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.817972 \n",
      "\n",
      "loss: 0.831932  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.817169 \n",
      "\n",
      "loss: 0.840963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.835938 \n",
      "\n",
      "loss: 0.808991  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.826186 \n",
      "\n",
      "loss: 0.811566  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.832516 \n",
      "\n",
      "loss: 0.814235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815000 \n",
      "\n",
      "loss: 0.800954  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.822768 \n",
      "\n",
      "loss: 0.844806  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.830786 \n",
      "\n",
      "loss: 0.834596  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.827469 \n",
      "\n",
      "loss: 0.824698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.845456 \n",
      "\n",
      "loss: 0.842679  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 0.817107 \n",
      "\n",
      "loss: 0.823377  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.800846 \n",
      "\n",
      "loss: 0.824280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.836352 \n",
      "\n",
      "loss: 0.829241  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.823103 \n",
      "\n",
      "loss: 0.820873  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.834038 \n",
      "\n",
      "loss: 0.823575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.835414 \n",
      "\n",
      "loss: 0.842354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.908852 \n",
      "\n",
      "loss: 0.935718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.768182 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 157/500\n",
      "--------------------\n",
      "{'hl': [473], 'alpha': 0.0029808672423110457, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.41122640888326445}\n",
      "loss: 1.174420  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 77.627454 \n",
      "\n",
      "loss: 67.653923  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 6.130486 \n",
      "\n",
      "loss: 5.790390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.262134 \n",
      "\n",
      "loss: 1.136017  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 1.002582 \n",
      "\n",
      "loss: 0.901320  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.595553 \n",
      "\n",
      "loss: 1.467726  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 1.710159 \n",
      "\n",
      "loss: 1.662799  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.705419 \n",
      "\n",
      "loss: 0.652722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 36.825257 \n",
      "\n",
      "loss: 39.107021  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 12.027233 \n",
      "\n",
      "loss: 15.615320  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 42.533416 \n",
      "\n",
      "loss: 44.181416  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 75.502626 \n",
      "\n",
      "loss: 80.779228  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 20.552578 \n",
      "\n",
      "loss: 17.542498  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 41.949311 \n",
      "\n",
      "loss: 38.360245  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 58.072233 \n",
      "\n",
      "loss: 59.974045  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 9.952706 \n",
      "\n",
      "loss: 10.225766  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 2.758534 \n",
      "\n",
      "loss: 1.973810  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 1.107564 \n",
      "\n",
      "loss: 0.863393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 3.375132 \n",
      "\n",
      "loss: 2.699473  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 19.073928 \n",
      "\n",
      "loss: 21.989069  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 22.006055 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 158/500\n",
      "--------------------\n",
      "{'hl': [118, 699], 'alpha': 0.000861564128838507, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4576364287807054}\n",
      "loss: 1.092323  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 750.037743 \n",
      "\n",
      "loss: 537.770874  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 122.284242 \n",
      "\n",
      "loss: 237.004166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 139.538581 \n",
      "\n",
      "loss: 93.185463  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 53.806922 \n",
      "\n",
      "loss: 39.809368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 20.169895 \n",
      "\n",
      "loss: 19.890911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 17.093205 \n",
      "\n",
      "loss: 5.767368  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 3.779438 \n",
      "\n",
      "loss: 2.821704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 2.447217 \n",
      "\n",
      "loss: 3.816649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 3.524531 \n",
      "\n",
      "loss: 1.910421  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 2.522517 \n",
      "\n",
      "loss: 2.782006  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 12.764084 \n",
      "\n",
      "loss: 17.864288  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 2.691139 \n",
      "\n",
      "loss: 3.276030  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 3.653964 \n",
      "\n",
      "loss: 3.602476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 2.403242 \n",
      "\n",
      "loss: 1.942036  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.711600 \n",
      "\n",
      "loss: 1.793317  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.834077 \n",
      "\n",
      "loss: 1.806164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 2.454387 \n",
      "\n",
      "loss: 1.975351  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 2.379530 \n",
      "\n",
      "loss: 1.949088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 4.043466 \n",
      "\n",
      "loss: 3.826123  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 3.319741 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 159/500\n",
      "--------------------\n",
      "{'hl': [671], 'alpha': 0.0001790062376396911, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3246547991976671}\n",
      "loss: 0.962020  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 6.512242 \n",
      "\n",
      "loss: 7.064920  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 3.564017 \n",
      "\n",
      "loss: 3.364697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 4.436573 \n",
      "\n",
      "loss: 4.418309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 1.401191 \n",
      "\n",
      "loss: 1.361620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 4.382232 \n",
      "\n",
      "loss: 4.864715  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 2.603113 \n",
      "\n",
      "loss: 2.827077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.520321 \n",
      "\n",
      "loss: 1.529629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 5.373552 \n",
      "\n",
      "loss: 4.913036  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 1.673761 \n",
      "\n",
      "loss: 1.584913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 4.128152 \n",
      "\n",
      "loss: 4.345944  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 4.630266 \n",
      "\n",
      "loss: 3.761077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 3.247777 \n",
      "\n",
      "loss: 3.237310  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 3.617749 \n",
      "\n",
      "loss: 3.824244  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.431752 \n",
      "\n",
      "loss: 1.537887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 3.811657 \n",
      "\n",
      "loss: 3.201170  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 4.840444 \n",
      "\n",
      "loss: 4.591409  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 2.280884 \n",
      "\n",
      "loss: 1.953804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 2.395881 \n",
      "\n",
      "loss: 2.456844  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 2.438117 \n",
      "\n",
      "loss: 2.651118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 3.682042 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 160/500\n",
      "--------------------\n",
      "{'hl': [151], 'alpha': 0.00015184036674618494, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4979640946400392}\n",
      "loss: 1.170900  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 30.181968 \n",
      "\n",
      "loss: 23.762732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 17.003210 \n",
      "\n",
      "loss: 22.595465  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 2.937500 \n",
      "\n",
      "loss: 3.716627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 1.198448 \n",
      "\n",
      "loss: 1.690313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.891716 \n",
      "\n",
      "loss: 0.724110  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.541566 \n",
      "\n",
      "loss: 0.385153  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.419153 \n",
      "\n",
      "loss: 0.367203  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.383063 \n",
      "\n",
      "loss: 0.383799  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.416400 \n",
      "\n",
      "loss: 0.338123  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.379522 \n",
      "\n",
      "loss: 0.378283  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.376656 \n",
      "\n",
      "loss: 0.339621  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.433476 \n",
      "\n",
      "loss: 0.345530  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.384794 \n",
      "\n",
      "loss: 0.357317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.390013 \n",
      "\n",
      "loss: 0.357558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.431931 \n",
      "\n",
      "loss: 0.462713  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.576479 \n",
      "\n",
      "loss: 0.461759  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.628992 \n",
      "\n",
      "loss: 0.589418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.463843 \n",
      "\n",
      "loss: 0.428079  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.392729 \n",
      "\n",
      "loss: 0.360233  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.369312 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 161/500\n",
      "--------------------\n",
      "{'hl': [107], 'alpha': 0.0008693609521906058, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.2268765140687574}\n",
      "loss: 1.077602  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.593797 \n",
      "\n",
      "loss: 0.461236  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.439749 \n",
      "\n",
      "loss: 0.435056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.564523 \n",
      "\n",
      "loss: 0.636205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.473206 \n",
      "\n",
      "loss: 0.468774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.576242 \n",
      "\n",
      "loss: 0.595828  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.483098 \n",
      "\n",
      "loss: 0.497121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.463782 \n",
      "\n",
      "loss: 0.449597  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.505373 \n",
      "\n",
      "loss: 0.511386  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.529814 \n",
      "\n",
      "loss: 0.527156  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.545822 \n",
      "\n",
      "loss: 0.514282  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.524463 \n",
      "\n",
      "loss: 0.550632  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.587787 \n",
      "\n",
      "loss: 0.578702  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.550166 \n",
      "\n",
      "loss: 0.527068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.598257 \n",
      "\n",
      "loss: 0.588126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.611962 \n",
      "\n",
      "loss: 0.584517  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.537589 \n",
      "\n",
      "loss: 0.567701  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.532098 \n",
      "\n",
      "loss: 0.516150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.430001 \n",
      "\n",
      "loss: 0.433544  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.522122 \n",
      "\n",
      "loss: 0.519216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.427691 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 162/500\n",
      "--------------------\n",
      "{'hl': [561, 437, 609], 'alpha': 0.09312709569612082, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.32749545655698264}\n",
      "loss: 1.122629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 34.6%, Avg loss: 15.719636 \n",
      "\n",
      "loss: 16.196146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 10.537071 \n",
      "\n",
      "loss: 9.872632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 2.978995 \n",
      "\n",
      "loss: 3.479276  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 15.860000 \n",
      "\n",
      "loss: 16.170258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 25.321785 \n",
      "\n",
      "loss: 23.388073  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 18.557963 \n",
      "\n",
      "loss: 17.351099  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 10.579153 \n",
      "\n",
      "loss: 9.691894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 24.095708 \n",
      "\n",
      "loss: 24.127537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 38.6%, Avg loss: 16.196761 \n",
      "\n",
      "loss: 15.739748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 9.667695 \n",
      "\n",
      "loss: 10.056967  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 16.966688 \n",
      "\n",
      "loss: 15.884405  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.8%, Avg loss: 15.443900 \n",
      "\n",
      "loss: 15.768371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 30.6%, Avg loss: 20.816359 \n",
      "\n",
      "loss: 21.309217  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 17.928493 \n",
      "\n",
      "loss: 19.053762  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 20.242770 \n",
      "\n",
      "loss: 21.092300  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 29.9%, Avg loss: 14.515050 \n",
      "\n",
      "loss: 14.139445  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 31.267746 \n",
      "\n",
      "loss: 31.016968  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 22.104750 \n",
      "\n",
      "loss: 21.256456  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 11.092034 \n",
      "\n",
      "loss: 11.531251  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 11.575968 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 163/500\n",
      "--------------------\n",
      "{'hl': [638, 425], 'alpha': 0.5704430100531795, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.345171303807407}\n",
      "loss: 1.105894  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.968730 \n",
      "\n",
      "loss: 0.970461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.974608 \n",
      "\n",
      "loss: 0.973277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.970598 \n",
      "\n",
      "loss: 0.973567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.972821 \n",
      "\n",
      "loss: 0.973440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.971858 \n",
      "\n",
      "loss: 0.975689  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.969603 \n",
      "\n",
      "loss: 0.968577  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.968658 \n",
      "\n",
      "loss: 0.960148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.969722 \n",
      "\n",
      "loss: 0.968143  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.968990 \n",
      "\n",
      "loss: 0.969053  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.968552 \n",
      "\n",
      "loss: 0.970678  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.969263 \n",
      "\n",
      "loss: 0.969494  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.974456 \n",
      "\n",
      "loss: 0.973372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.967261 \n",
      "\n",
      "loss: 0.972985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.967471 \n",
      "\n",
      "loss: 0.972548  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.971066 \n",
      "\n",
      "loss: 0.967191  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.966588 \n",
      "\n",
      "loss: 0.968906  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.970100 \n",
      "\n",
      "loss: 0.966366  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.968966 \n",
      "\n",
      "loss: 0.971087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.968501 \n",
      "\n",
      "loss: 0.966132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.967229 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 164/500\n",
      "--------------------\n",
      "{'hl': [462], 'alpha': 0.006008740370107799, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.049767376840604546}\n",
      "loss: 1.089765  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.497585 \n",
      "\n",
      "loss: 0.553560  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.490627 \n",
      "\n",
      "loss: 0.498313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.417967 \n",
      "\n",
      "loss: 0.414753  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.439772 \n",
      "\n",
      "loss: 0.439238  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.406381 \n",
      "\n",
      "loss: 0.414249  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.417380 \n",
      "\n",
      "loss: 0.431580  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.420047 \n",
      "\n",
      "loss: 0.408398  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.423365 \n",
      "\n",
      "loss: 0.403265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.392518 \n",
      "\n",
      "loss: 0.405148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.407680 \n",
      "\n",
      "loss: 0.390988  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.398501 \n",
      "\n",
      "loss: 0.405858  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.421453 \n",
      "\n",
      "loss: 0.398930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.418579 \n",
      "\n",
      "loss: 0.390331  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.406317 \n",
      "\n",
      "loss: 0.379928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.396891 \n",
      "\n",
      "loss: 0.475261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.412450 \n",
      "\n",
      "loss: 0.432539  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.434220 \n",
      "\n",
      "loss: 0.391353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.400427 \n",
      "\n",
      "loss: 0.411186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.436597 \n",
      "\n",
      "loss: 0.468138  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.435392 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 165/500\n",
      "--------------------\n",
      "{'hl': [384, 565, 668], 'alpha': 0.0027207921433876144, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.09498530022432368}\n",
      "loss: 1.331209  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 6.265705 \n",
      "\n",
      "loss: 5.924789  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.869062 \n",
      "\n",
      "loss: 1.764685  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 4.028475 \n",
      "\n",
      "loss: 4.077253  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.482162 \n",
      "\n",
      "loss: 3.936056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.249886 \n",
      "\n",
      "loss: 3.162625  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 4.848044 \n",
      "\n",
      "loss: 3.826130  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 2.970623 \n",
      "\n",
      "loss: 3.017383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.120765 \n",
      "\n",
      "loss: 2.103516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.535755 \n",
      "\n",
      "loss: 3.385704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 1.950411 \n",
      "\n",
      "loss: 1.949953  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 4.120780 \n",
      "\n",
      "loss: 3.841277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.492980 \n",
      "\n",
      "loss: 1.502275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.693094 \n",
      "\n",
      "loss: 3.472521  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.020997 \n",
      "\n",
      "loss: 3.057194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.049798 \n",
      "\n",
      "loss: 1.097688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.855100 \n",
      "\n",
      "loss: 6.041742  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.167314 \n",
      "\n",
      "loss: 4.102467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.735690 \n",
      "\n",
      "loss: 2.776206  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.576605 \n",
      "\n",
      "loss: 2.542016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.606701 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 166/500\n",
      "--------------------\n",
      "{'hl': [473], 'alpha': 0.00023264498507885467, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.025384197480370213}\n",
      "loss: 1.141953  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.603746 \n",
      "\n",
      "loss: 0.588856  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.555709 \n",
      "\n",
      "loss: 0.552698  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.532530 \n",
      "\n",
      "loss: 0.488744  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.507286 \n",
      "\n",
      "loss: 0.531516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.500331 \n",
      "\n",
      "loss: 0.495774  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.495441 \n",
      "\n",
      "loss: 0.471827  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.488450 \n",
      "\n",
      "loss: 0.504665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.490381 \n",
      "\n",
      "loss: 0.461751  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.476227 \n",
      "\n",
      "loss: 0.429240  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.469506 \n",
      "\n",
      "loss: 0.448631  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.465347 \n",
      "\n",
      "loss: 0.487126  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.477858 \n",
      "\n",
      "loss: 0.454485  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.466005 \n",
      "\n",
      "loss: 0.521641  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.446410 \n",
      "\n",
      "loss: 0.465154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.449037 \n",
      "\n",
      "loss: 0.449646  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.457443 \n",
      "\n",
      "loss: 0.431520  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.461103 \n",
      "\n",
      "loss: 0.433674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.459851 \n",
      "\n",
      "loss: 0.472579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.448715 \n",
      "\n",
      "loss: 0.448278  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.442126 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 167/500\n",
      "--------------------\n",
      "{'hl': [257, 136], 'alpha': 0.14057639435637542, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.4149259368248446}\n",
      "loss: 1.126351  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.563355 \n",
      "\n",
      "loss: 0.579904  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.556353 \n",
      "\n",
      "loss: 0.509684  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.568673 \n",
      "\n",
      "loss: 0.557922  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.566153 \n",
      "\n",
      "loss: 0.550950  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.562739 \n",
      "\n",
      "loss: 0.582672  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.564691 \n",
      "\n",
      "loss: 0.521534  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.571943 \n",
      "\n",
      "loss: 0.547697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.560972 \n",
      "\n",
      "loss: 0.564391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.557992 \n",
      "\n",
      "loss: 0.562554  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.569293 \n",
      "\n",
      "loss: 0.564226  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.576854 \n",
      "\n",
      "loss: 0.550489  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.567962 \n",
      "\n",
      "loss: 0.543519  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.555574 \n",
      "\n",
      "loss: 0.547795  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.559653 \n",
      "\n",
      "loss: 0.592737  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.562968 \n",
      "\n",
      "loss: 0.544083  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.558792 \n",
      "\n",
      "loss: 0.556962  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.558529 \n",
      "\n",
      "loss: 0.559196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.559935 \n",
      "\n",
      "loss: 0.566681  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.551612 \n",
      "\n",
      "loss: 0.564498  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.562906 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 168/500\n",
      "--------------------\n",
      "{'hl': [220, 608, 229], 'alpha': 0.178735954735532, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3872068520446295}\n",
      "loss: 1.124263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 15.823891 \n",
      "\n",
      "loss: 15.867058  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 7.765135 \n",
      "\n",
      "loss: 7.900493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 5.975209 \n",
      "\n",
      "loss: 6.135329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 6.703834 \n",
      "\n",
      "loss: 6.377079  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 34.4%, Avg loss: 6.079090 \n",
      "\n",
      "loss: 5.936624  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 8.448130 \n",
      "\n",
      "loss: 8.416543  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 5.557008 \n",
      "\n",
      "loss: 5.815013  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 9.905030 \n",
      "\n",
      "loss: 10.424336  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 23.4%, Avg loss: 10.402623 \n",
      "\n",
      "loss: 10.470459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 12.718053 \n",
      "\n",
      "loss: 12.817232  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 37.8%, Avg loss: 9.999631 \n",
      "\n",
      "loss: 9.681225  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 40.9%, Avg loss: 2.747478 \n",
      "\n",
      "loss: 2.695902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 4.987841 \n",
      "\n",
      "loss: 4.802338  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 7.437458 \n",
      "\n",
      "loss: 7.570960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 3.848299 \n",
      "\n",
      "loss: 3.509123  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 20.5%, Avg loss: 15.915214 \n",
      "\n",
      "loss: 15.256315  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 5.806907 \n",
      "\n",
      "loss: 5.972601  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 34.1%, Avg loss: 4.087066 \n",
      "\n",
      "loss: 4.112122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 16.871583 \n",
      "\n",
      "loss: 17.623066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 40.9%, Avg loss: 7.816186 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 169/500\n",
      "--------------------\n",
      "{'hl': [10, 291, 156], 'alpha': 0.8914751003384759, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.05505218130992884}\n",
      "loss: 1.083523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.004960 \n",
      "\n",
      "loss: 1.004891  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.002161 \n",
      "\n",
      "loss: 0.999475  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.999861 \n",
      "\n",
      "loss: 1.006981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.999438 \n",
      "\n",
      "loss: 0.998715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.997976 \n",
      "\n",
      "loss: 1.001553  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.999863 \n",
      "\n",
      "loss: 0.997579  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.002554 \n",
      "\n",
      "loss: 0.998655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.998766 \n",
      "\n",
      "loss: 0.999274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.999095 \n",
      "\n",
      "loss: 0.999055  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.998595 \n",
      "\n",
      "loss: 0.995775  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.999754 \n",
      "\n",
      "loss: 0.998103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.000539 \n",
      "\n",
      "loss: 0.998018  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.999695 \n",
      "\n",
      "loss: 1.000069  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.999977 \n",
      "\n",
      "loss: 1.000431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.998728 \n",
      "\n",
      "loss: 1.002062  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.999176 \n",
      "\n",
      "loss: 1.001544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.000863 \n",
      "\n",
      "loss: 0.999170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.999958 \n",
      "\n",
      "loss: 0.997043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.998457 \n",
      "\n",
      "loss: 0.997827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.998438 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 170/500\n",
      "--------------------\n",
      "{'hl': [142], 'alpha': 0.00011466775475719672, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.00798896364722901}\n",
      "loss: 1.145365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.421635 \n",
      "\n",
      "loss: 0.424938  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.383115 \n",
      "\n",
      "loss: 0.367637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.343785 \n",
      "\n",
      "loss: 0.331404  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.335882 \n",
      "\n",
      "loss: 0.374074  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.315207 \n",
      "\n",
      "loss: 0.346822  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.306754 \n",
      "\n",
      "loss: 0.276455  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.299852 \n",
      "\n",
      "loss: 0.275219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.299334 \n",
      "\n",
      "loss: 0.287624  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.290332 \n",
      "\n",
      "loss: 0.282945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.279064 \n",
      "\n",
      "loss: 0.282458  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.266666 \n",
      "\n",
      "loss: 0.269617  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.267661 \n",
      "\n",
      "loss: 0.273050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.261108 \n",
      "\n",
      "loss: 0.306193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.266082 \n",
      "\n",
      "loss: 0.265743  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.247320 \n",
      "\n",
      "loss: 0.248441  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.263620 \n",
      "\n",
      "loss: 0.241219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.246265 \n",
      "\n",
      "loss: 0.213529  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.224617 \n",
      "\n",
      "loss: 0.229051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.249734 \n",
      "\n",
      "loss: 0.242368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.225137 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 171/500\n",
      "--------------------\n",
      "{'hl': [61, 137], 'alpha': 0.09265571842913356, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2381753581150828}\n",
      "loss: 1.138075  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.517942 \n",
      "\n",
      "loss: 0.516355  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.512644 \n",
      "\n",
      "loss: 0.507472  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.494165 \n",
      "\n",
      "loss: 0.501067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.481947 \n",
      "\n",
      "loss: 0.504684  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.503455 \n",
      "\n",
      "loss: 0.493283  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.491000 \n",
      "\n",
      "loss: 0.486172  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.501142 \n",
      "\n",
      "loss: 0.502528  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.493834 \n",
      "\n",
      "loss: 0.457549  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.496525 \n",
      "\n",
      "loss: 0.521359  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.497489 \n",
      "\n",
      "loss: 0.507152  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.495135 \n",
      "\n",
      "loss: 0.513840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.509639 \n",
      "\n",
      "loss: 0.457692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.494486 \n",
      "\n",
      "loss: 0.533345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.492033 \n",
      "\n",
      "loss: 0.494135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.490927 \n",
      "\n",
      "loss: 0.488581  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.495061 \n",
      "\n",
      "loss: 0.501096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.494402 \n",
      "\n",
      "loss: 0.495729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.490690 \n",
      "\n",
      "loss: 0.501216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.491729 \n",
      "\n",
      "loss: 0.513168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.490495 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 172/500\n",
      "--------------------\n",
      "{'hl': [533, 615], 'alpha': 0.0002730335651930538, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3636487742821512}\n",
      "loss: 1.060931  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.487283 \n",
      "\n",
      "loss: 0.489106  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.458603 \n",
      "\n",
      "loss: 0.467678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.452638 \n",
      "\n",
      "loss: 0.429787  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.433881 \n",
      "\n",
      "loss: 0.459718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.458302 \n",
      "\n",
      "loss: 0.446711  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.430525 \n",
      "\n",
      "loss: 0.466373  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.428846 \n",
      "\n",
      "loss: 0.389525  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.417478 \n",
      "\n",
      "loss: 0.412754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.409433 \n",
      "\n",
      "loss: 0.409881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.422652 \n",
      "\n",
      "loss: 0.429209  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.419403 \n",
      "\n",
      "loss: 0.391353  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.385595 \n",
      "\n",
      "loss: 0.398213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.373310 \n",
      "\n",
      "loss: 0.357969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.367665 \n",
      "\n",
      "loss: 0.374371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.448356 \n",
      "\n",
      "loss: 0.474077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.369782 \n",
      "\n",
      "loss: 0.374501  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.391252 \n",
      "\n",
      "loss: 0.391567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.365364 \n",
      "\n",
      "loss: 0.355653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.355048 \n",
      "\n",
      "loss: 0.353614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.334563 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 173/500\n",
      "--------------------\n",
      "{'hl': [541, 316, 477], 'alpha': 0.03744231880847276, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.4992935188691545}\n",
      "loss: 1.102337  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.462730 \n",
      "\n",
      "loss: 0.503544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.446174 \n",
      "\n",
      "loss: 0.427264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.417373 \n",
      "\n",
      "loss: 0.421923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.414169 \n",
      "\n",
      "loss: 0.420888  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.435126 \n",
      "\n",
      "loss: 0.463097  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.409086 \n",
      "\n",
      "loss: 0.475823  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.445732 \n",
      "\n",
      "loss: 0.417438  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.428725 \n",
      "\n",
      "loss: 0.445459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.466081 \n",
      "\n",
      "loss: 0.454771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.407956 \n",
      "\n",
      "loss: 0.399926  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.427308 \n",
      "\n",
      "loss: 0.397596  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.439515 \n",
      "\n",
      "loss: 0.416716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.425197 \n",
      "\n",
      "loss: 0.438333  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.422541 \n",
      "\n",
      "loss: 0.438539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.407388 \n",
      "\n",
      "loss: 0.385830  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.411280 \n",
      "\n",
      "loss: 0.367684  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.428819 \n",
      "\n",
      "loss: 0.374895  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.407627 \n",
      "\n",
      "loss: 0.399340  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.440601 \n",
      "\n",
      "loss: 0.435246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.396969 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 174/500\n",
      "--------------------\n",
      "{'hl': [444, 710], 'alpha': 0.0002703007923133579, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.449643455885255}\n",
      "loss: 1.090698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.793308 \n",
      "\n",
      "loss: 0.796089  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.764167 \n",
      "\n",
      "loss: 0.756109  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.544458 \n",
      "\n",
      "loss: 0.541650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.525911 \n",
      "\n",
      "loss: 0.524740  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.517427 \n",
      "\n",
      "loss: 0.553058  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.494933 \n",
      "\n",
      "loss: 0.501559  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.507138 \n",
      "\n",
      "loss: 0.492770  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.493033 \n",
      "\n",
      "loss: 0.494122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.481740 \n",
      "\n",
      "loss: 0.493066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.503306 \n",
      "\n",
      "loss: 0.519259  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.512891 \n",
      "\n",
      "loss: 0.495739  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.490964 \n",
      "\n",
      "loss: 0.474431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.476019 \n",
      "\n",
      "loss: 0.473059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.466217 \n",
      "\n",
      "loss: 0.504182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.482795 \n",
      "\n",
      "loss: 0.457736  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.461709 \n",
      "\n",
      "loss: 0.455327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.474217 \n",
      "\n",
      "loss: 0.494919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.463228 \n",
      "\n",
      "loss: 0.467137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.463895 \n",
      "\n",
      "loss: 0.442637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.471256 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 175/500\n",
      "--------------------\n",
      "{'hl': [630, 159], 'alpha': 0.0001831171132483136, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.19051410896937854}\n",
      "loss: 1.095050  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 203.956758 \n",
      "\n",
      "loss: 201.503998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 8.284492 \n",
      "\n",
      "loss: 11.875466  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 6.390470 \n",
      "\n",
      "loss: 5.093820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 2.151279 \n",
      "\n",
      "loss: 2.133780  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.929895 \n",
      "\n",
      "loss: 1.165250  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 2.334118 \n",
      "\n",
      "loss: 2.303770  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 1.188163 \n",
      "\n",
      "loss: 1.200875  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 1.033892 \n",
      "\n",
      "loss: 0.923968  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 1.587045 \n",
      "\n",
      "loss: 3.217837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.556357 \n",
      "\n",
      "loss: 0.589140  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.568368 \n",
      "\n",
      "loss: 0.544513  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.587249 \n",
      "\n",
      "loss: 0.527111  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.400963 \n",
      "\n",
      "loss: 0.375170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.393722 \n",
      "\n",
      "loss: 0.355113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.398204 \n",
      "\n",
      "loss: 0.336454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.345534 \n",
      "\n",
      "loss: 0.287901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.311603 \n",
      "\n",
      "loss: 0.262127  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.405561 \n",
      "\n",
      "loss: 0.307010  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.332093 \n",
      "\n",
      "loss: 0.284534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 1.300184 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 176/500\n",
      "--------------------\n",
      "{'hl': [551, 309, 472], 'alpha': 0.010524568471941902, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3965687369415129}\n",
      "loss: 1.083466  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.825869 \n",
      "\n",
      "loss: 0.825603  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.829854 \n",
      "\n",
      "loss: 0.815920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.890122 \n",
      "\n",
      "loss: 0.902213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.841376 \n",
      "\n",
      "loss: 0.861849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.805262 \n",
      "\n",
      "loss: 0.835222  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.841902 \n",
      "\n",
      "loss: 0.840686  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.860421 \n",
      "\n",
      "loss: 0.859533  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.817073 \n",
      "\n",
      "loss: 0.821455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.842210 \n",
      "\n",
      "loss: 0.851867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.804575 \n",
      "\n",
      "loss: 0.809024  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.858424 \n",
      "\n",
      "loss: 0.826839  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.838420 \n",
      "\n",
      "loss: 0.849934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.847513 \n",
      "\n",
      "loss: 0.823064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.836725 \n",
      "\n",
      "loss: 0.810886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.822002 \n",
      "\n",
      "loss: 0.849090  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.907443 \n",
      "\n",
      "loss: 0.891862  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.861569 \n",
      "\n",
      "loss: 0.848643  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 0.812228 \n",
      "\n",
      "loss: 0.838683  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.816393 \n",
      "\n",
      "loss: 0.795162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.804511 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 177/500\n",
      "--------------------\n",
      "{'hl': [678], 'alpha': 0.04014825367203617, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.22583230249104422}\n",
      "loss: 1.175276  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 6.249212 \n",
      "\n",
      "loss: 5.868805  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 5.492033 \n",
      "\n",
      "loss: 5.368086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 3.615800 \n",
      "\n",
      "loss: 3.670969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 3.815370 \n",
      "\n",
      "loss: 4.173087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 2.834300 \n",
      "\n",
      "loss: 2.706869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 2.491375 \n",
      "\n",
      "loss: 2.495853  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 4.853607 \n",
      "\n",
      "loss: 4.985560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 4.654257 \n",
      "\n",
      "loss: 4.735983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 5.502745 \n",
      "\n",
      "loss: 4.963405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 7.345149 \n",
      "\n",
      "loss: 7.849719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 7.432567 \n",
      "\n",
      "loss: 7.598316  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 3.403043 \n",
      "\n",
      "loss: 3.554594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 10.958198 \n",
      "\n",
      "loss: 11.341024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 6.450157 \n",
      "\n",
      "loss: 6.079356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 2.371921 \n",
      "\n",
      "loss: 2.258694  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 4.932107 \n",
      "\n",
      "loss: 5.392648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 4.507171 \n",
      "\n",
      "loss: 4.854714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 5.312084 \n",
      "\n",
      "loss: 5.217464  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 4.807178 \n",
      "\n",
      "loss: 4.505781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 5.163454 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 178/500\n",
      "--------------------\n",
      "{'hl': [431], 'alpha': 0.0022684357097629633, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.20805322616572147}\n",
      "loss: 1.038564  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 1.620191 \n",
      "\n",
      "loss: 1.635511  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.862389 \n",
      "\n",
      "loss: 1.929161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.737845 \n",
      "\n",
      "loss: 0.687626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 1.217872 \n",
      "\n",
      "loss: 1.379789  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 1.426406 \n",
      "\n",
      "loss: 1.417105  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 2.387234 \n",
      "\n",
      "loss: 2.139135  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.493575 \n",
      "\n",
      "loss: 1.246714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 1.537282 \n",
      "\n",
      "loss: 1.515265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.238220 \n",
      "\n",
      "loss: 1.273355  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 1.879229 \n",
      "\n",
      "loss: 2.027578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 1.651842 \n",
      "\n",
      "loss: 1.526843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.984324 \n",
      "\n",
      "loss: 1.537600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 1.124989 \n",
      "\n",
      "loss: 1.080644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.998789 \n",
      "\n",
      "loss: 0.972075  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 2.462281 \n",
      "\n",
      "loss: 2.215592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.170006 \n",
      "\n",
      "loss: 1.254965  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.886825 \n",
      "\n",
      "loss: 0.907477  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.609133 \n",
      "\n",
      "loss: 0.563251  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 2.019800 \n",
      "\n",
      "loss: 2.217746  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 2.497977 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 179/500\n",
      "--------------------\n",
      "{'hl': [328], 'alpha': 0.005093965802158534, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.47680089955780053}\n",
      "loss: 1.137707  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 42.634547 \n",
      "\n",
      "loss: 34.641502  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 12.208188 \n",
      "\n",
      "loss: 10.517397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 3.006924 \n",
      "\n",
      "loss: 4.140041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 5.680585 \n",
      "\n",
      "loss: 6.219111  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 18.837350 \n",
      "\n",
      "loss: 19.354822  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 10.121918 \n",
      "\n",
      "loss: 6.887828  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 39.117786 \n",
      "\n",
      "loss: 38.090271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 61.729341 \n",
      "\n",
      "loss: 61.379093  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 44.229763 \n",
      "\n",
      "loss: 48.595840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 260.537533 \n",
      "\n",
      "loss: 221.438644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 61.226542 \n",
      "\n",
      "loss: 62.697132  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 8.899151 \n",
      "\n",
      "loss: 8.771784  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 37.163937 \n",
      "\n",
      "loss: 30.919964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 105.239339 \n",
      "\n",
      "loss: 117.567268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 16.506874 \n",
      "\n",
      "loss: 14.655309  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 2.049514 \n",
      "\n",
      "loss: 1.987557  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.629149 \n",
      "\n",
      "loss: 0.600380  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.446910 \n",
      "\n",
      "loss: 0.417142  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.436794 \n",
      "\n",
      "loss: 0.409854  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.403087 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 180/500\n",
      "--------------------\n",
      "{'hl': [493, 76, 101], 'alpha': 0.21236725518785216, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.04837255983963624}\n",
      "loss: 1.103489  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.717041 \n",
      "\n",
      "loss: 0.729166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.754189 \n",
      "\n",
      "loss: 0.751275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.725505 \n",
      "\n",
      "loss: 0.734731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.777229 \n",
      "\n",
      "loss: 0.760126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.715304 \n",
      "\n",
      "loss: 0.724382  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.716763 \n",
      "\n",
      "loss: 0.722156  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.724835 \n",
      "\n",
      "loss: 0.739729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.725429 \n",
      "\n",
      "loss: 0.714177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.736235 \n",
      "\n",
      "loss: 0.715305  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.721466 \n",
      "\n",
      "loss: 0.721295  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.709312 \n",
      "\n",
      "loss: 0.746305  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.733428 \n",
      "\n",
      "loss: 0.742372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.712875 \n",
      "\n",
      "loss: 0.716175  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.721185 \n",
      "\n",
      "loss: 0.736292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.713639 \n",
      "\n",
      "loss: 0.696129  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.718324 \n",
      "\n",
      "loss: 0.739550  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.722922 \n",
      "\n",
      "loss: 0.720300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.712469 \n",
      "\n",
      "loss: 0.722738  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.710696 \n",
      "\n",
      "loss: 0.699699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.717264 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 181/500\n",
      "--------------------\n",
      "{'hl': [389, 141, 577], 'alpha': 0.00017374963938202197, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.20546323559778687}\n",
      "loss: 1.087609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.487398 \n",
      "\n",
      "loss: 0.485775  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.445472 \n",
      "\n",
      "loss: 0.444280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.407343 \n",
      "\n",
      "loss: 0.419847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.403752 \n",
      "\n",
      "loss: 0.445253  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.370571 \n",
      "\n",
      "loss: 0.416771  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.366555 \n",
      "\n",
      "loss: 0.311719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.351368 \n",
      "\n",
      "loss: 0.345492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.390062 \n",
      "\n",
      "loss: 0.359027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.335775 \n",
      "\n",
      "loss: 0.365475  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.327075 \n",
      "\n",
      "loss: 0.307146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.322863 \n",
      "\n",
      "loss: 0.303102  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.325892 \n",
      "\n",
      "loss: 0.282757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.314900 \n",
      "\n",
      "loss: 0.313590  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.320537 \n",
      "\n",
      "loss: 0.312277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.303736 \n",
      "\n",
      "loss: 0.314423  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.297435 \n",
      "\n",
      "loss: 0.268970  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.320437 \n",
      "\n",
      "loss: 0.294878  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.322792 \n",
      "\n",
      "loss: 0.282869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.336429 \n",
      "\n",
      "loss: 0.322577  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.288432 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 182/500\n",
      "--------------------\n",
      "{'hl': [441, 60, 302], 'alpha': 0.025213919671990635, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.28900146734308846}\n",
      "loss: 1.071471  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.481086 \n",
      "\n",
      "loss: 0.453731  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.454860 \n",
      "\n",
      "loss: 0.412688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.459616 \n",
      "\n",
      "loss: 0.465688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.401028 \n",
      "\n",
      "loss: 0.403090  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.377321 \n",
      "\n",
      "loss: 0.424106  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.397163 \n",
      "\n",
      "loss: 0.428786  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.386103 \n",
      "\n",
      "loss: 0.339649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.398582 \n",
      "\n",
      "loss: 0.401833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.376317 \n",
      "\n",
      "loss: 0.381221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.379466 \n",
      "\n",
      "loss: 0.402523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.393399 \n",
      "\n",
      "loss: 0.375956  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.394940 \n",
      "\n",
      "loss: 0.401710  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.407319 \n",
      "\n",
      "loss: 0.408229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.378478 \n",
      "\n",
      "loss: 0.410506  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.372880 \n",
      "\n",
      "loss: 0.439896  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.388420 \n",
      "\n",
      "loss: 0.396710  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.388876 \n",
      "\n",
      "loss: 0.382406  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.401462 \n",
      "\n",
      "loss: 0.421220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.384626 \n",
      "\n",
      "loss: 0.406243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.386458 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 183/500\n",
      "--------------------\n",
      "{'hl': [166], 'alpha': 0.042358952510595356, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.17512198571117346}\n",
      "loss: 1.116635  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.530398 \n",
      "\n",
      "loss: 0.511102  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.508480 \n",
      "\n",
      "loss: 0.469918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.508881 \n",
      "\n",
      "loss: 0.460736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.491722 \n",
      "\n",
      "loss: 0.488259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.489718 \n",
      "\n",
      "loss: 0.488156  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.485299 \n",
      "\n",
      "loss: 0.488065  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.485874 \n",
      "\n",
      "loss: 0.471678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.488298 \n",
      "\n",
      "loss: 0.508078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.477662 \n",
      "\n",
      "loss: 0.492692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.486262 \n",
      "\n",
      "loss: 0.490775  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.485039 \n",
      "\n",
      "loss: 0.496894  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.489549 \n",
      "\n",
      "loss: 0.464319  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.479334 \n",
      "\n",
      "loss: 0.471578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.470985 \n",
      "\n",
      "loss: 0.455597  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.480709 \n",
      "\n",
      "loss: 0.460734  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.469175 \n",
      "\n",
      "loss: 0.440823  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.485452 \n",
      "\n",
      "loss: 0.459008  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.479036 \n",
      "\n",
      "loss: 0.472691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.488897 \n",
      "\n",
      "loss: 0.495825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.481250 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 184/500\n",
      "--------------------\n",
      "{'hl': [384, 125, 293], 'alpha': 0.019787914141761263, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.30453655828497733}\n",
      "loss: 1.092733  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.863388 \n",
      "\n",
      "loss: 0.846669  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.932172 \n",
      "\n",
      "loss: 0.893571  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.907726 \n",
      "\n",
      "loss: 0.929702  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.841576 \n",
      "\n",
      "loss: 0.862807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.816791 \n",
      "\n",
      "loss: 0.818835  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.909235 \n",
      "\n",
      "loss: 0.899558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.849155 \n",
      "\n",
      "loss: 0.865952  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.859045 \n",
      "\n",
      "loss: 0.865193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.867232 \n",
      "\n",
      "loss: 0.854868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.854924 \n",
      "\n",
      "loss: 0.849647  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.823861 \n",
      "\n",
      "loss: 0.824704  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.888417 \n",
      "\n",
      "loss: 0.869408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.910711 \n",
      "\n",
      "loss: 0.892740  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.908495 \n",
      "\n",
      "loss: 0.880391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.912230 \n",
      "\n",
      "loss: 0.925437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.893577 \n",
      "\n",
      "loss: 0.885834  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.957700 \n",
      "\n",
      "loss: 0.903117  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.868073 \n",
      "\n",
      "loss: 0.894375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.033722 \n",
      "\n",
      "loss: 1.054592  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.893701 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 185/500\n",
      "--------------------\n",
      "{'hl': [718, 281, 37], 'alpha': 0.0005268224671575222, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.1755766080264172}\n",
      "loss: 1.063106  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 169.627392 \n",
      "\n",
      "loss: 141.165344  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 24.647890 \n",
      "\n",
      "loss: 16.704058  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 3.402876 \n",
      "\n",
      "loss: 2.738502  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 19.554729 \n",
      "\n",
      "loss: 20.034931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 130.015671 \n",
      "\n",
      "loss: 121.077667  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1858.564996 \n",
      "\n",
      "loss: 1532.154541  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 872.740068 \n",
      "\n",
      "loss: 927.628296  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 97.284818 \n",
      "\n",
      "loss: 93.560905  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 43.020077 \n",
      "\n",
      "loss: 45.696007  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 13.298370 \n",
      "\n",
      "loss: 14.127372  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 15.450088 \n",
      "\n",
      "loss: 15.452952  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 9.904575 \n",
      "\n",
      "loss: 8.505111  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 2.672291 \n",
      "\n",
      "loss: 2.809819  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 6.976771 \n",
      "\n",
      "loss: 5.356832  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 5045.353407 \n",
      "\n",
      "loss: 5025.448242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 1139.140116 \n",
      "\n",
      "loss: 1508.339355  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 195.117728 \n",
      "\n",
      "loss: 224.579391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 85.144367 \n",
      "\n",
      "loss: 81.409729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 440.365462 \n",
      "\n",
      "loss: 558.102112  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 122.893071 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 186/500\n",
      "--------------------\n",
      "{'hl': [154], 'alpha': 0.01841977746492642, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.07102313961021921}\n",
      "loss: 1.194798  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.629220 \n",
      "\n",
      "loss: 0.654358  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.589886 \n",
      "\n",
      "loss: 0.566736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.548963 \n",
      "\n",
      "loss: 0.556219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.530219 \n",
      "\n",
      "loss: 0.592703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.519674 \n",
      "\n",
      "loss: 0.545305  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.520312 \n",
      "\n",
      "loss: 0.508993  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.528289 \n",
      "\n",
      "loss: 0.535718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.524707 \n",
      "\n",
      "loss: 0.513228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.520022 \n",
      "\n",
      "loss: 0.511134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.515539 \n",
      "\n",
      "loss: 0.487982  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.504510 \n",
      "\n",
      "loss: 0.464243  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.510256 \n",
      "\n",
      "loss: 0.518553  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.513377 \n",
      "\n",
      "loss: 0.500890  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.494742 \n",
      "\n",
      "loss: 0.525050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.507735 \n",
      "\n",
      "loss: 0.475865  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.508632 \n",
      "\n",
      "loss: 0.494331  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.521125 \n",
      "\n",
      "loss: 0.488393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.500005 \n",
      "\n",
      "loss: 0.512512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.497614 \n",
      "\n",
      "loss: 0.543634  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.498781 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 187/500\n",
      "--------------------\n",
      "{'hl': [39, 101, 551], 'alpha': 0.000725323118530504, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.17051390128648944}\n",
      "loss: 1.170279  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.674731 \n",
      "\n",
      "loss: 2.661458  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.628469 \n",
      "\n",
      "loss: 0.553221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.647309 \n",
      "\n",
      "loss: 0.636255  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.584290 \n",
      "\n",
      "loss: 0.624705  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.472789 \n",
      "\n",
      "loss: 0.547546  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.460126 \n",
      "\n",
      "loss: 0.433997  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.645465 \n",
      "\n",
      "loss: 0.703648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.717074 \n",
      "\n",
      "loss: 0.792425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.669547 \n",
      "\n",
      "loss: 0.664968  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.523066 \n",
      "\n",
      "loss: 0.560858  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.535448 \n",
      "\n",
      "loss: 0.493949  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.552533 \n",
      "\n",
      "loss: 0.516490  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.534628 \n",
      "\n",
      "loss: 0.512340  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.578549 \n",
      "\n",
      "loss: 0.576620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.931035 \n",
      "\n",
      "loss: 0.980536  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.563027 \n",
      "\n",
      "loss: 0.587083  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.492046 \n",
      "\n",
      "loss: 0.476941  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.492619 \n",
      "\n",
      "loss: 0.451510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.481828 \n",
      "\n",
      "loss: 0.437650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.552225 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 188/500\n",
      "--------------------\n",
      "{'hl': [327, 340], 'alpha': 0.128039060813798, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.07787439371190373}\n",
      "loss: 1.077797  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.596199 \n",
      "\n",
      "loss: 0.601279  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.556367 \n",
      "\n",
      "loss: 0.571836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.543977 \n",
      "\n",
      "loss: 0.550661  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.537468 \n",
      "\n",
      "loss: 0.543470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.529393 \n",
      "\n",
      "loss: 0.548408  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.530343 \n",
      "\n",
      "loss: 0.526308  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.541675 \n",
      "\n",
      "loss: 0.522160  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.532941 \n",
      "\n",
      "loss: 0.494556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.528992 \n",
      "\n",
      "loss: 0.552345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.524664 \n",
      "\n",
      "loss: 0.518958  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.521418 \n",
      "\n",
      "loss: 0.518582  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.535960 \n",
      "\n",
      "loss: 0.531188  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.545300 \n",
      "\n",
      "loss: 0.509885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.529282 \n",
      "\n",
      "loss: 0.503232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.530225 \n",
      "\n",
      "loss: 0.509864  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.521891 \n",
      "\n",
      "loss: 0.537905  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.543473 \n",
      "\n",
      "loss: 0.534553  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.531764 \n",
      "\n",
      "loss: 0.538581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.524205 \n",
      "\n",
      "loss: 0.490598  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.524765 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 189/500\n",
      "--------------------\n",
      "{'hl': [58, 698, 91], 'alpha': 0.0012257767347570855, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3035772961197636}\n",
      "loss: 1.096400  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.416410 \n",
      "\n",
      "loss: 1.411935  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.983483 \n",
      "\n",
      "loss: 0.977792  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.464365 \n",
      "\n",
      "loss: 2.376073  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.552102 \n",
      "\n",
      "loss: 3.735910  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.867819 \n",
      "\n",
      "loss: 0.845800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.071584 \n",
      "\n",
      "loss: 1.105482  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.897785 \n",
      "\n",
      "loss: 0.871293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.309137 \n",
      "\n",
      "loss: 1.246510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.061941 \n",
      "\n",
      "loss: 1.061898  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.826902 \n",
      "\n",
      "loss: 0.814686  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.862034 \n",
      "\n",
      "loss: 0.885752  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.059022 \n",
      "\n",
      "loss: 1.058425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.038599 \n",
      "\n",
      "loss: 1.087068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.830928 \n",
      "\n",
      "loss: 0.826059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.458038 \n",
      "\n",
      "loss: 1.397815  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.376539 \n",
      "\n",
      "loss: 1.345931  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.879325 \n",
      "\n",
      "loss: 0.892974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.016773 \n",
      "\n",
      "loss: 1.052632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.056212 \n",
      "\n",
      "loss: 1.041686  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.316124 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 190/500\n",
      "--------------------\n",
      "{'hl': [287, 228], 'alpha': 0.1046580345808207, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.21501382533560537}\n",
      "loss: 1.094357  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 142.946100 \n",
      "\n",
      "loss: 151.379608  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 96.200003 \n",
      "\n",
      "loss: 98.945084  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 6.803793 \n",
      "\n",
      "loss: 6.802104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 2.331488 \n",
      "\n",
      "loss: 2.014178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 2.114348 \n",
      "\n",
      "loss: 2.330746  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 3.305173 \n",
      "\n",
      "loss: 3.536701  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 5.918679 \n",
      "\n",
      "loss: 6.328478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 1.930394 \n",
      "\n",
      "loss: 2.143893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 9.653008 \n",
      "\n",
      "loss: 10.068063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 2.734488 \n",
      "\n",
      "loss: 2.716591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 29.119043 \n",
      "\n",
      "loss: 29.259085  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 1407.543877 \n",
      "\n",
      "loss: 1449.458862  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 3020.797797 \n",
      "\n",
      "loss: 2573.964111  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 72.064495 \n",
      "\n",
      "loss: 67.440239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 3.076895 \n",
      "\n",
      "loss: 2.820606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 3.147499 \n",
      "\n",
      "loss: 3.180519  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 4.234796 \n",
      "\n",
      "loss: 4.049032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.989587 \n",
      "\n",
      "loss: 2.492591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.538553 \n",
      "\n",
      "loss: 0.583210  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 4.703333 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 191/500\n",
      "--------------------\n",
      "{'hl': [702, 702], 'alpha': 0.02357963084116366, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.11033716590771205}\n",
      "loss: 1.090600  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.499691 \n",
      "\n",
      "loss: 0.529661  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.486106 \n",
      "\n",
      "loss: 0.444023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.448853 \n",
      "\n",
      "loss: 0.461081  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.439733 \n",
      "\n",
      "loss: 0.442324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.422419 \n",
      "\n",
      "loss: 0.431968  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.419568 \n",
      "\n",
      "loss: 0.440901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.415161 \n",
      "\n",
      "loss: 0.399929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.413897 \n",
      "\n",
      "loss: 0.392317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.408102 \n",
      "\n",
      "loss: 0.421417  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.403553 \n",
      "\n",
      "loss: 0.398974  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.402763 \n",
      "\n",
      "loss: 0.439609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.400621 \n",
      "\n",
      "loss: 0.395503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.408613 \n",
      "\n",
      "loss: 0.389208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.390723 \n",
      "\n",
      "loss: 0.370893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.377423 \n",
      "\n",
      "loss: 0.404380  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.396094 \n",
      "\n",
      "loss: 0.370467  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.396124 \n",
      "\n",
      "loss: 0.400626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.390435 \n",
      "\n",
      "loss: 0.368976  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.380066 \n",
      "\n",
      "loss: 0.389948  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.381361 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 192/500\n",
      "--------------------\n",
      "{'hl': [64, 15, 217], 'alpha': 0.0016057482156015123, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.38210403179104774}\n",
      "loss: 1.163788  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.544298 \n",
      "\n",
      "loss: 0.536571  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.492973 \n",
      "\n",
      "loss: 0.433733  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.459349 \n",
      "\n",
      "loss: 0.458968  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.408764 \n",
      "\n",
      "loss: 0.413891  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.393203 \n",
      "\n",
      "loss: 0.414288  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.402004 \n",
      "\n",
      "loss: 0.378662  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.383229 \n",
      "\n",
      "loss: 0.370228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.388700 \n",
      "\n",
      "loss: 0.376219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.387106 \n",
      "\n",
      "loss: 0.396908  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.378081 \n",
      "\n",
      "loss: 0.367184  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.358945 \n",
      "\n",
      "loss: 0.358339  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364183 \n",
      "\n",
      "loss: 0.340636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.381491 \n",
      "\n",
      "loss: 0.346338  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.372985 \n",
      "\n",
      "loss: 0.378098  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.373698 \n",
      "\n",
      "loss: 0.352862  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.357833 \n",
      "\n",
      "loss: 0.341085  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.353540 \n",
      "\n",
      "loss: 0.357106  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.386187 \n",
      "\n",
      "loss: 0.396493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.349432 \n",
      "\n",
      "loss: 0.332805  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.334252 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 193/500\n",
      "--------------------\n",
      "{'hl': [343, 130], 'alpha': 0.00010737906703728324, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.06467993230943156}\n",
      "loss: 1.189283  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.808251 \n",
      "\n",
      "loss: 0.790336  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.791268 \n",
      "\n",
      "loss: 0.785900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 0.761367 \n",
      "\n",
      "loss: 0.752695  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.712013 \n",
      "\n",
      "loss: 0.723515  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.667954 \n",
      "\n",
      "loss: 0.664042  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.631293 \n",
      "\n",
      "loss: 0.630602  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.604234 \n",
      "\n",
      "loss: 0.612180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.561085 \n",
      "\n",
      "loss: 0.544667  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.552929 \n",
      "\n",
      "loss: 0.577803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.543932 \n",
      "\n",
      "loss: 0.503147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.523309 \n",
      "\n",
      "loss: 0.532206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.547526 \n",
      "\n",
      "loss: 0.507782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.528126 \n",
      "\n",
      "loss: 0.555150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.519407 \n",
      "\n",
      "loss: 0.536258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.516272 \n",
      "\n",
      "loss: 0.530654  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.517135 \n",
      "\n",
      "loss: 0.521729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.522674 \n",
      "\n",
      "loss: 0.505763  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.515217 \n",
      "\n",
      "loss: 0.492984  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.499390 \n",
      "\n",
      "loss: 0.543254  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.505689 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 194/500\n",
      "--------------------\n",
      "{'hl': [243, 520, 580], 'alpha': 0.21548488367196117, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.1985958800062239}\n",
      "loss: 1.078602  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.869463 \n",
      "\n",
      "loss: 0.865919  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.900871 \n",
      "\n",
      "loss: 0.906593  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.897607 \n",
      "\n",
      "loss: 0.911697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.898640 \n",
      "\n",
      "loss: 0.901962  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.903537 \n",
      "\n",
      "loss: 0.913961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.903974 \n",
      "\n",
      "loss: 0.900017  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.906016 \n",
      "\n",
      "loss: 0.905826  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.902342 \n",
      "\n",
      "loss: 0.895037  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.905987 \n",
      "\n",
      "loss: 0.895615  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.902059 \n",
      "\n",
      "loss: 0.901248  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.903997 \n",
      "\n",
      "loss: 0.897012  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.904020 \n",
      "\n",
      "loss: 0.904576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.901961 \n",
      "\n",
      "loss: 0.914655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.904520 \n",
      "\n",
      "loss: 0.908683  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.901645 \n",
      "\n",
      "loss: 0.906934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.902483 \n",
      "\n",
      "loss: 0.892162  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.904570 \n",
      "\n",
      "loss: 0.892022  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.904921 \n",
      "\n",
      "loss: 0.910299  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.903950 \n",
      "\n",
      "loss: 0.900736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.900873 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 195/500\n",
      "--------------------\n",
      "{'hl': [51, 454, 27], 'alpha': 0.006902668253441193, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.28792200445234184}\n",
      "loss: 1.048151  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.822142 \n",
      "\n",
      "loss: 0.816001  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.837977 \n",
      "\n",
      "loss: 0.800479  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.814860 \n",
      "\n",
      "loss: 0.804971  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.818224 \n",
      "\n",
      "loss: 0.844184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.841654 \n",
      "\n",
      "loss: 0.863218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.828068 \n",
      "\n",
      "loss: 0.787654  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.830925 \n",
      "\n",
      "loss: 0.803154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.818960 \n",
      "\n",
      "loss: 0.827104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814116 \n",
      "\n",
      "loss: 0.826265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.817310 \n",
      "\n",
      "loss: 0.818783  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817675 \n",
      "\n",
      "loss: 0.823384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824452 \n",
      "\n",
      "loss: 0.804044  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.816952 \n",
      "\n",
      "loss: 0.830589  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.817047 \n",
      "\n",
      "loss: 0.827436  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.823105 \n",
      "\n",
      "loss: 0.817944  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820256 \n",
      "\n",
      "loss: 0.831744  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.821070 \n",
      "\n",
      "loss: 0.821696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.818710 \n",
      "\n",
      "loss: 0.825484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814907 \n",
      "\n",
      "loss: 0.823428  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.809669 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 196/500\n",
      "--------------------\n",
      "{'hl': [422, 663, 435], 'alpha': 0.0014390000941224264, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.48310322554745977}\n",
      "loss: 1.130609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820809 \n",
      "\n",
      "loss: 0.819756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.823027 \n",
      "\n",
      "loss: 0.819718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.824239 \n",
      "\n",
      "loss: 0.822996  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.811002 \n",
      "\n",
      "loss: 0.846885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.797278 \n",
      "\n",
      "loss: 0.830133  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.804877 \n",
      "\n",
      "loss: 0.800208  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 0.801393 \n",
      "\n",
      "loss: 0.797698  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.768379 \n",
      "\n",
      "loss: 0.781818  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 0.704287 \n",
      "\n",
      "loss: 0.737012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.634638 \n",
      "\n",
      "loss: 0.637797  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.579428 \n",
      "\n",
      "loss: 0.535763  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.560583 \n",
      "\n",
      "loss: 0.535851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.530438 \n",
      "\n",
      "loss: 0.518443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.568852 \n",
      "\n",
      "loss: 0.565140  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.531168 \n",
      "\n",
      "loss: 0.514738  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.516033 \n",
      "\n",
      "loss: 0.494350  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.517782 \n",
      "\n",
      "loss: 0.535345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.579146 \n",
      "\n",
      "loss: 0.565006  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.499641 \n",
      "\n",
      "loss: 0.485201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.541794 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 197/500\n",
      "--------------------\n",
      "{'hl': [640], 'alpha': 0.006924487052852269, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.2184122186061571}\n",
      "loss: 1.172528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.464810 \n",
      "\n",
      "loss: 0.462783  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.435113 \n",
      "\n",
      "loss: 0.389616  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.411340 \n",
      "\n",
      "loss: 0.423534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.400895 \n",
      "\n",
      "loss: 0.416198  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.376660 \n",
      "\n",
      "loss: 0.408904  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382635 \n",
      "\n",
      "loss: 0.382859  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.365799 \n",
      "\n",
      "loss: 0.364035  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.375962 \n",
      "\n",
      "loss: 0.359133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.366619 \n",
      "\n",
      "loss: 0.358071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.357845 \n",
      "\n",
      "loss: 0.324228  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.361825 \n",
      "\n",
      "loss: 0.364736  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.372377 \n",
      "\n",
      "loss: 0.361782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.348282 \n",
      "\n",
      "loss: 0.344804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.362390 \n",
      "\n",
      "loss: 0.376034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.344193 \n",
      "\n",
      "loss: 0.338394  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.350958 \n",
      "\n",
      "loss: 0.352589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.357878 \n",
      "\n",
      "loss: 0.335938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.353358 \n",
      "\n",
      "loss: 0.336311  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.351142 \n",
      "\n",
      "loss: 0.352170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.337882 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 198/500\n",
      "--------------------\n",
      "{'hl': [257], 'alpha': 0.0055297577729082675, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.19794377175998054}\n",
      "loss: 1.045818  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.682162 \n",
      "\n",
      "loss: 0.634318  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.620541 \n",
      "\n",
      "loss: 0.584184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.778952 \n",
      "\n",
      "loss: 0.776991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.656291 \n",
      "\n",
      "loss: 0.772149  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.657391 \n",
      "\n",
      "loss: 0.658174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.683838 \n",
      "\n",
      "loss: 0.630696  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.622732 \n",
      "\n",
      "loss: 0.601861  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.683298 \n",
      "\n",
      "loss: 0.680274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.634690 \n",
      "\n",
      "loss: 0.647591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.518187 \n",
      "\n",
      "loss: 0.533065  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.628563 \n",
      "\n",
      "loss: 0.649936  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.568054 \n",
      "\n",
      "loss: 0.599320  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.518529 \n",
      "\n",
      "loss: 0.510537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.577891 \n",
      "\n",
      "loss: 0.536836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.681591 \n",
      "\n",
      "loss: 0.660695  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.760849 \n",
      "\n",
      "loss: 0.802197  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.830220 \n",
      "\n",
      "loss: 0.814188  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.487863 \n",
      "\n",
      "loss: 0.521352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 0.670548 \n",
      "\n",
      "loss: 0.630936  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.552333 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 199/500\n",
      "--------------------\n",
      "{'hl': [355, 234], 'alpha': 0.002149188410514119, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.25529059394261994}\n",
      "loss: 1.111066  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.485407 \n",
      "\n",
      "loss: 0.503431  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.487163 \n",
      "\n",
      "loss: 0.461589  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.457972 \n",
      "\n",
      "loss: 0.481754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.449319 \n",
      "\n",
      "loss: 0.457862  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.416880 \n",
      "\n",
      "loss: 0.413669  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.435411 \n",
      "\n",
      "loss: 0.463446  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.419952 \n",
      "\n",
      "loss: 0.436342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.435142 \n",
      "\n",
      "loss: 0.394784  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.411367 \n",
      "\n",
      "loss: 0.413853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.377798 \n",
      "\n",
      "loss: 0.401792  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.383194 \n",
      "\n",
      "loss: 0.370486  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.423402 \n",
      "\n",
      "loss: 0.365547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.377615 \n",
      "\n",
      "loss: 0.366064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.380476 \n",
      "\n",
      "loss: 0.417056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.370979 \n",
      "\n",
      "loss: 0.382886  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.381817 \n",
      "\n",
      "loss: 0.360374  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.401401 \n",
      "\n",
      "loss: 0.439139  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.375881 \n",
      "\n",
      "loss: 0.362308  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.385012 \n",
      "\n",
      "loss: 0.387189  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.374584 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 200/500\n",
      "--------------------\n",
      "{'hl': [551], 'alpha': 0.01095994183403002, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.36371681492638475}\n",
      "loss: 1.276440  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 31.081362 \n",
      "\n",
      "loss: 24.740358  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 6.870445 \n",
      "\n",
      "loss: 6.557184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 5.855239 \n",
      "\n",
      "loss: 5.227907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 2.021273 \n",
      "\n",
      "loss: 3.046537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 1.439785 \n",
      "\n",
      "loss: 1.336276  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.708288 \n",
      "\n",
      "loss: 0.582999  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.441706 \n",
      "\n",
      "loss: 0.398833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.427209 \n",
      "\n",
      "loss: 0.414267  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.424086 \n",
      "\n",
      "loss: 0.450318  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.421097 \n",
      "\n",
      "loss: 0.428786  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.440670 \n",
      "\n",
      "loss: 0.484143  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.434250 \n",
      "\n",
      "loss: 0.424321  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.422203 \n",
      "\n",
      "loss: 0.427356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.408792 \n",
      "\n",
      "loss: 0.394169  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.438148 \n",
      "\n",
      "loss: 0.414636  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.425069 \n",
      "\n",
      "loss: 0.476391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.470391 \n",
      "\n",
      "loss: 0.477433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.469224 \n",
      "\n",
      "loss: 0.404815  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.425467 \n",
      "\n",
      "loss: 0.418364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.429399 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 201/500\n",
      "--------------------\n",
      "{'hl': [159, 249, 113], 'alpha': 0.00038528036183712666, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3012392527380556}\n",
      "loss: 1.115860  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.483517 \n",
      "\n",
      "loss: 0.479790  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.466252 \n",
      "\n",
      "loss: 0.469954  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.443359 \n",
      "\n",
      "loss: 0.429005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.423741 \n",
      "\n",
      "loss: 0.483490  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.404210 \n",
      "\n",
      "loss: 0.438637  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.417221 \n",
      "\n",
      "loss: 0.386327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.419343 \n",
      "\n",
      "loss: 0.409126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.407808 \n",
      "\n",
      "loss: 0.398830  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.424845 \n",
      "\n",
      "loss: 0.466993  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.360611 \n",
      "\n",
      "loss: 0.380495  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.391092 \n",
      "\n",
      "loss: 0.373895  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.371097 \n",
      "\n",
      "loss: 0.431805  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.373313 \n",
      "\n",
      "loss: 0.405727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.396093 \n",
      "\n",
      "loss: 0.363402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.356065 \n",
      "\n",
      "loss: 0.356986  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.369925 \n",
      "\n",
      "loss: 0.363275  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.379565 \n",
      "\n",
      "loss: 0.377836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.347683 \n",
      "\n",
      "loss: 0.369682  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.350783 \n",
      "\n",
      "loss: 0.344109  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.380663 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 202/500\n",
      "--------------------\n",
      "{'hl': [85, 189, 651], 'alpha': 0.009472576036950777, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4321370127282249}\n",
      "loss: 1.116161  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 56.091592 \n",
      "\n",
      "loss: 56.719368  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 26.264492 \n",
      "\n",
      "loss: 24.745689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 23.499034 \n",
      "\n",
      "loss: 23.921694  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 23.504279 \n",
      "\n",
      "loss: 22.951595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 9.251366 \n",
      "\n",
      "loss: 10.883343  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.624025 \n",
      "\n",
      "loss: 3.508360  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 22.024667 \n",
      "\n",
      "loss: 22.421474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 23.919888 \n",
      "\n",
      "loss: 23.811157  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 6.766311 \n",
      "\n",
      "loss: 6.797919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 13.643801 \n",
      "\n",
      "loss: 12.175654  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 30.048554 \n",
      "\n",
      "loss: 30.010830  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 14.344874 \n",
      "\n",
      "loss: 12.321032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 10.730682 \n",
      "\n",
      "loss: 11.981403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 12.397627 \n",
      "\n",
      "loss: 12.714334  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 14.370961 \n",
      "\n",
      "loss: 15.002609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 15.904626 \n",
      "\n",
      "loss: 17.258644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 10.771289 \n",
      "\n",
      "loss: 10.477190  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 4.469804 \n",
      "\n",
      "loss: 4.120583  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 24.590530 \n",
      "\n",
      "loss: 27.182741  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 15.708848 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 203/500\n",
      "--------------------\n",
      "{'hl': [331, 162, 458], 'alpha': 0.0001875620772837745, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.39818520660779894}\n",
      "loss: 1.152838  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.097605 \n",
      "\n",
      "loss: 5.510523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 15.947292 \n",
      "\n",
      "loss: 16.647078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 6.144547 \n",
      "\n",
      "loss: 5.883225  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 17.327930 \n",
      "\n",
      "loss: 16.402037  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 25.178022 \n",
      "\n",
      "loss: 26.687180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 28.122764 \n",
      "\n",
      "loss: 26.424957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 35.818483 \n",
      "\n",
      "loss: 35.389385  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 12.396639 \n",
      "\n",
      "loss: 13.058832  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 10.641099 \n",
      "\n",
      "loss: 11.080132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 18.173455 \n",
      "\n",
      "loss: 17.837944  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 22.821359 \n",
      "\n",
      "loss: 23.617266  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 32.188417 \n",
      "\n",
      "loss: 31.576748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 19.820081 \n",
      "\n",
      "loss: 19.592068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 17.319003 \n",
      "\n",
      "loss: 14.533620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 11.933605 \n",
      "\n",
      "loss: 11.450714  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.634667 \n",
      "\n",
      "loss: 11.841260  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 12.858282 \n",
      "\n",
      "loss: 10.890179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 16.874639 \n",
      "\n",
      "loss: 16.977777  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 7.858202 \n",
      "\n",
      "loss: 7.910164  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 24.514603 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 204/500\n",
      "--------------------\n",
      "{'hl': [65, 368, 527], 'alpha': 0.00019804442649519826, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.01889986206098893}\n",
      "loss: 1.090564  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.535017 \n",
      "\n",
      "loss: 0.523298  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.499449 \n",
      "\n",
      "loss: 0.468004  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.424310 \n",
      "\n",
      "loss: 0.425566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.411722 \n",
      "\n",
      "loss: 0.401506  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.375076 \n",
      "\n",
      "loss: 0.398348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.367464 \n",
      "\n",
      "loss: 0.322875  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.372441 \n",
      "\n",
      "loss: 0.367037  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.356650 \n",
      "\n",
      "loss: 0.365849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.398921 \n",
      "\n",
      "loss: 0.405926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.368640 \n",
      "\n",
      "loss: 0.412407  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.325325 \n",
      "\n",
      "loss: 0.307044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.343228 \n",
      "\n",
      "loss: 0.313599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366204 \n",
      "\n",
      "loss: 0.319100  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.314878 \n",
      "\n",
      "loss: 0.323814  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.299913 \n",
      "\n",
      "loss: 0.289591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.315250 \n",
      "\n",
      "loss: 0.274023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.333735 \n",
      "\n",
      "loss: 0.304839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.319821 \n",
      "\n",
      "loss: 0.292243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.328097 \n",
      "\n",
      "loss: 0.287537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.344716 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 205/500\n",
      "--------------------\n",
      "{'hl': [301, 86], 'alpha': 0.03790232736307335, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.2314095582977434}\n",
      "loss: 1.116204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 29.820832 \n",
      "\n",
      "loss: 23.529505  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 75.963637 \n",
      "\n",
      "loss: 92.119858  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 1.221886 \n",
      "\n",
      "loss: 0.989364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 1.431520 \n",
      "\n",
      "loss: 1.411613  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 1.459397 \n",
      "\n",
      "loss: 1.029304  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.618269 \n",
      "\n",
      "loss: 0.828746  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.492990 \n",
      "\n",
      "loss: 0.461298  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.528723 \n",
      "\n",
      "loss: 0.540578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.447504 \n",
      "\n",
      "loss: 0.420176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.461185 \n",
      "\n",
      "loss: 0.463444  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.455468 \n",
      "\n",
      "loss: 0.399366  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.442806 \n",
      "\n",
      "loss: 0.412148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.463482 \n",
      "\n",
      "loss: 0.455445  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.431704 \n",
      "\n",
      "loss: 0.417572  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.465437 \n",
      "\n",
      "loss: 0.448826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.442841 \n",
      "\n",
      "loss: 0.455421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.429965 \n",
      "\n",
      "loss: 0.422754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.463999 \n",
      "\n",
      "loss: 0.458534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.7%, Avg loss: 0.791107 \n",
      "\n",
      "loss: 0.824576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.613619 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 206/500\n",
      "--------------------\n",
      "{'hl': [50, 468, 593], 'alpha': 0.0404901903632986, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.2507335142062265}\n",
      "loss: 1.098015  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1510.978651 \n",
      "\n",
      "loss: 1395.480347  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 128.804384 \n",
      "\n",
      "loss: 126.331131  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 12.925311 \n",
      "\n",
      "loss: 11.524723  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 1.600991 \n",
      "\n",
      "loss: 1.972882  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.889552 \n",
      "\n",
      "loss: 0.944988  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 2.376374 \n",
      "\n",
      "loss: 0.948718  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.653471 \n",
      "\n",
      "loss: 0.638971  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.555102 \n",
      "\n",
      "loss: 0.555294  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.511347 \n",
      "\n",
      "loss: 0.522341  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.511207 \n",
      "\n",
      "loss: 0.503559  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.534268 \n",
      "\n",
      "loss: 0.502436  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.507344 \n",
      "\n",
      "loss: 0.536174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.558348 \n",
      "\n",
      "loss: 0.574241  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.453038 \n",
      "\n",
      "loss: 0.527889  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.481191 \n",
      "\n",
      "loss: 0.449926  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.480283 \n",
      "\n",
      "loss: 0.489612  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.438666 \n",
      "\n",
      "loss: 0.440782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.446453 \n",
      "\n",
      "loss: 0.431730  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.422692 \n",
      "\n",
      "loss: 0.402916  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382158 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 207/500\n",
      "--------------------\n",
      "{'hl': [469], 'alpha': 0.00025942242166441366, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.2523240458503286}\n",
      "loss: 1.116878  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.464608 \n",
      "\n",
      "loss: 0.447223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.433613 \n",
      "\n",
      "loss: 0.426699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.397860 \n",
      "\n",
      "loss: 0.412454  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.386388 \n",
      "\n",
      "loss: 0.398416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.379591 \n",
      "\n",
      "loss: 0.415259  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.357530 \n",
      "\n",
      "loss: 0.357913  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.371495 \n",
      "\n",
      "loss: 0.391422  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364867 \n",
      "\n",
      "loss: 0.374044  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.356443 \n",
      "\n",
      "loss: 0.344975  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.334175 \n",
      "\n",
      "loss: 0.377800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.349947 \n",
      "\n",
      "loss: 0.355603  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.342435 \n",
      "\n",
      "loss: 0.321457  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.346167 \n",
      "\n",
      "loss: 0.309994  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.330351 \n",
      "\n",
      "loss: 0.302124  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.322005 \n",
      "\n",
      "loss: 0.317840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.329397 \n",
      "\n",
      "loss: 0.342385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.317858 \n",
      "\n",
      "loss: 0.294371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.344401 \n",
      "\n",
      "loss: 0.318756  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.326604 \n",
      "\n",
      "loss: 0.322939  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.307459 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 208/500\n",
      "--------------------\n",
      "{'hl': [48], 'alpha': 0.0009794333648878966, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.26208186972977027}\n",
      "loss: 1.347462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.468150 \n",
      "\n",
      "loss: 0.480416  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.446991 \n",
      "\n",
      "loss: 0.382752  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.441152 \n",
      "\n",
      "loss: 0.420048  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.433989 \n",
      "\n",
      "loss: 0.457786  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.430302 \n",
      "\n",
      "loss: 0.435627  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.436401 \n",
      "\n",
      "loss: 0.437472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.481995 \n",
      "\n",
      "loss: 0.495049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.478607 \n",
      "\n",
      "loss: 0.481585  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.454479 \n",
      "\n",
      "loss: 0.484254  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.437528 \n",
      "\n",
      "loss: 0.450420  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.473981 \n",
      "\n",
      "loss: 0.434887  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.503361 \n",
      "\n",
      "loss: 0.502512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.499811 \n",
      "\n",
      "loss: 0.466842  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.476330 \n",
      "\n",
      "loss: 0.476327  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.425980 \n",
      "\n",
      "loss: 0.443173  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.451062 \n",
      "\n",
      "loss: 0.463485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.528732 \n",
      "\n",
      "loss: 0.552501  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.453260 \n",
      "\n",
      "loss: 0.458012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.460517 \n",
      "\n",
      "loss: 0.445893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.451269 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 209/500\n",
      "--------------------\n",
      "{'hl': [170, 380, 389], 'alpha': 0.4696206188127089, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.38725494780801034}\n",
      "loss: 1.183422  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 12.830608 \n",
      "\n",
      "loss: 12.461094  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 6.595488 \n",
      "\n",
      "loss: 6.365963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 12.815102 \n",
      "\n",
      "loss: 12.730670  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 7.205491 \n",
      "\n",
      "loss: 7.761014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 11.209684 \n",
      "\n",
      "loss: 11.733766  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.967273 \n",
      "\n",
      "loss: 5.977507  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 20.497932 \n",
      "\n",
      "loss: 19.770191  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 24.130910 \n",
      "\n",
      "loss: 24.345346  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 15.149635 \n",
      "\n",
      "loss: 14.973396  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 10.449065 \n",
      "\n",
      "loss: 11.506564  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.673439 \n",
      "\n",
      "loss: 3.336741  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 8.658382 \n",
      "\n",
      "loss: 8.196541  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 3.958106 \n",
      "\n",
      "loss: 3.950722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 9.502508 \n",
      "\n",
      "loss: 9.277251  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 20.341156 \n",
      "\n",
      "loss: 18.826683  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.640759 \n",
      "\n",
      "loss: 2.585678  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 14.394866 \n",
      "\n",
      "loss: 13.302447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 24.627402 \n",
      "\n",
      "loss: 24.938591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 19.681306 \n",
      "\n",
      "loss: 19.698195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 25.387969 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 210/500\n",
      "--------------------\n",
      "{'hl': [620, 61, 654], 'alpha': 0.03883483174482235, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.047343523162795664}\n",
      "loss: 1.092373  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.915565 \n",
      "\n",
      "loss: 0.935526  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.530968 \n",
      "\n",
      "loss: 0.526780  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.465581 \n",
      "\n",
      "loss: 0.474419  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.463387 \n",
      "\n",
      "loss: 0.486133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.461778 \n",
      "\n",
      "loss: 0.421516  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.469773 \n",
      "\n",
      "loss: 0.470872  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.483184 \n",
      "\n",
      "loss: 0.468127  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.467052 \n",
      "\n",
      "loss: 0.455538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.453352 \n",
      "\n",
      "loss: 0.449791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.468716 \n",
      "\n",
      "loss: 0.456767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.468254 \n",
      "\n",
      "loss: 0.490759  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.460667 \n",
      "\n",
      "loss: 0.443541  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.460175 \n",
      "\n",
      "loss: 0.467922  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.466731 \n",
      "\n",
      "loss: 0.482629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.456832 \n",
      "\n",
      "loss: 0.447640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.460918 \n",
      "\n",
      "loss: 0.475107  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.459145 \n",
      "\n",
      "loss: 0.493658  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.456992 \n",
      "\n",
      "loss: 0.480602  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.448313 \n",
      "\n",
      "loss: 0.431912  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.476683 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 211/500\n",
      "--------------------\n",
      "{'hl': [403, 298, 266], 'alpha': 0.07851174317867551, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.04084284352519719}\n",
      "loss: 1.111283  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.786666 \n",
      "\n",
      "loss: 0.779917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.570022 \n",
      "\n",
      "loss: 0.561991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.544522 \n",
      "\n",
      "loss: 0.540923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.541955 \n",
      "\n",
      "loss: 0.526204  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.544357 \n",
      "\n",
      "loss: 0.544259  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.531020 \n",
      "\n",
      "loss: 0.544044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.527880 \n",
      "\n",
      "loss: 0.521643  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.540384 \n",
      "\n",
      "loss: 0.574815  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.527320 \n",
      "\n",
      "loss: 0.592838  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.565898 \n",
      "\n",
      "loss: 0.578351  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.529449 \n",
      "\n",
      "loss: 0.516717  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.547648 \n",
      "\n",
      "loss: 0.531969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.544313 \n",
      "\n",
      "loss: 0.541402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.549776 \n",
      "\n",
      "loss: 0.564390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.580214 \n",
      "\n",
      "loss: 0.584833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.781051 \n",
      "\n",
      "loss: 0.808168  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 2.969400 \n",
      "\n",
      "loss: 3.038521  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 1.032533 \n",
      "\n",
      "loss: 1.192290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.338556 \n",
      "\n",
      "loss: 2.318038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 1.344393 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 212/500\n",
      "--------------------\n",
      "{'hl': [152, 366, 325], 'alpha': 0.7426531556403723, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.29756110995297225}\n",
      "loss: 1.107555  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.159276 \n",
      "\n",
      "loss: 3.203557  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.403211 \n",
      "\n",
      "loss: 2.492357  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.493598 \n",
      "\n",
      "loss: 3.607303  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.507972 \n",
      "\n",
      "loss: 2.507415  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.743254 \n",
      "\n",
      "loss: 3.927640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.360696 \n",
      "\n",
      "loss: 3.240510  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.733566 \n",
      "\n",
      "loss: 3.633859  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.759145 \n",
      "\n",
      "loss: 2.701452  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.539910 \n",
      "\n",
      "loss: 3.581156  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.623989 \n",
      "\n",
      "loss: 2.593166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.219919 \n",
      "\n",
      "loss: 3.166617  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.311992 \n",
      "\n",
      "loss: 2.219457  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.154779 \n",
      "\n",
      "loss: 3.054857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.545118 \n",
      "\n",
      "loss: 2.599181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.947154 \n",
      "\n",
      "loss: 3.996196  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.890025 \n",
      "\n",
      "loss: 2.807986  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.357021 \n",
      "\n",
      "loss: 3.301931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.785485 \n",
      "\n",
      "loss: 2.686012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.279337 \n",
      "\n",
      "loss: 3.348871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.602554 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 213/500\n",
      "--------------------\n",
      "{'hl': [325], 'alpha': 0.017206331283298126, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.3350911883573618}\n",
      "loss: 1.011435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.466746 \n",
      "\n",
      "loss: 0.431993  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.439551 \n",
      "\n",
      "loss: 0.440329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.417733 \n",
      "\n",
      "loss: 0.347670  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.409513 \n",
      "\n",
      "loss: 0.403144  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.388095 \n",
      "\n",
      "loss: 0.388041  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.393908 \n",
      "\n",
      "loss: 0.396824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.391233 \n",
      "\n",
      "loss: 0.366903  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.389404 \n",
      "\n",
      "loss: 0.392426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.385413 \n",
      "\n",
      "loss: 0.388451  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.374216 \n",
      "\n",
      "loss: 0.367941  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.374335 \n",
      "\n",
      "loss: 0.351310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.391950 \n",
      "\n",
      "loss: 0.371746  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.391643 \n",
      "\n",
      "loss: 0.397604  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.378224 \n",
      "\n",
      "loss: 0.363151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.376007 \n",
      "\n",
      "loss: 0.374500  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.387160 \n",
      "\n",
      "loss: 0.374658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.395938 \n",
      "\n",
      "loss: 0.375718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.381043 \n",
      "\n",
      "loss: 0.401927  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.387305 \n",
      "\n",
      "loss: 0.394793  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.371388 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 214/500\n",
      "--------------------\n",
      "{'hl': [709, 547, 103], 'alpha': 0.03837949738367462, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.009213445841987206}\n",
      "loss: 1.169364  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.818537 \n",
      "\n",
      "loss: 0.838196  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.826764 \n",
      "\n",
      "loss: 0.798821  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.819539 \n",
      "\n",
      "loss: 0.830886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.818028 \n",
      "\n",
      "loss: 0.813417  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.803533 \n",
      "\n",
      "loss: 0.816735  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817466 \n",
      "\n",
      "loss: 0.797961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.836917 \n",
      "\n",
      "loss: 0.809981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809773 \n",
      "\n",
      "loss: 0.806780  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.827499 \n",
      "\n",
      "loss: 0.813384  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.817119 \n",
      "\n",
      "loss: 0.827958  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.815393 \n",
      "\n",
      "loss: 0.834337  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.835637 \n",
      "\n",
      "loss: 0.802502  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.825268 \n",
      "\n",
      "loss: 0.833312  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.825592 \n",
      "\n",
      "loss: 0.840063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.815319 \n",
      "\n",
      "loss: 0.822836  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.823299 \n",
      "\n",
      "loss: 0.807357  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.827735 \n",
      "\n",
      "loss: 0.810761  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.812390 \n",
      "\n",
      "loss: 0.834802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.822039 \n",
      "\n",
      "loss: 0.775043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.817099 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 215/500\n",
      "--------------------\n",
      "{'hl': [192, 227], 'alpha': 0.0023277127236975156, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.11334886896229024}\n",
      "loss: 1.164961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.977133 \n",
      "\n",
      "loss: 0.944653  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.793564 \n",
      "\n",
      "loss: 0.819539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.732758 \n",
      "\n",
      "loss: 0.745826  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.644281 \n",
      "\n",
      "loss: 0.638615  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.582254 \n",
      "\n",
      "loss: 0.538615  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.556071 \n",
      "\n",
      "loss: 0.541512  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.537010 \n",
      "\n",
      "loss: 0.564900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.544054 \n",
      "\n",
      "loss: 0.525982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.511730 \n",
      "\n",
      "loss: 0.578498  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.523938 \n",
      "\n",
      "loss: 0.552941  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.514756 \n",
      "\n",
      "loss: 0.524203  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.519100 \n",
      "\n",
      "loss: 0.542431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.504559 \n",
      "\n",
      "loss: 0.493752  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.500876 \n",
      "\n",
      "loss: 0.528969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.525877 \n",
      "\n",
      "loss: 0.539652  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.486676 \n",
      "\n",
      "loss: 0.505740  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.512306 \n",
      "\n",
      "loss: 0.506279  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.499915 \n",
      "\n",
      "loss: 0.449969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.491381 \n",
      "\n",
      "loss: 0.499266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.492685 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 216/500\n",
      "--------------------\n",
      "{'hl': [166], 'alpha': 0.00020354495248716827, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3309984257619717}\n",
      "loss: 1.072865  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.457562 \n",
      "\n",
      "loss: 0.449745  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.427255 \n",
      "\n",
      "loss: 0.404246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.396166 \n",
      "\n",
      "loss: 0.374350  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.383190 \n",
      "\n",
      "loss: 0.388593  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.356281 \n",
      "\n",
      "loss: 0.368649  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.372671 \n",
      "\n",
      "loss: 0.346120  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.356175 \n",
      "\n",
      "loss: 0.323991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.350438 \n",
      "\n",
      "loss: 0.305984  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.350859 \n",
      "\n",
      "loss: 0.341609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.334066 \n",
      "\n",
      "loss: 0.340529  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.334728 \n",
      "\n",
      "loss: 0.318592  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.334571 \n",
      "\n",
      "loss: 0.339907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.337429 \n",
      "\n",
      "loss: 0.309557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.336253 \n",
      "\n",
      "loss: 0.315629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.318763 \n",
      "\n",
      "loss: 0.330799  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.325364 \n",
      "\n",
      "loss: 0.339062  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.317533 \n",
      "\n",
      "loss: 0.319964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.329042 \n",
      "\n",
      "loss: 0.349914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.339288 \n",
      "\n",
      "loss: 0.333652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.304065 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 217/500\n",
      "--------------------\n",
      "{'hl': [142, 619, 393], 'alpha': 0.00041401020408621947, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.36061938060293297}\n",
      "loss: 1.144391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.507795 \n",
      "\n",
      "loss: 0.504634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.468155 \n",
      "\n",
      "loss: 0.457063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.429059 \n",
      "\n",
      "loss: 0.450738  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.499250 \n",
      "\n",
      "loss: 0.498839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.432565 \n",
      "\n",
      "loss: 0.392917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.393302 \n",
      "\n",
      "loss: 0.402941  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.406489 \n",
      "\n",
      "loss: 0.359499  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.449565 \n",
      "\n",
      "loss: 0.457943  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.433003 \n",
      "\n",
      "loss: 0.425000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.355287 \n",
      "\n",
      "loss: 0.369970  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.392279 \n",
      "\n",
      "loss: 0.350453  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.387976 \n",
      "\n",
      "loss: 0.399440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.354296 \n",
      "\n",
      "loss: 0.369253  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.348304 \n",
      "\n",
      "loss: 0.353631  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.345613 \n",
      "\n",
      "loss: 0.354329  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.355309 \n",
      "\n",
      "loss: 0.329917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.369024 \n",
      "\n",
      "loss: 0.361012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.340173 \n",
      "\n",
      "loss: 0.318723  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.341882 \n",
      "\n",
      "loss: 0.356766  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.351921 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 218/500\n",
      "--------------------\n",
      "{'hl': [428], 'alpha': 0.0028654818140249655, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3053366515206953}\n",
      "loss: 1.124182  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 4.351590 \n",
      "\n",
      "loss: 4.410719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 1.869199 \n",
      "\n",
      "loss: 1.511854  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 1.801117 \n",
      "\n",
      "loss: 1.869257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 1.408716 \n",
      "\n",
      "loss: 1.210653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 2.273462 \n",
      "\n",
      "loss: 2.283694  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 5.269455 \n",
      "\n",
      "loss: 5.238153  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 3.011846 \n",
      "\n",
      "loss: 3.163902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 2.077487 \n",
      "\n",
      "loss: 1.756536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 2.439998 \n",
      "\n",
      "loss: 2.105222  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 3.228499 \n",
      "\n",
      "loss: 3.142517  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 1.946802 \n",
      "\n",
      "loss: 2.033013  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 3.094790 \n",
      "\n",
      "loss: 3.064707  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 2.573202 \n",
      "\n",
      "loss: 2.680546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 3.973259 \n",
      "\n",
      "loss: 4.113625  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 2.141229 \n",
      "\n",
      "loss: 1.887700  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 3.431653 \n",
      "\n",
      "loss: 3.088930  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 2.643309 \n",
      "\n",
      "loss: 2.818041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 1.460808 \n",
      "\n",
      "loss: 1.379518  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 2.134045 \n",
      "\n",
      "loss: 2.384518  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 5.420712 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 219/500\n",
      "--------------------\n",
      "{'hl': [467, 247, 554], 'alpha': 0.0009050529514460012, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.1839836950166939}\n",
      "loss: 1.139482  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.012811 \n",
      "\n",
      "loss: 1.019437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.833266 \n",
      "\n",
      "loss: 0.802652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815758 \n",
      "\n",
      "loss: 0.816121  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.837026 \n",
      "\n",
      "loss: 0.836162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.822242 \n",
      "\n",
      "loss: 0.834444  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820849 \n",
      "\n",
      "loss: 0.780332  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.821229 \n",
      "\n",
      "loss: 0.841020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.810834 \n",
      "\n",
      "loss: 0.832309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.804691 \n",
      "\n",
      "loss: 0.832887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.805204 \n",
      "\n",
      "loss: 0.808918  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819088 \n",
      "\n",
      "loss: 0.791422  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.815203 \n",
      "\n",
      "loss: 0.796558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.813930 \n",
      "\n",
      "loss: 0.852543  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.819586 \n",
      "\n",
      "loss: 0.820697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.772875 \n",
      "\n",
      "loss: 0.771457  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.793913 \n",
      "\n",
      "loss: 0.826211  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.790103 \n",
      "\n",
      "loss: 0.802060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.732157 \n",
      "\n",
      "loss: 0.704914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.626830 \n",
      "\n",
      "loss: 0.600078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.597261 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 220/500\n",
      "--------------------\n",
      "{'hl': [459, 480, 296], 'alpha': 0.12956752083824774, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.4084639306666619}\n",
      "loss: 1.043911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.379767 \n",
      "\n",
      "loss: 1.419849  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.087026 \n",
      "\n",
      "loss: 1.052435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.191503 \n",
      "\n",
      "loss: 1.207982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.077445 \n",
      "\n",
      "loss: 1.105699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.163238 \n",
      "\n",
      "loss: 1.200379  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.058919 \n",
      "\n",
      "loss: 1.070336  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.312167 \n",
      "\n",
      "loss: 1.330200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.095600 \n",
      "\n",
      "loss: 1.105881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.015249 \n",
      "\n",
      "loss: 0.992965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.077562 \n",
      "\n",
      "loss: 1.077554  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.080242 \n",
      "\n",
      "loss: 1.072296  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.049279 \n",
      "\n",
      "loss: 1.029456  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.198025 \n",
      "\n",
      "loss: 1.199444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.005974 \n",
      "\n",
      "loss: 1.014095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.207214 \n",
      "\n",
      "loss: 1.272426  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.103470 \n",
      "\n",
      "loss: 1.143648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.106677 \n",
      "\n",
      "loss: 1.098122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.950590 \n",
      "\n",
      "loss: 0.993510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.908233 \n",
      "\n",
      "loss: 0.905461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.034327 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 221/500\n",
      "--------------------\n",
      "{'hl': [149, 264, 61], 'alpha': 0.03670423229585824, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.35572934846178844}\n",
      "loss: 1.108695  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.492270 \n",
      "\n",
      "loss: 0.464265  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.464382 \n",
      "\n",
      "loss: 0.425277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.432068 \n",
      "\n",
      "loss: 0.432030  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.410263 \n",
      "\n",
      "loss: 0.447912  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.406554 \n",
      "\n",
      "loss: 0.390480  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.412998 \n",
      "\n",
      "loss: 0.411925  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.423970 \n",
      "\n",
      "loss: 0.391358  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.410774 \n",
      "\n",
      "loss: 0.377290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.413031 \n",
      "\n",
      "loss: 0.426318  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.398544 \n",
      "\n",
      "loss: 0.396989  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.409662 \n",
      "\n",
      "loss: 0.403767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.405098 \n",
      "\n",
      "loss: 0.406824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.423814 \n",
      "\n",
      "loss: 0.401546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.404266 \n",
      "\n",
      "loss: 0.393703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.399669 \n",
      "\n",
      "loss: 0.410916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.396201 \n",
      "\n",
      "loss: 0.393140  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.409084 \n",
      "\n",
      "loss: 0.341193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.414032 \n",
      "\n",
      "loss: 0.401352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.405196 \n",
      "\n",
      "loss: 0.407472  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.413365 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 222/500\n",
      "--------------------\n",
      "{'hl': [135, 299, 93], 'alpha': 0.11284110261492675, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.4526625738682228}\n",
      "loss: 1.114892  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 376.810577 \n",
      "\n",
      "loss: 318.639099  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 213.845016 \n",
      "\n",
      "loss: 147.783295  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 20.236959 \n",
      "\n",
      "loss: 30.409967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 1.343354 \n",
      "\n",
      "loss: 2.405735  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.624391 \n",
      "\n",
      "loss: 0.614140  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.555349 \n",
      "\n",
      "loss: 0.531229  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.591596 \n",
      "\n",
      "loss: 0.549568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.515073 \n",
      "\n",
      "loss: 0.494894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.501152 \n",
      "\n",
      "loss: 0.546250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.480037 \n",
      "\n",
      "loss: 0.492603  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.460529 \n",
      "\n",
      "loss: 0.468728  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.499989 \n",
      "\n",
      "loss: 0.465074  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.563694 \n",
      "\n",
      "loss: 0.611043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.491684 \n",
      "\n",
      "loss: 0.474608  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.492343 \n",
      "\n",
      "loss: 0.493245  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.505609 \n",
      "\n",
      "loss: 0.498011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.456067 \n",
      "\n",
      "loss: 0.415364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.425560 \n",
      "\n",
      "loss: 0.435407  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.515643 \n",
      "\n",
      "loss: 0.509043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.502315 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 223/500\n",
      "--------------------\n",
      "{'hl': [455], 'alpha': 0.00023273102306487677, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.4423264238816319}\n",
      "loss: 1.115457  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 3.078152 \n",
      "\n",
      "loss: 3.027011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 1.926351 \n",
      "\n",
      "loss: 1.835437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 2.512097 \n",
      "\n",
      "loss: 2.530683  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 4.361244 \n",
      "\n",
      "loss: 4.681586  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 5.340234 \n",
      "\n",
      "loss: 5.232568  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 3.991696 \n",
      "\n",
      "loss: 4.087247  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 4.977346 \n",
      "\n",
      "loss: 4.463751  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 2.256304 \n",
      "\n",
      "loss: 2.127205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 2.806787 \n",
      "\n",
      "loss: 2.241003  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 5.210509 \n",
      "\n",
      "loss: 5.248922  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 5.068847 \n",
      "\n",
      "loss: 4.986623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 2.247748 \n",
      "\n",
      "loss: 2.038673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 7.942060 \n",
      "\n",
      "loss: 8.247469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 3.927144 \n",
      "\n",
      "loss: 3.366536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 8.867317 \n",
      "\n",
      "loss: 8.280633  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 4.208851 \n",
      "\n",
      "loss: 4.028591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 3.646011 \n",
      "\n",
      "loss: 3.569389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 4.372610 \n",
      "\n",
      "loss: 3.914085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 3.003463 \n",
      "\n",
      "loss: 2.842390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 2.709841 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 224/500\n",
      "--------------------\n",
      "{'hl': [432], 'alpha': 0.00016331555408740734, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.19314444241049303}\n",
      "loss: 1.159481  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.477623 \n",
      "\n",
      "loss: 0.450333  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.460118 \n",
      "\n",
      "loss: 0.401665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.412268 \n",
      "\n",
      "loss: 0.412750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.399127 \n",
      "\n",
      "loss: 0.381069  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.371880 \n",
      "\n",
      "loss: 0.354504  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.373647 \n",
      "\n",
      "loss: 0.383203  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.373937 \n",
      "\n",
      "loss: 0.393141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.372093 \n",
      "\n",
      "loss: 0.382024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.368534 \n",
      "\n",
      "loss: 0.389078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340182 \n",
      "\n",
      "loss: 0.352464  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.356150 \n",
      "\n",
      "loss: 0.355326  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.353497 \n",
      "\n",
      "loss: 0.337921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.355250 \n",
      "\n",
      "loss: 0.355120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.337740 \n",
      "\n",
      "loss: 0.325720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.337801 \n",
      "\n",
      "loss: 0.336756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.336832 \n",
      "\n",
      "loss: 0.340730  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.338459 \n",
      "\n",
      "loss: 0.344263  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.341368 \n",
      "\n",
      "loss: 0.294555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.319756 \n",
      "\n",
      "loss: 0.399230  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.317963 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 225/500\n",
      "--------------------\n",
      "{'hl': [391], 'alpha': 0.0007909609348138304, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4196042261770417}\n",
      "loss: 1.109107  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.450354 \n",
      "\n",
      "loss: 0.448620  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.420568 \n",
      "\n",
      "loss: 0.391630  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.387735 \n",
      "\n",
      "loss: 0.389718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.359486 \n",
      "\n",
      "loss: 0.399507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360399 \n",
      "\n",
      "loss: 0.365724  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.368767 \n",
      "\n",
      "loss: 0.355317  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.355305 \n",
      "\n",
      "loss: 0.355367  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.338390 \n",
      "\n",
      "loss: 0.334306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.338548 \n",
      "\n",
      "loss: 0.322629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.318578 \n",
      "\n",
      "loss: 0.323352  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.327372 \n",
      "\n",
      "loss: 0.316619  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.329286 \n",
      "\n",
      "loss: 0.316558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.321979 \n",
      "\n",
      "loss: 0.287824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.320490 \n",
      "\n",
      "loss: 0.312432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.395256 \n",
      "\n",
      "loss: 0.384167  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.300884 \n",
      "\n",
      "loss: 0.328515  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.309161 \n",
      "\n",
      "loss: 0.323956  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.310281 \n",
      "\n",
      "loss: 0.308617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.315534 \n",
      "\n",
      "loss: 0.288022  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.318240 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 226/500\n",
      "--------------------\n",
      "{'hl': [351, 157, 148], 'alpha': 0.0001423025768505171, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.37944469326732705}\n",
      "loss: 1.086606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820584 \n",
      "\n",
      "loss: 0.818039  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.819006 \n",
      "\n",
      "loss: 0.821659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.812220 \n",
      "\n",
      "loss: 0.799584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817859 \n",
      "\n",
      "loss: 0.824000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.801386 \n",
      "\n",
      "loss: 0.799340  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.802470 \n",
      "\n",
      "loss: 0.804934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.837425 \n",
      "\n",
      "loss: 0.776668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.8%, Avg loss: 0.894222 \n",
      "\n",
      "loss: 0.893462  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.563313 \n",
      "\n",
      "loss: 0.615250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.527664 \n",
      "\n",
      "loss: 0.540233  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.533731 \n",
      "\n",
      "loss: 0.505583  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.517816 \n",
      "\n",
      "loss: 0.527459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.514315 \n",
      "\n",
      "loss: 0.552755  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.506584 \n",
      "\n",
      "loss: 0.530229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.499589 \n",
      "\n",
      "loss: 0.483890  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.505624 \n",
      "\n",
      "loss: 0.476659  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.549392 \n",
      "\n",
      "loss: 0.533166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.543787 \n",
      "\n",
      "loss: 0.541180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.480766 \n",
      "\n",
      "loss: 0.519781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.541450 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 227/500\n",
      "--------------------\n",
      "{'hl': [467, 638], 'alpha': 0.00010495540123088622, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.12803637182567865}\n",
      "loss: 1.048115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.509942 \n",
      "\n",
      "loss: 0.463369  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.469478 \n",
      "\n",
      "loss: 0.459665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.443066 \n",
      "\n",
      "loss: 0.453862  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.414852 \n",
      "\n",
      "loss: 0.410807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.398678 \n",
      "\n",
      "loss: 0.412084  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.395045 \n",
      "\n",
      "loss: 0.392635  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.386610 \n",
      "\n",
      "loss: 0.420676  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.363372 \n",
      "\n",
      "loss: 0.355134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.354802 \n",
      "\n",
      "loss: 0.360764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.355268 \n",
      "\n",
      "loss: 0.357399  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.348001 \n",
      "\n",
      "loss: 0.391423  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.358467 \n",
      "\n",
      "loss: 0.346529  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.336862 \n",
      "\n",
      "loss: 0.349610  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.327878 \n",
      "\n",
      "loss: 0.329487  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.321570 \n",
      "\n",
      "loss: 0.307360  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.326649 \n",
      "\n",
      "loss: 0.326589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.335604 \n",
      "\n",
      "loss: 0.339315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.331945 \n",
      "\n",
      "loss: 0.320831  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.321453 \n",
      "\n",
      "loss: 0.300680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.298150 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 228/500\n",
      "--------------------\n",
      "{'hl': [569], 'alpha': 0.5766387152613558, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3881086990544347}\n",
      "loss: 1.068623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 8.554835 \n",
      "\n",
      "loss: 8.647670  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.600765 \n",
      "\n",
      "loss: 2.614350  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 20.840341 \n",
      "\n",
      "loss: 20.527605  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 17.433891 \n",
      "\n",
      "loss: 16.943153  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 21.419176 \n",
      "\n",
      "loss: 21.814522  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 9.538899 \n",
      "\n",
      "loss: 10.016788  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 25.011730 \n",
      "\n",
      "loss: 24.166706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 7.984433 \n",
      "\n",
      "loss: 7.838046  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 12.936610 \n",
      "\n",
      "loss: 12.083393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.375568 \n",
      "\n",
      "loss: 6.377360  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 24.229195 \n",
      "\n",
      "loss: 24.466591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 18.352375 \n",
      "\n",
      "loss: 18.959028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 22.660381 \n",
      "\n",
      "loss: 23.652895  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 3.144041 \n",
      "\n",
      "loss: 3.174457  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 22.577636 \n",
      "\n",
      "loss: 23.456493  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 9.556857 \n",
      "\n",
      "loss: 9.304322  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 19.636312 \n",
      "\n",
      "loss: 20.341999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 5.182799 \n",
      "\n",
      "loss: 5.209809  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 20.612179 \n",
      "\n",
      "loss: 20.360092  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 9.384737 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 229/500\n",
      "--------------------\n",
      "{'hl': [316], 'alpha': 0.00030718031445219063, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3195119709131879}\n",
      "loss: 1.119717  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 2.253099 \n",
      "\n",
      "loss: 2.243388  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.988441 \n",
      "\n",
      "loss: 2.050577  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.960458 \n",
      "\n",
      "loss: 1.026874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.573085 \n",
      "\n",
      "loss: 2.399811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 1.661585 \n",
      "\n",
      "loss: 1.892375  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.123461 \n",
      "\n",
      "loss: 1.113263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 1.544356 \n",
      "\n",
      "loss: 1.147207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 1.584120 \n",
      "\n",
      "loss: 1.694610  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.939500 \n",
      "\n",
      "loss: 0.943400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 1.932880 \n",
      "\n",
      "loss: 1.720213  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.877642 \n",
      "\n",
      "loss: 1.849578  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 1.002501 \n",
      "\n",
      "loss: 0.960926  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.863101 \n",
      "\n",
      "loss: 1.925562  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 1.423867 \n",
      "\n",
      "loss: 1.112994  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 2.996858 \n",
      "\n",
      "loss: 3.044436  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 2.284778 \n",
      "\n",
      "loss: 2.168424  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.971927 \n",
      "\n",
      "loss: 1.623148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 1.575050 \n",
      "\n",
      "loss: 1.672486  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 1.345177 \n",
      "\n",
      "loss: 1.281672  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 1.187944 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 230/500\n",
      "--------------------\n",
      "{'hl': [476, 72, 121], 'alpha': 0.2222034933733073, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3160142755123699}\n",
      "loss: 0.991737  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.286033 \n",
      "\n",
      "loss: 1.301296  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.279867 \n",
      "\n",
      "loss: 1.326974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.232438 \n",
      "\n",
      "loss: 1.249416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.239165 \n",
      "\n",
      "loss: 1.256006  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.195080 \n",
      "\n",
      "loss: 1.199472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.435921 \n",
      "\n",
      "loss: 1.427433  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.089834 \n",
      "\n",
      "loss: 1.130815  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.414535 \n",
      "\n",
      "loss: 1.419729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.129468 \n",
      "\n",
      "loss: 1.111402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.439949 \n",
      "\n",
      "loss: 1.436274  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.260772 \n",
      "\n",
      "loss: 1.274988  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.223509 \n",
      "\n",
      "loss: 1.199111  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.138276 \n",
      "\n",
      "loss: 1.151108  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.270703 \n",
      "\n",
      "loss: 1.324773  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.073826 \n",
      "\n",
      "loss: 1.059635  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.240582 \n",
      "\n",
      "loss: 1.227049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.211453 \n",
      "\n",
      "loss: 1.195943  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.225556 \n",
      "\n",
      "loss: 1.235194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.236704 \n",
      "\n",
      "loss: 1.279196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.519489 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 231/500\n",
      "--------------------\n",
      "{'hl': [255, 155, 306], 'alpha': 0.005211413964998483, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.28537479163961216}\n",
      "loss: 1.108613  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.475522 \n",
      "\n",
      "loss: 0.452197  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.476787 \n",
      "\n",
      "loss: 0.487944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.403182 \n",
      "\n",
      "loss: 0.404604  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.380722 \n",
      "\n",
      "loss: 0.369106  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.369869 \n",
      "\n",
      "loss: 0.377212  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.375685 \n",
      "\n",
      "loss: 0.335988  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.367846 \n",
      "\n",
      "loss: 0.402955  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.375746 \n",
      "\n",
      "loss: 0.380346  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.342333 \n",
      "\n",
      "loss: 0.331524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.353648 \n",
      "\n",
      "loss: 0.398866  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.327543 \n",
      "\n",
      "loss: 0.315273  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.332955 \n",
      "\n",
      "loss: 0.307216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.361549 \n",
      "\n",
      "loss: 0.375236  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.363627 \n",
      "\n",
      "loss: 0.357729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.325763 \n",
      "\n",
      "loss: 0.338269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.317837 \n",
      "\n",
      "loss: 0.297424  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.341531 \n",
      "\n",
      "loss: 0.337297  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.339025 \n",
      "\n",
      "loss: 0.280711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.399634 \n",
      "\n",
      "loss: 0.364052  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.318044 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 232/500\n",
      "--------------------\n",
      "{'hl': [688], 'alpha': 0.04708251047284636, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4767064986249589}\n",
      "loss: 1.088250  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.462857 \n",
      "\n",
      "loss: 0.447480  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.460397 \n",
      "\n",
      "loss: 0.464306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.443716 \n",
      "\n",
      "loss: 0.411575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.445121 \n",
      "\n",
      "loss: 0.410385  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.437938 \n",
      "\n",
      "loss: 0.441227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.445896 \n",
      "\n",
      "loss: 0.431784  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.449611 \n",
      "\n",
      "loss: 0.447757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.443048 \n",
      "\n",
      "loss: 0.426767  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.430834 \n",
      "\n",
      "loss: 0.431062  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.425588 \n",
      "\n",
      "loss: 0.431277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.455657 \n",
      "\n",
      "loss: 0.435278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.439285 \n",
      "\n",
      "loss: 0.454006  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.439109 \n",
      "\n",
      "loss: 0.435177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.436052 \n",
      "\n",
      "loss: 0.446316  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.443609 \n",
      "\n",
      "loss: 0.441926  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.439335 \n",
      "\n",
      "loss: 0.438398  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.450790 \n",
      "\n",
      "loss: 0.448580  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.436547 \n",
      "\n",
      "loss: 0.426982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.439309 \n",
      "\n",
      "loss: 0.473381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.439378 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 233/500\n",
      "--------------------\n",
      "{'hl': [527, 527, 575], 'alpha': 0.00012059720016324654, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.31787182865516816}\n",
      "loss: 1.079897  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819280 \n",
      "\n",
      "loss: 0.815683  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.826893 \n",
      "\n",
      "loss: 0.814158  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.805245 \n",
      "\n",
      "loss: 0.820724  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.813798 \n",
      "\n",
      "loss: 0.812215  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.805251 \n",
      "\n",
      "loss: 0.833244  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.808638 \n",
      "\n",
      "loss: 0.784048  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.822192 \n",
      "\n",
      "loss: 0.806644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.780878 \n",
      "\n",
      "loss: 0.797526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 0.756351 \n",
      "\n",
      "loss: 0.750255  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.720990 \n",
      "\n",
      "loss: 0.739321  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.631314 \n",
      "\n",
      "loss: 0.646401  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.581954 \n",
      "\n",
      "loss: 0.545818  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.546922 \n",
      "\n",
      "loss: 0.566129  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.608004 \n",
      "\n",
      "loss: 0.647986  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.517913 \n",
      "\n",
      "loss: 0.526199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.518779 \n",
      "\n",
      "loss: 0.551600  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.529703 \n",
      "\n",
      "loss: 0.543074  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.514863 \n",
      "\n",
      "loss: 0.541110  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.497291 \n",
      "\n",
      "loss: 0.485603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.504925 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 234/500\n",
      "--------------------\n",
      "{'hl': [267, 24], 'alpha': 0.0026814858283481157, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.12063884960038375}\n",
      "loss: 1.035826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.817547 \n",
      "\n",
      "loss: 0.869232  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.640070 \n",
      "\n",
      "loss: 0.875884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.491608 \n",
      "\n",
      "loss: 0.445695  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.503157 \n",
      "\n",
      "loss: 0.509181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.463140 \n",
      "\n",
      "loss: 0.454762  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.447275 \n",
      "\n",
      "loss: 0.446355  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.437047 \n",
      "\n",
      "loss: 0.456292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.417014 \n",
      "\n",
      "loss: 0.408517  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.425829 \n",
      "\n",
      "loss: 0.411524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.401033 \n",
      "\n",
      "loss: 0.402714  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.422263 \n",
      "\n",
      "loss: 0.400801  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.459667 \n",
      "\n",
      "loss: 0.404950  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.439891 \n",
      "\n",
      "loss: 0.439677  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.445667 \n",
      "\n",
      "loss: 0.450422  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.405158 \n",
      "\n",
      "loss: 0.396351  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.410449 \n",
      "\n",
      "loss: 0.398166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.441624 \n",
      "\n",
      "loss: 0.415033  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.424727 \n",
      "\n",
      "loss: 0.390347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.400563 \n",
      "\n",
      "loss: 0.405781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.399236 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 235/500\n",
      "--------------------\n",
      "{'hl': [651, 114, 603], 'alpha': 0.08724648503805381, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.022263410578774567}\n",
      "loss: 1.077767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.814959 \n",
      "\n",
      "loss: 0.819853  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.686384 \n",
      "\n",
      "loss: 0.668508  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.599232 \n",
      "\n",
      "loss: 0.582848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.568521 \n",
      "\n",
      "loss: 0.548711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.551138 \n",
      "\n",
      "loss: 0.558045  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.539053 \n",
      "\n",
      "loss: 0.526097  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.537985 \n",
      "\n",
      "loss: 0.511396  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.526784 \n",
      "\n",
      "loss: 0.540144  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.509695 \n",
      "\n",
      "loss: 0.518794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.509898 \n",
      "\n",
      "loss: 0.510558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.522201 \n",
      "\n",
      "loss: 0.503119  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.510886 \n",
      "\n",
      "loss: 0.511418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.508723 \n",
      "\n",
      "loss: 0.522737  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.511158 \n",
      "\n",
      "loss: 0.508123  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.510803 \n",
      "\n",
      "loss: 0.533356  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.497561 \n",
      "\n",
      "loss: 0.508129  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.517144 \n",
      "\n",
      "loss: 0.477151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.518218 \n",
      "\n",
      "loss: 0.473621  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.492011 \n",
      "\n",
      "loss: 0.497220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.501641 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 236/500\n",
      "--------------------\n",
      "{'hl': [354, 666, 187], 'alpha': 0.2096691946523317, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3159047502943931}\n",
      "loss: 1.165756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.049858 \n",
      "\n",
      "loss: 1.086545  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.637153 \n",
      "\n",
      "loss: 2.670913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 4.173912 \n",
      "\n",
      "loss: 3.832252  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 8.926407 \n",
      "\n",
      "loss: 8.852919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.732451 \n",
      "\n",
      "loss: 2.797224  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.090112 \n",
      "\n",
      "loss: 1.169771  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.291547 \n",
      "\n",
      "loss: 1.134202  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 10.633412 \n",
      "\n",
      "loss: 10.333941  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 6.262797 \n",
      "\n",
      "loss: 6.142038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.732980 \n",
      "\n",
      "loss: 6.803925  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 12.175025 \n",
      "\n",
      "loss: 12.574914  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 19.429181 \n",
      "\n",
      "loss: 19.016119  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.021249 \n",
      "\n",
      "loss: 2.834233  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 6.127670 \n",
      "\n",
      "loss: 6.043317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.261471 \n",
      "\n",
      "loss: 6.249609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.295506 \n",
      "\n",
      "loss: 1.180143  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 17.747500 \n",
      "\n",
      "loss: 17.398142  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.531801 \n",
      "\n",
      "loss: 1.469097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.520270 \n",
      "\n",
      "loss: 4.700881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 14.624792 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 237/500\n",
      "--------------------\n",
      "{'hl': [72], 'alpha': 0.0731442566097951, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.1467919413303981}\n",
      "loss: 0.949150  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.610018 \n",
      "\n",
      "loss: 0.592607  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.565736 \n",
      "\n",
      "loss: 0.571938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.567606 \n",
      "\n",
      "loss: 0.549634  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.554986 \n",
      "\n",
      "loss: 0.557858  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.548135 \n",
      "\n",
      "loss: 0.528275  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.548276 \n",
      "\n",
      "loss: 0.561529  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.575743 \n",
      "\n",
      "loss: 0.542440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.544955 \n",
      "\n",
      "loss: 0.578705  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.545416 \n",
      "\n",
      "loss: 0.537928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.548942 \n",
      "\n",
      "loss: 0.573118  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.545098 \n",
      "\n",
      "loss: 0.541446  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.560850 \n",
      "\n",
      "loss: 0.559428  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.535580 \n",
      "\n",
      "loss: 0.544777  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.537169 \n",
      "\n",
      "loss: 0.548418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.539310 \n",
      "\n",
      "loss: 0.551272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.556853 \n",
      "\n",
      "loss: 0.515004  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.551217 \n",
      "\n",
      "loss: 0.538523  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.547002 \n",
      "\n",
      "loss: 0.551150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.539641 \n",
      "\n",
      "loss: 0.570771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.544395 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 238/500\n",
      "--------------------\n",
      "{'hl': [212], 'alpha': 0.3492702077130966, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.2577402562683239}\n",
      "loss: 1.188671  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.667280 \n",
      "\n",
      "loss: 0.684051  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.621115 \n",
      "\n",
      "loss: 0.603907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.650337 \n",
      "\n",
      "loss: 0.636599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.653305 \n",
      "\n",
      "loss: 0.658002  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.633319 \n",
      "\n",
      "loss: 0.620719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.660642 \n",
      "\n",
      "loss: 0.664418  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.639411 \n",
      "\n",
      "loss: 0.650287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.664217 \n",
      "\n",
      "loss: 0.654948  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.652673 \n",
      "\n",
      "loss: 0.630524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.637035 \n",
      "\n",
      "loss: 0.624077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.672034 \n",
      "\n",
      "loss: 0.678169  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.640586 \n",
      "\n",
      "loss: 0.631619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.646788 \n",
      "\n",
      "loss: 0.629981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.659628 \n",
      "\n",
      "loss: 0.667331  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.664327 \n",
      "\n",
      "loss: 0.668809  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.649128 \n",
      "\n",
      "loss: 0.658443  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.692143 \n",
      "\n",
      "loss: 0.679518  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.620246 \n",
      "\n",
      "loss: 0.621110  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.628582 \n",
      "\n",
      "loss: 0.654644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.621372 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 239/500\n",
      "--------------------\n",
      "{'hl': [492, 267, 45], 'alpha': 0.10307745216830902, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.17855139060007816}\n",
      "loss: 1.053839  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.831600 \n",
      "\n",
      "loss: 0.835011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 1.454516 \n",
      "\n",
      "loss: 1.451367  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 1.305492 \n",
      "\n",
      "loss: 1.241375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.037895 \n",
      "\n",
      "loss: 1.090220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.016507 \n",
      "\n",
      "loss: 1.063039  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.825712 \n",
      "\n",
      "loss: 0.808009  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.760642 \n",
      "\n",
      "loss: 0.741674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.715113 \n",
      "\n",
      "loss: 0.729056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.816575 \n",
      "\n",
      "loss: 0.799408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.820087 \n",
      "\n",
      "loss: 0.805699  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 0.998712 \n",
      "\n",
      "loss: 0.983396  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.830918 \n",
      "\n",
      "loss: 0.800337  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 1.039549 \n",
      "\n",
      "loss: 1.038716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.561315 \n",
      "\n",
      "loss: 1.563721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 2.027425 \n",
      "\n",
      "loss: 1.918175  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 3.197622 \n",
      "\n",
      "loss: 3.019548  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.571115 \n",
      "\n",
      "loss: 1.550706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 2.985833 \n",
      "\n",
      "loss: 2.962869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.777653 \n",
      "\n",
      "loss: 0.805941  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.934356 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 240/500\n",
      "--------------------\n",
      "{'hl': [679], 'alpha': 0.00212666334428638, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.21853199642415572}\n",
      "loss: 1.070138  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 39.455419 \n",
      "\n",
      "loss: 36.503693  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 4.808673 \n",
      "\n",
      "loss: 4.544870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.965341 \n",
      "\n",
      "loss: 2.638695  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 11.725570 \n",
      "\n",
      "loss: 12.946960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 1.663432 \n",
      "\n",
      "loss: 1.561612  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.646630 \n",
      "\n",
      "loss: 0.671192  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.404590 \n",
      "\n",
      "loss: 0.411833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.413590 \n",
      "\n",
      "loss: 0.369505  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.401014 \n",
      "\n",
      "loss: 0.399103  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.356513 \n",
      "\n",
      "loss: 0.402206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.396226 \n",
      "\n",
      "loss: 0.365752  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.396240 \n",
      "\n",
      "loss: 0.385617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.477577 \n",
      "\n",
      "loss: 0.466219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.385636 \n",
      "\n",
      "loss: 0.385899  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.421983 \n",
      "\n",
      "loss: 0.424233  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.401175 \n",
      "\n",
      "loss: 0.352434  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.416068 \n",
      "\n",
      "loss: 0.362437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.421534 \n",
      "\n",
      "loss: 0.332237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.438858 \n",
      "\n",
      "loss: 0.423012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.395822 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 241/500\n",
      "--------------------\n",
      "{'hl': [458, 403], 'alpha': 0.0022706307429151405, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.34606503870719624}\n",
      "loss: 1.109072  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 4.060610 \n",
      "\n",
      "loss: 3.554851  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.9%, Avg loss: 3.560345 \n",
      "\n",
      "loss: 3.377274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 6.032877 \n",
      "\n",
      "loss: 5.475957  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 4.864393 \n",
      "\n",
      "loss: 4.896873  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 6.279586 \n",
      "\n",
      "loss: 6.340877  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 3.176017 \n",
      "\n",
      "loss: 3.340732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 3.595396 \n",
      "\n",
      "loss: 3.726739  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 3.877302 \n",
      "\n",
      "loss: 3.792663  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 5.430639 \n",
      "\n",
      "loss: 5.670412  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 5.414369 \n",
      "\n",
      "loss: 4.974974  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 4.498440 \n",
      "\n",
      "loss: 4.869700  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 3.079163 \n",
      "\n",
      "loss: 2.519478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 5.156229 \n",
      "\n",
      "loss: 5.548827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 5.439946 \n",
      "\n",
      "loss: 5.096651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 6.800234 \n",
      "\n",
      "loss: 6.787308  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 5.034776 \n",
      "\n",
      "loss: 4.965998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 9.717299 \n",
      "\n",
      "loss: 9.173965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 8.219074 \n",
      "\n",
      "loss: 8.850925  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 8.932012 \n",
      "\n",
      "loss: 9.105685  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 3.584762 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 242/500\n",
      "--------------------\n",
      "{'hl': [539, 281], 'alpha': 0.16017412109158166, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.2153605152865231}\n",
      "loss: 1.147284  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.960816 \n",
      "\n",
      "loss: 0.966545  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.013091 \n",
      "\n",
      "loss: 1.043344  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.074751 \n",
      "\n",
      "loss: 1.057966  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.028765 \n",
      "\n",
      "loss: 1.039605  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.081405 \n",
      "\n",
      "loss: 1.054768  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.131647 \n",
      "\n",
      "loss: 1.067065  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.055236 \n",
      "\n",
      "loss: 1.044057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.115736 \n",
      "\n",
      "loss: 1.128001  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.095238 \n",
      "\n",
      "loss: 1.089827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.944116 \n",
      "\n",
      "loss: 0.948009  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.156018 \n",
      "\n",
      "loss: 1.124528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.033512 \n",
      "\n",
      "loss: 1.011361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.047846 \n",
      "\n",
      "loss: 1.040998  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.175277 \n",
      "\n",
      "loss: 1.179887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.164202 \n",
      "\n",
      "loss: 1.174205  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.212403 \n",
      "\n",
      "loss: 1.190575  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.050025 \n",
      "\n",
      "loss: 1.034837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.167596 \n",
      "\n",
      "loss: 1.170199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.026930 \n",
      "\n",
      "loss: 1.042626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.069093 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 243/500\n",
      "--------------------\n",
      "{'hl': [566], 'alpha': 0.00149646194084488, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.16402716068024573}\n",
      "loss: 1.119810  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.476684 \n",
      "\n",
      "loss: 0.470646  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.458911 \n",
      "\n",
      "loss: 0.465211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.421234 \n",
      "\n",
      "loss: 0.426151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.406141 \n",
      "\n",
      "loss: 0.418740  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.382507 \n",
      "\n",
      "loss: 0.393967  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.392249 \n",
      "\n",
      "loss: 0.417131  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.382372 \n",
      "\n",
      "loss: 0.350743  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.366693 \n",
      "\n",
      "loss: 0.357547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.369612 \n",
      "\n",
      "loss: 0.363372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.363076 \n",
      "\n",
      "loss: 0.372520  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.358489 \n",
      "\n",
      "loss: 0.364694  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.353897 \n",
      "\n",
      "loss: 0.363804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.349597 \n",
      "\n",
      "loss: 0.345192  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.355319 \n",
      "\n",
      "loss: 0.344183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.351603 \n",
      "\n",
      "loss: 0.342481  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.342729 \n",
      "\n",
      "loss: 0.340780  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.353743 \n",
      "\n",
      "loss: 0.373918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.339078 \n",
      "\n",
      "loss: 0.328132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.331496 \n",
      "\n",
      "loss: 0.345726  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.321715 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 244/500\n",
      "--------------------\n",
      "{'hl': [321, 464], 'alpha': 0.02573276837852171, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3449134277418986}\n",
      "loss: 1.093218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.073773 \n",
      "\n",
      "loss: 1.128648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.919589 \n",
      "\n",
      "loss: 0.908512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.916821 \n",
      "\n",
      "loss: 0.995896  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.842878 \n",
      "\n",
      "loss: 0.863184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 0.793961 \n",
      "\n",
      "loss: 0.751929  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.678825 \n",
      "\n",
      "loss: 0.664487  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.768739 \n",
      "\n",
      "loss: 0.747186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.636987 \n",
      "\n",
      "loss: 0.607946  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.648160 \n",
      "\n",
      "loss: 0.662388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.702981 \n",
      "\n",
      "loss: 0.700153  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.671202 \n",
      "\n",
      "loss: 0.699898  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.661065 \n",
      "\n",
      "loss: 0.650100  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.658104 \n",
      "\n",
      "loss: 0.659680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.706605 \n",
      "\n",
      "loss: 0.721856  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.662817 \n",
      "\n",
      "loss: 0.673623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.656575 \n",
      "\n",
      "loss: 0.657331  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.707294 \n",
      "\n",
      "loss: 0.722868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.547515 \n",
      "\n",
      "loss: 0.556286  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.608792 \n",
      "\n",
      "loss: 0.601766  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.672826 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 245/500\n",
      "--------------------\n",
      "{'hl': [465, 51], 'alpha': 0.08077139485366293, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.13735022450142131}\n",
      "loss: 1.118769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 7.383611 \n",
      "\n",
      "loss: 7.386973  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 3.451863 \n",
      "\n",
      "loss: 3.600083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 3.609674 \n",
      "\n",
      "loss: 3.957632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.842220 \n",
      "\n",
      "loss: 1.049495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.492274 \n",
      "\n",
      "loss: 0.522399  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.466047 \n",
      "\n",
      "loss: 0.475024  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.514703 \n",
      "\n",
      "loss: 0.524174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.496236 \n",
      "\n",
      "loss: 0.469675  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.484584 \n",
      "\n",
      "loss: 0.484060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.503268 \n",
      "\n",
      "loss: 0.501214  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.500703 \n",
      "\n",
      "loss: 0.504525  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.509478 \n",
      "\n",
      "loss: 0.491062  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.503263 \n",
      "\n",
      "loss: 0.463600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.488992 \n",
      "\n",
      "loss: 0.491865  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.517348 \n",
      "\n",
      "loss: 0.491796  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.492400 \n",
      "\n",
      "loss: 0.490897  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.519817 \n",
      "\n",
      "loss: 0.486599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.510281 \n",
      "\n",
      "loss: 0.516421  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.501234 \n",
      "\n",
      "loss: 0.547315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.505102 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 246/500\n",
      "--------------------\n",
      "{'hl': [84], 'alpha': 0.04838776419644772, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2565917011303296}\n",
      "loss: 1.017033  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.603275 \n",
      "\n",
      "loss: 0.600791  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.538912 \n",
      "\n",
      "loss: 0.571989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.563810 \n",
      "\n",
      "loss: 0.526418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.708297 \n",
      "\n",
      "loss: 0.732706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.574260 \n",
      "\n",
      "loss: 0.538451  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.595509 \n",
      "\n",
      "loss: 0.638668  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.587277 \n",
      "\n",
      "loss: 0.583609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.636810 \n",
      "\n",
      "loss: 0.671538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.747724 \n",
      "\n",
      "loss: 0.728085  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.766650 \n",
      "\n",
      "loss: 0.775127  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.567736 \n",
      "\n",
      "loss: 0.563353  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 0.724220 \n",
      "\n",
      "loss: 0.686143  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.600935 \n",
      "\n",
      "loss: 0.632432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.547943 \n",
      "\n",
      "loss: 0.547301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.614761 \n",
      "\n",
      "loss: 0.611814  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.569094 \n",
      "\n",
      "loss: 0.566934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.581670 \n",
      "\n",
      "loss: 0.591426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.575624 \n",
      "\n",
      "loss: 0.562991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.569142 \n",
      "\n",
      "loss: 0.592512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.601555 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 247/500\n",
      "--------------------\n",
      "{'hl': [703, 171, 39], 'alpha': 0.0003724927921639548, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.06320238914869691}\n",
      "loss: 1.163327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.814600 \n",
      "\n",
      "loss: 0.828192  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.823582 \n",
      "\n",
      "loss: 0.796729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.812578 \n",
      "\n",
      "loss: 0.794186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.824770 \n",
      "\n",
      "loss: 0.817710  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813857 \n",
      "\n",
      "loss: 0.821602  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.810665 \n",
      "\n",
      "loss: 0.813901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824909 \n",
      "\n",
      "loss: 0.812925  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.818375 \n",
      "\n",
      "loss: 0.782293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.812549 \n",
      "\n",
      "loss: 0.817527  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.805068 \n",
      "\n",
      "loss: 0.809677  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.822704 \n",
      "\n",
      "loss: 0.799542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.814594 \n",
      "\n",
      "loss: 0.844363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.808150 \n",
      "\n",
      "loss: 0.817918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.805450 \n",
      "\n",
      "loss: 0.836236  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.802986 \n",
      "\n",
      "loss: 0.817605  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.803028 \n",
      "\n",
      "loss: 0.810824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.812886 \n",
      "\n",
      "loss: 0.786833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.794621 \n",
      "\n",
      "loss: 0.783128  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.785995 \n",
      "\n",
      "loss: 0.798327  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 0.776661 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 248/500\n",
      "--------------------\n",
      "{'hl': [668], 'alpha': 0.0029195363874957633, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.30258690494450724}\n",
      "loss: 1.185223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 2.634269 \n",
      "\n",
      "loss: 3.098983  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.665801 \n",
      "\n",
      "loss: 1.660865  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 2.432489 \n",
      "\n",
      "loss: 2.534253  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.810806 \n",
      "\n",
      "loss: 0.884983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 4.072695 \n",
      "\n",
      "loss: 4.344302  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 1.275552 \n",
      "\n",
      "loss: 1.238470  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 2.735678 \n",
      "\n",
      "loss: 2.815459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 1.072401 \n",
      "\n",
      "loss: 1.133630  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.810324 \n",
      "\n",
      "loss: 0.780577  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.975877 \n",
      "\n",
      "loss: 0.923390  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 1.873771 \n",
      "\n",
      "loss: 1.959950  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 4.525398 \n",
      "\n",
      "loss: 4.481622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.059350 \n",
      "\n",
      "loss: 0.948496  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.831755 \n",
      "\n",
      "loss: 0.753519  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 1.277543 \n",
      "\n",
      "loss: 1.402844  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 3.271399 \n",
      "\n",
      "loss: 3.443147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.822672 \n",
      "\n",
      "loss: 0.749698  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.249196 \n",
      "\n",
      "loss: 1.232464  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.977568 \n",
      "\n",
      "loss: 0.958389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.651524 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 249/500\n",
      "--------------------\n",
      "{'hl': [468, 387, 388], 'alpha': 0.0059670153726018756, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.26477699477999117}\n",
      "loss: 1.110652  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.481292 \n",
      "\n",
      "loss: 0.455590  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.432892 \n",
      "\n",
      "loss: 0.426450  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.462679 \n",
      "\n",
      "loss: 0.478959  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.381612 \n",
      "\n",
      "loss: 0.336365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.384408 \n",
      "\n",
      "loss: 0.363294  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.367294 \n",
      "\n",
      "loss: 0.374684  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.379010 \n",
      "\n",
      "loss: 0.385732  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.370395 \n",
      "\n",
      "loss: 0.346600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.354866 \n",
      "\n",
      "loss: 0.322558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.332389 \n",
      "\n",
      "loss: 0.390830  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.349126 \n",
      "\n",
      "loss: 0.327179  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.484615 \n",
      "\n",
      "loss: 0.428567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.330910 \n",
      "\n",
      "loss: 0.301697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.348345 \n",
      "\n",
      "loss: 0.348703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.313109 \n",
      "\n",
      "loss: 0.326510  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.328468 \n",
      "\n",
      "loss: 0.344069  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.340729 \n",
      "\n",
      "loss: 0.301267  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.321783 \n",
      "\n",
      "loss: 0.288049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.347871 \n",
      "\n",
      "loss: 0.344488  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.319586 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 250/500\n",
      "--------------------\n",
      "{'hl': [329, 673], 'alpha': 0.0013024440173673756, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3678638622537659}\n",
      "loss: 1.105399  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.449451 \n",
      "\n",
      "loss: 0.490281  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.409651 \n",
      "\n",
      "loss: 0.416391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.388855 \n",
      "\n",
      "loss: 0.376737  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.361858 \n",
      "\n",
      "loss: 0.355853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.372747 \n",
      "\n",
      "loss: 0.399542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.344162 \n",
      "\n",
      "loss: 0.325380  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.336398 \n",
      "\n",
      "loss: 0.358559  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.355231 \n",
      "\n",
      "loss: 0.381235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.367500 \n",
      "\n",
      "loss: 0.334195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.349507 \n",
      "\n",
      "loss: 0.346888  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.311947 \n",
      "\n",
      "loss: 0.300187  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.351669 \n",
      "\n",
      "loss: 0.325468  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.322239 \n",
      "\n",
      "loss: 0.309027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.310345 \n",
      "\n",
      "loss: 0.319649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.292164 \n",
      "\n",
      "loss: 0.269594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.308487 \n",
      "\n",
      "loss: 0.278362  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.309060 \n",
      "\n",
      "loss: 0.290102  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.343803 \n",
      "\n",
      "loss: 0.318423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.299195 \n",
      "\n",
      "loss: 0.288849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.279413 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 251/500\n",
      "--------------------\n",
      "{'hl': [538, 404], 'alpha': 0.45099323068095354, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.38750474531739093}\n",
      "loss: 1.080455  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 2781.698500 \n",
      "\n",
      "loss: 2810.014648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 4288.102620 \n",
      "\n",
      "loss: 3768.441650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 839.578668 \n",
      "\n",
      "loss: 797.754883  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 612.771315 \n",
      "\n",
      "loss: 686.758118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 357.039185 \n",
      "\n",
      "loss: 380.846588  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 50.088577 \n",
      "\n",
      "loss: 41.076515  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 33.558006 \n",
      "\n",
      "loss: 33.935471  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 5.922414 \n",
      "\n",
      "loss: 6.275079  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.586141 \n",
      "\n",
      "loss: 0.564360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.518225 \n",
      "\n",
      "loss: 0.502160  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.527371 \n",
      "\n",
      "loss: 0.531554  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.534231 \n",
      "\n",
      "loss: 0.538930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.553913 \n",
      "\n",
      "loss: 0.549453  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.578942 \n",
      "\n",
      "loss: 0.576090  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.574428 \n",
      "\n",
      "loss: 0.584978  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.617940 \n",
      "\n",
      "loss: 0.614730  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.635458 \n",
      "\n",
      "loss: 0.623196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.641498 \n",
      "\n",
      "loss: 0.634914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.662829 \n",
      "\n",
      "loss: 0.681294  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.678686 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 252/500\n",
      "--------------------\n",
      "{'hl': [464, 227, 634], 'alpha': 0.001387738096464545, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.06140644720979504}\n",
      "loss: 1.247514  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.649098 \n",
      "\n",
      "loss: 2.619514  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.216810 \n",
      "\n",
      "loss: 1.274309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.357072 \n",
      "\n",
      "loss: 1.468764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.050173 \n",
      "\n",
      "loss: 1.068928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962812 \n",
      "\n",
      "loss: 0.970708  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.930313 \n",
      "\n",
      "loss: 0.898026  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.830668 \n",
      "\n",
      "loss: 0.835429  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.874608 \n",
      "\n",
      "loss: 0.865923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.815451 \n",
      "\n",
      "loss: 0.832431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.858771 \n",
      "\n",
      "loss: 0.868274  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.829562 \n",
      "\n",
      "loss: 0.803350  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.894491 \n",
      "\n",
      "loss: 0.926431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.840754 \n",
      "\n",
      "loss: 0.855376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.845656 \n",
      "\n",
      "loss: 0.858916  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.795721 \n",
      "\n",
      "loss: 0.797551  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817195 \n",
      "\n",
      "loss: 0.803677  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.805749 \n",
      "\n",
      "loss: 0.807997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.828529 \n",
      "\n",
      "loss: 0.801620  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.820469 \n",
      "\n",
      "loss: 0.827993  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.799330 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 253/500\n",
      "--------------------\n",
      "{'hl': [470], 'alpha': 0.0004904846900973853, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.40527555785698016}\n",
      "loss: 0.921894  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 1.719574 \n",
      "\n",
      "loss: 1.597031  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 4.636523 \n",
      "\n",
      "loss: 4.674890  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.213288 \n",
      "\n",
      "loss: 1.334242  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.872577 \n",
      "\n",
      "loss: 1.036300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 1.578411 \n",
      "\n",
      "loss: 1.573817  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.822905 \n",
      "\n",
      "loss: 0.880462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.768631 \n",
      "\n",
      "loss: 0.799609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.925136 \n",
      "\n",
      "loss: 0.986151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.776118 \n",
      "\n",
      "loss: 0.805840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.683642 \n",
      "\n",
      "loss: 0.708496  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.742672 \n",
      "\n",
      "loss: 0.688676  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 1.936261 \n",
      "\n",
      "loss: 1.727942  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.568274 \n",
      "\n",
      "loss: 0.532828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.488879 \n",
      "\n",
      "loss: 0.499662  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.675301 \n",
      "\n",
      "loss: 0.659875  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.550150 \n",
      "\n",
      "loss: 0.538919  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.646806 \n",
      "\n",
      "loss: 0.569176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.561473 \n",
      "\n",
      "loss: 0.598476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.578876 \n",
      "\n",
      "loss: 0.540775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.464447 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 254/500\n",
      "--------------------\n",
      "{'hl': [691, 363], 'alpha': 0.06889091408728526, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.42569588917148765}\n",
      "loss: 1.080688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 880.450738 \n",
      "\n",
      "loss: 860.306885  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 390.540236 \n",
      "\n",
      "loss: 311.022614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 2128.545342 \n",
      "\n",
      "loss: 2029.462646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 230.786903 \n",
      "\n",
      "loss: 220.104172  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 55.284486 \n",
      "\n",
      "loss: 39.723343  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 181.942105 \n",
      "\n",
      "loss: 200.488770  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 354.090842 \n",
      "\n",
      "loss: 414.310547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 107.163153 \n",
      "\n",
      "loss: 123.485924  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 37.939984 \n",
      "\n",
      "loss: 49.711819  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 458.129971 \n",
      "\n",
      "loss: 540.832520  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 50.272476 \n",
      "\n",
      "loss: 33.207359  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 876.306508 \n",
      "\n",
      "loss: 801.172119  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 54755.344184 \n",
      "\n",
      "loss: 49939.117188  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 16050.235894 \n",
      "\n",
      "loss: 16279.643555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 4012.470866 \n",
      "\n",
      "loss: 3424.330322  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 572.672312 \n",
      "\n",
      "loss: 478.142700  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 127.579502 \n",
      "\n",
      "loss: 150.872162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 114.952395 \n",
      "\n",
      "loss: 135.700928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 45.217370 \n",
      "\n",
      "loss: 43.457458  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 22.016152 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 255/500\n",
      "--------------------\n",
      "{'hl': [661, 186, 378], 'alpha': 0.01083984271543096, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3960536302382093}\n",
      "loss: 1.082473  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.467835 \n",
      "\n",
      "loss: 0.469905  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.441006 \n",
      "\n",
      "loss: 0.429078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.388373 \n",
      "\n",
      "loss: 0.408183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.391311 \n",
      "\n",
      "loss: 0.370441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.424901 \n",
      "\n",
      "loss: 0.468520  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.357109 \n",
      "\n",
      "loss: 0.379263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.424412 \n",
      "\n",
      "loss: 0.401686  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.383119 \n",
      "\n",
      "loss: 0.407416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.366638 \n",
      "\n",
      "loss: 0.383654  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352213 \n",
      "\n",
      "loss: 0.357497  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.353067 \n",
      "\n",
      "loss: 0.368220  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.368353 \n",
      "\n",
      "loss: 0.330122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.362768 \n",
      "\n",
      "loss: 0.327884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.386677 \n",
      "\n",
      "loss: 0.377064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.388069 \n",
      "\n",
      "loss: 0.382969  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.356895 \n",
      "\n",
      "loss: 0.335098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.371433 \n",
      "\n",
      "loss: 0.368264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.350924 \n",
      "\n",
      "loss: 0.345088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.343806 \n",
      "\n",
      "loss: 0.352900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.359628 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 256/500\n",
      "--------------------\n",
      "{'hl': [513], 'alpha': 0.00012739022575014258, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.40185049697166436}\n",
      "loss: 1.013106  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 78.333628 \n",
      "\n",
      "loss: 79.887238  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 13.965554 \n",
      "\n",
      "loss: 7.836090  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 8.869746 \n",
      "\n",
      "loss: 8.492325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 1.176358 \n",
      "\n",
      "loss: 1.192531  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 1.078091 \n",
      "\n",
      "loss: 0.856313  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 1.076751 \n",
      "\n",
      "loss: 0.658191  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.600650 \n",
      "\n",
      "loss: 0.463632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.712835 \n",
      "\n",
      "loss: 0.718895  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.501523 \n",
      "\n",
      "loss: 0.504588  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.402671 \n",
      "\n",
      "loss: 0.408098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.376333 \n",
      "\n",
      "loss: 0.339911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.346813 \n",
      "\n",
      "loss: 0.400753  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.343837 \n",
      "\n",
      "loss: 0.315130  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.323641 \n",
      "\n",
      "loss: 0.333728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.332629 \n",
      "\n",
      "loss: 0.336534  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.354939 \n",
      "\n",
      "loss: 0.316674  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.399496 \n",
      "\n",
      "loss: 0.333041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.353685 \n",
      "\n",
      "loss: 0.340410  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.336910 \n",
      "\n",
      "loss: 0.288065  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.355210 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 257/500\n",
      "--------------------\n",
      "{'hl': [140, 634, 96], 'alpha': 0.00018322824466885024, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.262895257849667}\n",
      "loss: 0.983131  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.058047 \n",
      "\n",
      "loss: 2.340244  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.923285 \n",
      "\n",
      "loss: 0.912974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.381258 \n",
      "\n",
      "loss: 2.085334  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.590686 \n",
      "\n",
      "loss: 1.678908  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.307546 \n",
      "\n",
      "loss: 1.320064  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.146692 \n",
      "\n",
      "loss: 1.184315  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.964763 \n",
      "\n",
      "loss: 0.984576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.941032 \n",
      "\n",
      "loss: 0.923565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.100013 \n",
      "\n",
      "loss: 1.063858  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.970553 \n",
      "\n",
      "loss: 0.976850  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.920291 \n",
      "\n",
      "loss: 0.951277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.930255 \n",
      "\n",
      "loss: 0.908027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.938487 \n",
      "\n",
      "loss: 0.933878  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.954732 \n",
      "\n",
      "loss: 3.005280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.192091 \n",
      "\n",
      "loss: 1.212029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.601584 \n",
      "\n",
      "loss: 3.635048  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.374149 \n",
      "\n",
      "loss: 1.391938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815966 \n",
      "\n",
      "loss: 0.820461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.950848 \n",
      "\n",
      "loss: 0.942334  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.867725 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 258/500\n",
      "--------------------\n",
      "{'hl': [596, 83], 'alpha': 0.0003171809744575488, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.22504225038193174}\n",
      "loss: 1.159600  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.478372 \n",
      "\n",
      "loss: 0.467473  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.426928 \n",
      "\n",
      "loss: 0.413619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.409318 \n",
      "\n",
      "loss: 0.426729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.390298 \n",
      "\n",
      "loss: 0.372437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.382506 \n",
      "\n",
      "loss: 0.366703  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.356656 \n",
      "\n",
      "loss: 0.365195  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.435488 \n",
      "\n",
      "loss: 0.413287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.350978 \n",
      "\n",
      "loss: 0.305257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.356173 \n",
      "\n",
      "loss: 0.375507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.338359 \n",
      "\n",
      "loss: 0.364594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.344220 \n",
      "\n",
      "loss: 0.304222  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.392650 \n",
      "\n",
      "loss: 0.364938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.328788 \n",
      "\n",
      "loss: 0.329676  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.310383 \n",
      "\n",
      "loss: 0.336235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.298108 \n",
      "\n",
      "loss: 0.317911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.322445 \n",
      "\n",
      "loss: 0.313646  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.319462 \n",
      "\n",
      "loss: 0.284323  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.303107 \n",
      "\n",
      "loss: 0.307479  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.319776 \n",
      "\n",
      "loss: 0.310907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.278696 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 259/500\n",
      "--------------------\n",
      "{'hl': [537, 360, 139], 'alpha': 0.32496800675753185, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.21636588141233923}\n",
      "loss: 1.078643  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.710670 \n",
      "\n",
      "loss: 0.729734  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.715582 \n",
      "\n",
      "loss: 0.706821  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.709024 \n",
      "\n",
      "loss: 0.708792  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.693472 \n",
      "\n",
      "loss: 0.708991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.707126 \n",
      "\n",
      "loss: 0.721387  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.706992 \n",
      "\n",
      "loss: 0.710421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.701816 \n",
      "\n",
      "loss: 0.705526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.707356 \n",
      "\n",
      "loss: 0.708357  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.701633 \n",
      "\n",
      "loss: 0.711675  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.698720 \n",
      "\n",
      "loss: 0.720038  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.695763 \n",
      "\n",
      "loss: 0.695234  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.706262 \n",
      "\n",
      "loss: 0.689956  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.706107 \n",
      "\n",
      "loss: 0.697885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.714918 \n",
      "\n",
      "loss: 0.701408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.705392 \n",
      "\n",
      "loss: 0.685166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.694004 \n",
      "\n",
      "loss: 0.702283  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.701913 \n",
      "\n",
      "loss: 0.702304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.707030 \n",
      "\n",
      "loss: 0.709704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.701964 \n",
      "\n",
      "loss: 0.713354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.705511 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 260/500\n",
      "--------------------\n",
      "{'hl': [135], 'alpha': 0.01181431460862193, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.08106728308199425}\n",
      "loss: 1.195320  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.538281 \n",
      "\n",
      "loss: 0.493078  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.489453 \n",
      "\n",
      "loss: 0.505655  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.462519 \n",
      "\n",
      "loss: 0.502549  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.452967 \n",
      "\n",
      "loss: 0.494258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.439032 \n",
      "\n",
      "loss: 0.488280  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.445183 \n",
      "\n",
      "loss: 0.448572  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.446075 \n",
      "\n",
      "loss: 0.449183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.428910 \n",
      "\n",
      "loss: 0.420875  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.419049 \n",
      "\n",
      "loss: 0.388776  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.400501 \n",
      "\n",
      "loss: 0.403237  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.420822 \n",
      "\n",
      "loss: 0.396077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.417631 \n",
      "\n",
      "loss: 0.417851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.400266 \n",
      "\n",
      "loss: 0.443529  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.397005 \n",
      "\n",
      "loss: 0.405760  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.382436 \n",
      "\n",
      "loss: 0.397428  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.392881 \n",
      "\n",
      "loss: 0.383390  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.398912 \n",
      "\n",
      "loss: 0.363748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.391126 \n",
      "\n",
      "loss: 0.385037  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.380852 \n",
      "\n",
      "loss: 0.414347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.374821 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 261/500\n",
      "--------------------\n",
      "{'hl': [238, 362, 539], 'alpha': 0.3799300696814796, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.0982313295495885}\n",
      "loss: 1.094330  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 25.032305 \n",
      "\n",
      "loss: 26.029325  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.478542 \n",
      "\n",
      "loss: 1.459757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.777121 \n",
      "\n",
      "loss: 0.772867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.942065 \n",
      "\n",
      "loss: 0.939686  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.938821 \n",
      "\n",
      "loss: 0.940261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.941985 \n",
      "\n",
      "loss: 0.939157  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.943123 \n",
      "\n",
      "loss: 0.944871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.940641 \n",
      "\n",
      "loss: 0.938191  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.941338 \n",
      "\n",
      "loss: 0.950311  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.941251 \n",
      "\n",
      "loss: 0.934695  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.941226 \n",
      "\n",
      "loss: 0.937269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.940990 \n",
      "\n",
      "loss: 0.942375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.939566 \n",
      "\n",
      "loss: 0.939821  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.943762 \n",
      "\n",
      "loss: 0.935906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.938805 \n",
      "\n",
      "loss: 0.947445  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.940815 \n",
      "\n",
      "loss: 0.944554  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.944639 \n",
      "\n",
      "loss: 0.941298  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.940650 \n",
      "\n",
      "loss: 0.950055  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.943200 \n",
      "\n",
      "loss: 0.945442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.940788 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 262/500\n",
      "--------------------\n",
      "{'hl': [289, 136, 648], 'alpha': 0.0016266661316257911, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2959450418137709}\n",
      "loss: 1.104192  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.473005 \n",
      "\n",
      "loss: 0.457637  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.433963 \n",
      "\n",
      "loss: 0.418645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.416414 \n",
      "\n",
      "loss: 0.424450  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.378246 \n",
      "\n",
      "loss: 0.350435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.355426 \n",
      "\n",
      "loss: 0.345216  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.346210 \n",
      "\n",
      "loss: 0.326564  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.350700 \n",
      "\n",
      "loss: 0.348836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.340959 \n",
      "\n",
      "loss: 0.307760  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.330836 \n",
      "\n",
      "loss: 0.302897  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.327444 \n",
      "\n",
      "loss: 0.339807  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.306625 \n",
      "\n",
      "loss: 0.307435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.346705 \n",
      "\n",
      "loss: 0.353645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.348537 \n",
      "\n",
      "loss: 0.350221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.312119 \n",
      "\n",
      "loss: 0.321161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.312878 \n",
      "\n",
      "loss: 0.317516  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.316181 \n",
      "\n",
      "loss: 0.276271  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.289775 \n",
      "\n",
      "loss: 0.259474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.343864 \n",
      "\n",
      "loss: 0.386668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.297699 \n",
      "\n",
      "loss: 0.304388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.286837 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 263/500\n",
      "--------------------\n",
      "{'hl': [165, 183, 682], 'alpha': 0.03147144977474873, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.41263561003658333}\n",
      "loss: 1.091987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.468391 \n",
      "\n",
      "loss: 0.468058  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.428323 \n",
      "\n",
      "loss: 0.413378  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.434358 \n",
      "\n",
      "loss: 0.458478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.405719 \n",
      "\n",
      "loss: 0.439565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.395875 \n",
      "\n",
      "loss: 0.410730  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.450034 \n",
      "\n",
      "loss: 0.406077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.410402 \n",
      "\n",
      "loss: 0.402313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.419495 \n",
      "\n",
      "loss: 0.409447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.446952 \n",
      "\n",
      "loss: 0.428206  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.406280 \n",
      "\n",
      "loss: 0.406765  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.441627 \n",
      "\n",
      "loss: 0.441099  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.422342 \n",
      "\n",
      "loss: 0.407400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.410264 \n",
      "\n",
      "loss: 0.391503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.419335 \n",
      "\n",
      "loss: 0.426588  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.389015 \n",
      "\n",
      "loss: 0.397870  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.401995 \n",
      "\n",
      "loss: 0.365233  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.418392 \n",
      "\n",
      "loss: 0.384977  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.406452 \n",
      "\n",
      "loss: 0.400290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.460521 \n",
      "\n",
      "loss: 0.454213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.393967 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 264/500\n",
      "--------------------\n",
      "{'hl': [91], 'alpha': 0.00015200126880688864, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.3835028045580639}\n",
      "loss: 1.218064  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.463558 \n",
      "\n",
      "loss: 0.456582  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.419420 \n",
      "\n",
      "loss: 0.428179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.391951 \n",
      "\n",
      "loss: 0.402057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.385157 \n",
      "\n",
      "loss: 0.377211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.380000 \n",
      "\n",
      "loss: 0.406315  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.358869 \n",
      "\n",
      "loss: 0.358228  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.372685 \n",
      "\n",
      "loss: 0.344089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.352424 \n",
      "\n",
      "loss: 0.379118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.347740 \n",
      "\n",
      "loss: 0.349459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.332819 \n",
      "\n",
      "loss: 0.365516  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.333728 \n",
      "\n",
      "loss: 0.342780  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.334621 \n",
      "\n",
      "loss: 0.324692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.343655 \n",
      "\n",
      "loss: 0.356173  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.340711 \n",
      "\n",
      "loss: 0.327958  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.322577 \n",
      "\n",
      "loss: 0.339750  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.323023 \n",
      "\n",
      "loss: 0.311119  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.323655 \n",
      "\n",
      "loss: 0.302559  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.396048 \n",
      "\n",
      "loss: 0.381842  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.314994 \n",
      "\n",
      "loss: 0.323188  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.312101 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 265/500\n",
      "--------------------\n",
      "{'hl': [640, 662], 'alpha': 0.00013217325771667796, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.24152411460589218}\n",
      "loss: 1.078657  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 890.504374 \n",
      "\n",
      "loss: 712.826721  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 95.390340 \n",
      "\n",
      "loss: 57.958084  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 23.547632 \n",
      "\n",
      "loss: 22.173916  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 24.751414 \n",
      "\n",
      "loss: 35.430569  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 12.491369 \n",
      "\n",
      "loss: 10.957622  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 11.382164 \n",
      "\n",
      "loss: 8.041381  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 9.125878 \n",
      "\n",
      "loss: 10.604136  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 6.169028 \n",
      "\n",
      "loss: 5.531969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 5.194526 \n",
      "\n",
      "loss: 4.152442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 4.600952 \n",
      "\n",
      "loss: 3.344837  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 4.097221 \n",
      "\n",
      "loss: 3.068123  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 2.883771 \n",
      "\n",
      "loss: 2.198086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 4.072640 \n",
      "\n",
      "loss: 5.603441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 2.178748 \n",
      "\n",
      "loss: 2.688797  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 1.381342 \n",
      "\n",
      "loss: 0.968620  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 1.940352 \n",
      "\n",
      "loss: 1.308922  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 2.355263 \n",
      "\n",
      "loss: 1.622505  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 1.666057 \n",
      "\n",
      "loss: 1.433035  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 1.163701 \n",
      "\n",
      "loss: 0.971779  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 1.164862 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 266/500\n",
      "--------------------\n",
      "{'hl': [423, 312, 472], 'alpha': 0.00019583580702064814, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.21985878941021345}\n",
      "loss: 1.069716  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.476684 \n",
      "\n",
      "loss: 0.519735  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.490491 \n",
      "\n",
      "loss: 0.467870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.414138 \n",
      "\n",
      "loss: 0.423293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.388122 \n",
      "\n",
      "loss: 0.390148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.358568 \n",
      "\n",
      "loss: 0.373653  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.430342 \n",
      "\n",
      "loss: 0.447471  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.360520 \n",
      "\n",
      "loss: 0.344625  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.356055 \n",
      "\n",
      "loss: 0.363572  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.355663 \n",
      "\n",
      "loss: 0.336331  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.342700 \n",
      "\n",
      "loss: 0.376813  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.310626 \n",
      "\n",
      "loss: 0.333786  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.353582 \n",
      "\n",
      "loss: 0.325764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.320204 \n",
      "\n",
      "loss: 0.296087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.304104 \n",
      "\n",
      "loss: 0.313140  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.329218 \n",
      "\n",
      "loss: 0.324536  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.302213 \n",
      "\n",
      "loss: 0.257433  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.304135 \n",
      "\n",
      "loss: 0.315610  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.307297 \n",
      "\n",
      "loss: 0.295274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.294393 \n",
      "\n",
      "loss: 0.295728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.282809 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 267/500\n",
      "--------------------\n",
      "{'hl': [483, 216], 'alpha': 0.0022949343869569936, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.43075638990856413}\n",
      "loss: 1.108034  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 5.334148 \n",
      "\n",
      "loss: 5.224823  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 1.758112 \n",
      "\n",
      "loss: 1.655089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 3.522573 \n",
      "\n",
      "loss: 3.315623  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 2.253254 \n",
      "\n",
      "loss: 2.191525  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 3.080793 \n",
      "\n",
      "loss: 3.031614  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 5.566944 \n",
      "\n",
      "loss: 5.371893  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 2.282673 \n",
      "\n",
      "loss: 1.928920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 3.155638 \n",
      "\n",
      "loss: 3.283528  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 2.289225 \n",
      "\n",
      "loss: 2.278455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 1.510000 \n",
      "\n",
      "loss: 1.686682  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 8.220894 \n",
      "\n",
      "loss: 8.496296  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 3.481149 \n",
      "\n",
      "loss: 3.407405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 2.042610 \n",
      "\n",
      "loss: 2.102922  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 2.078382 \n",
      "\n",
      "loss: 1.895299  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 3.042617 \n",
      "\n",
      "loss: 3.009232  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 4.366204 \n",
      "\n",
      "loss: 3.916649  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 7.258941 \n",
      "\n",
      "loss: 7.402309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 3.024923 \n",
      "\n",
      "loss: 3.294133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 2.528754 \n",
      "\n",
      "loss: 2.548348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.656591 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 268/500\n",
      "--------------------\n",
      "{'hl': [361, 416], 'alpha': 0.0003334760173977232, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.1596260316129383}\n",
      "loss: 1.086103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.488291 \n",
      "\n",
      "loss: 0.487244  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.454042 \n",
      "\n",
      "loss: 0.456276  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.425497 \n",
      "\n",
      "loss: 0.432149  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.399472 \n",
      "\n",
      "loss: 0.378285  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.385366 \n",
      "\n",
      "loss: 0.411812  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.387531 \n",
      "\n",
      "loss: 0.391272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.373540 \n",
      "\n",
      "loss: 0.336754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.367795 \n",
      "\n",
      "loss: 0.339170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.366475 \n",
      "\n",
      "loss: 0.381368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.335933 \n",
      "\n",
      "loss: 0.347870  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.333199 \n",
      "\n",
      "loss: 0.345217  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.363168 \n",
      "\n",
      "loss: 0.337071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.323492 \n",
      "\n",
      "loss: 0.322114  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.379079 \n",
      "\n",
      "loss: 0.360056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.322575 \n",
      "\n",
      "loss: 0.316165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.326981 \n",
      "\n",
      "loss: 0.364137  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.332442 \n",
      "\n",
      "loss: 0.320153  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.319357 \n",
      "\n",
      "loss: 0.277893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.333071 \n",
      "\n",
      "loss: 0.307555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.307831 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 269/500\n",
      "--------------------\n",
      "{'hl': [133, 281], 'alpha': 0.006286139984453288, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.02539758537096511}\n",
      "loss: 1.091922  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.649425 \n",
      "\n",
      "loss: 0.638326  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.566330 \n",
      "\n",
      "loss: 0.612805  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.539244 \n",
      "\n",
      "loss: 0.501025  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.521572 \n",
      "\n",
      "loss: 0.517061  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.515912 \n",
      "\n",
      "loss: 0.520971  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.499727 \n",
      "\n",
      "loss: 0.488119  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.511508 \n",
      "\n",
      "loss: 0.527057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.500246 \n",
      "\n",
      "loss: 0.511828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.486023 \n",
      "\n",
      "loss: 0.519687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.483147 \n",
      "\n",
      "loss: 0.496901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.486418 \n",
      "\n",
      "loss: 0.518028  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.480145 \n",
      "\n",
      "loss: 0.456606  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.474329 \n",
      "\n",
      "loss: 0.453653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.472842 \n",
      "\n",
      "loss: 0.470340  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.467609 \n",
      "\n",
      "loss: 0.502529  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.457624 \n",
      "\n",
      "loss: 0.470961  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.475045 \n",
      "\n",
      "loss: 0.472062  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.471562 \n",
      "\n",
      "loss: 0.459673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.454074 \n",
      "\n",
      "loss: 0.436955  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.462971 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 270/500\n",
      "--------------------\n",
      "{'hl': [638, 436], 'alpha': 0.0009841949255890005, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.46688239247117747}\n",
      "loss: 1.085637  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 9.533909 \n",
      "\n",
      "loss: 9.414629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 17.300016 \n",
      "\n",
      "loss: 17.906057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 3.815975 \n",
      "\n",
      "loss: 3.976434  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 13.219017 \n",
      "\n",
      "loss: 13.349194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 3.228918 \n",
      "\n",
      "loss: 3.222566  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 4.940005 \n",
      "\n",
      "loss: 4.325809  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 11.638577 \n",
      "\n",
      "loss: 12.128709  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 8.451094 \n",
      "\n",
      "loss: 7.692078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 4.261801 \n",
      "\n",
      "loss: 3.908581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 4.945793 \n",
      "\n",
      "loss: 5.073138  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 11.780753 \n",
      "\n",
      "loss: 10.896646  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 11.357501 \n",
      "\n",
      "loss: 9.911057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 9.883441 \n",
      "\n",
      "loss: 8.938536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 11.631088 \n",
      "\n",
      "loss: 10.719670  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 9.386822 \n",
      "\n",
      "loss: 8.402241  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 7.013175 \n",
      "\n",
      "loss: 6.919868  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 3.842797 \n",
      "\n",
      "loss: 3.429550  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 5.084525 \n",
      "\n",
      "loss: 5.100662  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 41.3%, Avg loss: 8.216927 \n",
      "\n",
      "loss: 8.212584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 6.991438 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 271/500\n",
      "--------------------\n",
      "{'hl': [328, 202, 171], 'alpha': 0.00984151974732441, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.43954992423384925}\n",
      "loss: 1.223757  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 14.313216 \n",
      "\n",
      "loss: 13.787415  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 9.380387 \n",
      "\n",
      "loss: 10.233988  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.024828 \n",
      "\n",
      "loss: 2.057350  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.857726 \n",
      "\n",
      "loss: 4.285145  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.662974 \n",
      "\n",
      "loss: 3.809916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.364644 \n",
      "\n",
      "loss: 2.275169  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.948062 \n",
      "\n",
      "loss: 5.395179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 5.313867 \n",
      "\n",
      "loss: 5.527711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.878737 \n",
      "\n",
      "loss: 2.805432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 5.859971 \n",
      "\n",
      "loss: 5.592430  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.978295 \n",
      "\n",
      "loss: 3.863911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.894961 \n",
      "\n",
      "loss: 6.120692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 5.190108 \n",
      "\n",
      "loss: 5.171212  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 11.869856 \n",
      "\n",
      "loss: 11.584125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 6.991888 \n",
      "\n",
      "loss: 6.852206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.541903 \n",
      "\n",
      "loss: 3.914384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.025566 \n",
      "\n",
      "loss: 0.988555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.011509 \n",
      "\n",
      "loss: 2.007816  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.587969 \n",
      "\n",
      "loss: 3.836575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.347612 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 272/500\n",
      "--------------------\n",
      "{'hl': [31, 100], 'alpha': 0.603852983340202, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.10765069682086793}\n",
      "loss: 1.094248  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.827589 \n",
      "\n",
      "loss: 0.821929  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.832742 \n",
      "\n",
      "loss: 0.828126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.824366 \n",
      "\n",
      "loss: 0.808844  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.826325 \n",
      "\n",
      "loss: 0.841913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.821241 \n",
      "\n",
      "loss: 0.821293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.834996 \n",
      "\n",
      "loss: 0.841015  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.837916 \n",
      "\n",
      "loss: 0.837055  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.826154 \n",
      "\n",
      "loss: 0.849280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.821029 \n",
      "\n",
      "loss: 0.833230  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.822378 \n",
      "\n",
      "loss: 0.819203  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.830677 \n",
      "\n",
      "loss: 0.824277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.832737 \n",
      "\n",
      "loss: 0.836268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.834001 \n",
      "\n",
      "loss: 0.829055  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.832064 \n",
      "\n",
      "loss: 0.827151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.823421 \n",
      "\n",
      "loss: 0.832073  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.826152 \n",
      "\n",
      "loss: 0.831609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.835389 \n",
      "\n",
      "loss: 0.818627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.820057 \n",
      "\n",
      "loss: 0.801282  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.825567 \n",
      "\n",
      "loss: 0.850642  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.825414 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 273/500\n",
      "--------------------\n",
      "{'hl': [57, 59], 'alpha': 0.0013348281396745444, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2683917055695346}\n",
      "loss: 1.019504  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.609925 \n",
      "\n",
      "loss: 0.528327  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.660855 \n",
      "\n",
      "loss: 0.702408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.483915 \n",
      "\n",
      "loss: 0.464102  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.485062 \n",
      "\n",
      "loss: 0.522403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.491013 \n",
      "\n",
      "loss: 0.485773  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.532882 \n",
      "\n",
      "loss: 0.569312  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.146134 \n",
      "\n",
      "loss: 1.116040  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.565595 \n",
      "\n",
      "loss: 0.562201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.527664 \n",
      "\n",
      "loss: 0.512918  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.489132 \n",
      "\n",
      "loss: 0.473873  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.578661 \n",
      "\n",
      "loss: 0.598537  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.521406 \n",
      "\n",
      "loss: 0.502997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.488421 \n",
      "\n",
      "loss: 0.431412  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.521323 \n",
      "\n",
      "loss: 0.508228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.595613 \n",
      "\n",
      "loss: 0.620831  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.487375 \n",
      "\n",
      "loss: 0.462744  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.524980 \n",
      "\n",
      "loss: 0.540748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.491084 \n",
      "\n",
      "loss: 0.534989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.520356 \n",
      "\n",
      "loss: 0.523356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.515591 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 274/500\n",
      "--------------------\n",
      "{'hl': [449], 'alpha': 0.00034335215376995364, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.38195199640457855}\n",
      "loss: 1.089190  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 64.942052 \n",
      "\n",
      "loss: 41.516026  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 17.990639 \n",
      "\n",
      "loss: 18.607567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 15.900990 \n",
      "\n",
      "loss: 16.857973  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 1.595418 \n",
      "\n",
      "loss: 2.725383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.618812 \n",
      "\n",
      "loss: 0.897662  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 1.187322 \n",
      "\n",
      "loss: 1.395194  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.503320 \n",
      "\n",
      "loss: 0.599802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.712846 \n",
      "\n",
      "loss: 0.616290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.817253 \n",
      "\n",
      "loss: 0.662639  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.754020 \n",
      "\n",
      "loss: 0.642985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 5.806117 \n",
      "\n",
      "loss: 5.311502  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 35.504700 \n",
      "\n",
      "loss: 32.815193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 18.165801 \n",
      "\n",
      "loss: 15.733063  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 9.333055 \n",
      "\n",
      "loss: 9.624399  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 5.317630 \n",
      "\n",
      "loss: 2.655574  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 2.169884 \n",
      "\n",
      "loss: 2.671008  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.579787 \n",
      "\n",
      "loss: 0.527224  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.404918 \n",
      "\n",
      "loss: 0.403431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.391475 \n",
      "\n",
      "loss: 0.432492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.354948 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 275/500\n",
      "--------------------\n",
      "{'hl': [54, 418], 'alpha': 0.00016018828416850247, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.27665614101791375}\n",
      "loss: 1.050073  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 3.155468 \n",
      "\n",
      "loss: 3.073695  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 2.346050 \n",
      "\n",
      "loss: 2.244949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 1.931067 \n",
      "\n",
      "loss: 2.004476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 1.815210 \n",
      "\n",
      "loss: 1.904748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 1.836025 \n",
      "\n",
      "loss: 1.951864  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 2.930703 \n",
      "\n",
      "loss: 2.555225  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 2.204212 \n",
      "\n",
      "loss: 2.521849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 1.268529 \n",
      "\n",
      "loss: 1.288414  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 1.117909 \n",
      "\n",
      "loss: 1.253942  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 2.784304 \n",
      "\n",
      "loss: 2.705660  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 1.551759 \n",
      "\n",
      "loss: 1.655402  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.950477 \n",
      "\n",
      "loss: 0.879977  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.352513 \n",
      "\n",
      "loss: 1.396452  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.009567 \n",
      "\n",
      "loss: 1.042547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 1.495851 \n",
      "\n",
      "loss: 1.748644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 1.043621 \n",
      "\n",
      "loss: 1.124126  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 2.872045 \n",
      "\n",
      "loss: 2.820049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 1.473899 \n",
      "\n",
      "loss: 1.611750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 1.813880 \n",
      "\n",
      "loss: 1.922232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 6.384692 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 276/500\n",
      "--------------------\n",
      "{'hl': [403], 'alpha': 0.010399731252229063, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.06441882900553866}\n",
      "loss: 1.085880  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.524354 \n",
      "\n",
      "loss: 0.556946  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.494086 \n",
      "\n",
      "loss: 0.491303  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.476012 \n",
      "\n",
      "loss: 0.459328  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.453711 \n",
      "\n",
      "loss: 0.472710  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.441662 \n",
      "\n",
      "loss: 0.472349  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.444808 \n",
      "\n",
      "loss: 0.431439  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.440875 \n",
      "\n",
      "loss: 0.425775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.423170 \n",
      "\n",
      "loss: 0.415105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.427035 \n",
      "\n",
      "loss: 0.444193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.412102 \n",
      "\n",
      "loss: 0.379085  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.405420 \n",
      "\n",
      "loss: 0.383589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.404363 \n",
      "\n",
      "loss: 0.389990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.411729 \n",
      "\n",
      "loss: 0.429431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.397161 \n",
      "\n",
      "loss: 0.429102  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.385240 \n",
      "\n",
      "loss: 0.402909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.394824 \n",
      "\n",
      "loss: 0.388458  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.397857 \n",
      "\n",
      "loss: 0.413205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.394100 \n",
      "\n",
      "loss: 0.365598  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.397670 \n",
      "\n",
      "loss: 0.409811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.377900 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 277/500\n",
      "--------------------\n",
      "{'hl': [411], 'alpha': 0.0031102360101279785, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.3775070896291677}\n",
      "loss: 1.137823  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 38.283721 \n",
      "\n",
      "loss: 30.163223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 4.310288 \n",
      "\n",
      "loss: 4.075745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 1.571207 \n",
      "\n",
      "loss: 1.226086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 10.935380 \n",
      "\n",
      "loss: 8.313974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 2.072959 \n",
      "\n",
      "loss: 2.042702  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 19.890837 \n",
      "\n",
      "loss: 18.191767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 32.572538 \n",
      "\n",
      "loss: 27.659031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 14.777646 \n",
      "\n",
      "loss: 11.636610  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 1.327788 \n",
      "\n",
      "loss: 1.537020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.845645 \n",
      "\n",
      "loss: 0.739098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.502336 \n",
      "\n",
      "loss: 0.447840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.413571 \n",
      "\n",
      "loss: 0.347957  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.415999 \n",
      "\n",
      "loss: 0.410833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.429573 \n",
      "\n",
      "loss: 0.401637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.413780 \n",
      "\n",
      "loss: 0.365450  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.407392 \n",
      "\n",
      "loss: 0.388487  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.431844 \n",
      "\n",
      "loss: 0.392373  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.402167 \n",
      "\n",
      "loss: 0.378127  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.401193 \n",
      "\n",
      "loss: 0.451890  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.398503 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 278/500\n",
      "--------------------\n",
      "{'hl': [624], 'alpha': 0.01087652255765847, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.019553091726485495}\n",
      "loss: 1.207393  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.571826 \n",
      "\n",
      "loss: 0.581012  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.530544 \n",
      "\n",
      "loss: 0.548626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.499221 \n",
      "\n",
      "loss: 0.532232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.493325 \n",
      "\n",
      "loss: 0.534940  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.491760 \n",
      "\n",
      "loss: 0.486766  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.487296 \n",
      "\n",
      "loss: 0.456070  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.486815 \n",
      "\n",
      "loss: 0.453757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.472057 \n",
      "\n",
      "loss: 0.479264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.459909 \n",
      "\n",
      "loss: 0.526547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.456639 \n",
      "\n",
      "loss: 0.505762  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.460710 \n",
      "\n",
      "loss: 0.433370  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.451031 \n",
      "\n",
      "loss: 0.462875  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.452622 \n",
      "\n",
      "loss: 0.423248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.449733 \n",
      "\n",
      "loss: 0.447429  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.439466 \n",
      "\n",
      "loss: 0.442018  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.438250 \n",
      "\n",
      "loss: 0.440968  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.450490 \n",
      "\n",
      "loss: 0.461495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.432882 \n",
      "\n",
      "loss: 0.432010  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.428748 \n",
      "\n",
      "loss: 0.458843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.426076 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 279/500\n",
      "--------------------\n",
      "{'hl': [349, 493, 539], 'alpha': 0.006729057465192493, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.46569123089144193}\n",
      "loss: 1.107295  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 18.867203 \n",
      "\n",
      "loss: 19.702681  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 11.466706 \n",
      "\n",
      "loss: 11.276752  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 11.147227 \n",
      "\n",
      "loss: 11.602242  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 5.449283 \n",
      "\n",
      "loss: 5.815742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 16.122283 \n",
      "\n",
      "loss: 14.777741  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 15.626397 \n",
      "\n",
      "loss: 15.197239  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 11.571276 \n",
      "\n",
      "loss: 11.821084  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 7.428094 \n",
      "\n",
      "loss: 8.316449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.8%, Avg loss: 7.815236 \n",
      "\n",
      "loss: 8.404474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 9.838075 \n",
      "\n",
      "loss: 9.476133  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 16.151596 \n",
      "\n",
      "loss: 17.618299  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 6.294604 \n",
      "\n",
      "loss: 5.686705  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 32.737999 \n",
      "\n",
      "loss: 32.652931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 4.525360 \n",
      "\n",
      "loss: 4.682316  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 10.006671 \n",
      "\n",
      "loss: 10.127398  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 22.9%, Avg loss: 17.750442 \n",
      "\n",
      "loss: 17.231312  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 11.232489 \n",
      "\n",
      "loss: 10.796470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 12.531215 \n",
      "\n",
      "loss: 12.428696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 21.789381 \n",
      "\n",
      "loss: 22.527153  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 21.465347 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 280/500\n",
      "--------------------\n",
      "{'hl': [174, 410], 'alpha': 0.9171976857207029, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.25370676160202815}\n",
      "loss: 1.071146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 11.366582 \n",
      "\n",
      "loss: 12.261582  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.905631 \n",
      "\n",
      "loss: 0.900287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.998899 \n",
      "\n",
      "loss: 1.000960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.999283 \n",
      "\n",
      "loss: 0.998067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.999995 \n",
      "\n",
      "loss: 0.999933  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.998214 \n",
      "\n",
      "loss: 1.002498  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.002906 \n",
      "\n",
      "loss: 1.004293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.004616 \n",
      "\n",
      "loss: 1.002115  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.998590 \n",
      "\n",
      "loss: 1.000490  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.003053 \n",
      "\n",
      "loss: 1.005480  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.003347 \n",
      "\n",
      "loss: 1.004848  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.003876 \n",
      "\n",
      "loss: 1.004129  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.003204 \n",
      "\n",
      "loss: 1.001578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.000935 \n",
      "\n",
      "loss: 1.002059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.001109 \n",
      "\n",
      "loss: 1.003219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.996272 \n",
      "\n",
      "loss: 0.995214  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.002650 \n",
      "\n",
      "loss: 0.996814  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.002256 \n",
      "\n",
      "loss: 1.003009  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.007098 \n",
      "\n",
      "loss: 1.008841  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.002873 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 281/500\n",
      "--------------------\n",
      "{'hl': [553, 509, 584], 'alpha': 0.0015818389276932652, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.1656866728301034}\n",
      "loss: 1.092939  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 866.074687 \n",
      "\n",
      "loss: 759.789185  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.998657 \n",
      "\n",
      "loss: 1.463761  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.729003 \n",
      "\n",
      "loss: 0.740835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.730422 \n",
      "\n",
      "loss: 0.657354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.676392 \n",
      "\n",
      "loss: 0.745363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.643372 \n",
      "\n",
      "loss: 0.626710  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.626594 \n",
      "\n",
      "loss: 0.623076  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.594031 \n",
      "\n",
      "loss: 0.558012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.701219 \n",
      "\n",
      "loss: 0.690823  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.641870 \n",
      "\n",
      "loss: 0.635545  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.568208 \n",
      "\n",
      "loss: 0.593472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.592968 \n",
      "\n",
      "loss: 0.571621  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.564026 \n",
      "\n",
      "loss: 0.574360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.567959 \n",
      "\n",
      "loss: 0.608095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.538208 \n",
      "\n",
      "loss: 0.543388  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.570777 \n",
      "\n",
      "loss: 0.562365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.568114 \n",
      "\n",
      "loss: 0.552744  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.547911 \n",
      "\n",
      "loss: 0.569995  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.568365 \n",
      "\n",
      "loss: 0.567659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.562183 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 282/500\n",
      "--------------------\n",
      "{'hl': [434], 'alpha': 0.021617654293994485, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.1328386654491621}\n",
      "loss: 1.155758  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 5.652243 \n",
      "\n",
      "loss: 4.008706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 1.446155 \n",
      "\n",
      "loss: 1.631430  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.511148 \n",
      "\n",
      "loss: 0.526374  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.436798 \n",
      "\n",
      "loss: 0.449092  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.414722 \n",
      "\n",
      "loss: 0.479290  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.436317 \n",
      "\n",
      "loss: 0.413709  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.463107 \n",
      "\n",
      "loss: 0.490129  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.449441 \n",
      "\n",
      "loss: 0.467975  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.457813 \n",
      "\n",
      "loss: 0.484476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.451450 \n",
      "\n",
      "loss: 0.473100  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.446393 \n",
      "\n",
      "loss: 0.450251  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.444988 \n",
      "\n",
      "loss: 0.416737  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.447069 \n",
      "\n",
      "loss: 0.397565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.446868 \n",
      "\n",
      "loss: 0.461006  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.433071 \n",
      "\n",
      "loss: 0.455269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.455791 \n",
      "\n",
      "loss: 0.469556  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.448608 \n",
      "\n",
      "loss: 0.473029  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.453643 \n",
      "\n",
      "loss: 0.434769  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.456748 \n",
      "\n",
      "loss: 0.465694  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.439710 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 283/500\n",
      "--------------------\n",
      "{'hl': [600, 599, 241], 'alpha': 0.07684231658698659, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.262163743079079}\n",
      "loss: 1.176007  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.920291 \n",
      "\n",
      "loss: 0.893884  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.834451 \n",
      "\n",
      "loss: 0.801611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.883583 \n",
      "\n",
      "loss: 0.867513  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.865927 \n",
      "\n",
      "loss: 0.866452  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.971742 \n",
      "\n",
      "loss: 0.983059  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.944768 \n",
      "\n",
      "loss: 0.956664  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.887105 \n",
      "\n",
      "loss: 0.858972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.922614 \n",
      "\n",
      "loss: 0.899770  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.821215 \n",
      "\n",
      "loss: 0.851749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.935033 \n",
      "\n",
      "loss: 0.932468  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.919452 \n",
      "\n",
      "loss: 0.892667  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.876335 \n",
      "\n",
      "loss: 0.862365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.973896 \n",
      "\n",
      "loss: 1.006575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.018107 \n",
      "\n",
      "loss: 1.031072  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.875117 \n",
      "\n",
      "loss: 0.920263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.881337 \n",
      "\n",
      "loss: 0.880874  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.881300 \n",
      "\n",
      "loss: 0.877296  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.931501 \n",
      "\n",
      "loss: 0.892980  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.054089 \n",
      "\n",
      "loss: 1.121292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.004290 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 284/500\n",
      "--------------------\n",
      "{'hl': [642, 397, 159], 'alpha': 0.19348404780184153, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.28632787867492254}\n",
      "loss: 1.090261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.608209 \n",
      "\n",
      "loss: 0.630039  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.602505 \n",
      "\n",
      "loss: 0.580651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.591859 \n",
      "\n",
      "loss: 0.611855  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.590323 \n",
      "\n",
      "loss: 0.586432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.607615 \n",
      "\n",
      "loss: 0.604393  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.619270 \n",
      "\n",
      "loss: 0.583369  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.601563 \n",
      "\n",
      "loss: 0.595724  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.613517 \n",
      "\n",
      "loss: 0.610930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.597368 \n",
      "\n",
      "loss: 0.627458  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.610878 \n",
      "\n",
      "loss: 0.608406  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.598914 \n",
      "\n",
      "loss: 0.597698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.604237 \n",
      "\n",
      "loss: 0.608179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.602480 \n",
      "\n",
      "loss: 0.627166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.590475 \n",
      "\n",
      "loss: 0.616514  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.609000 \n",
      "\n",
      "loss: 0.612110  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.605800 \n",
      "\n",
      "loss: 0.584646  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.602863 \n",
      "\n",
      "loss: 0.611728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.600637 \n",
      "\n",
      "loss: 0.590168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.603272 \n",
      "\n",
      "loss: 0.603767  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.611444 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 285/500\n",
      "--------------------\n",
      "{'hl': [120, 203, 27], 'alpha': 0.005809707461500593, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.2065387588834843}\n",
      "loss: 1.091403  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.822863 \n",
      "\n",
      "loss: 0.809238  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.830259 \n",
      "\n",
      "loss: 0.806834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809606 \n",
      "\n",
      "loss: 0.834213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.811562 \n",
      "\n",
      "loss: 0.813163  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.804885 \n",
      "\n",
      "loss: 0.824059  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.819596 \n",
      "\n",
      "loss: 0.813266  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824161 \n",
      "\n",
      "loss: 0.825614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815375 \n",
      "\n",
      "loss: 0.810866  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.817060 \n",
      "\n",
      "loss: 0.825470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813479 \n",
      "\n",
      "loss: 0.838791  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.820335 \n",
      "\n",
      "loss: 0.812049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.825448 \n",
      "\n",
      "loss: 0.820897  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.828385 \n",
      "\n",
      "loss: 0.822945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.812378 \n",
      "\n",
      "loss: 0.830827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.824908 \n",
      "\n",
      "loss: 0.838102  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.813001 \n",
      "\n",
      "loss: 0.814569  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.825264 \n",
      "\n",
      "loss: 0.797383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.807421 \n",
      "\n",
      "loss: 0.793611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.812832 \n",
      "\n",
      "loss: 0.850482  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.809961 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 286/500\n",
      "--------------------\n",
      "{'hl': [428], 'alpha': 0.010168994640537976, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.35291703855266743}\n",
      "loss: 1.086165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.224066 \n",
      "\n",
      "loss: 1.066324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.773986 \n",
      "\n",
      "loss: 0.805386  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 1.076289 \n",
      "\n",
      "loss: 1.122482  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.807008 \n",
      "\n",
      "loss: 1.960883  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 3.029130 \n",
      "\n",
      "loss: 3.118365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 4.582688 \n",
      "\n",
      "loss: 4.593090  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.799826 \n",
      "\n",
      "loss: 0.868884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 2.436195 \n",
      "\n",
      "loss: 2.287729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.768605 \n",
      "\n",
      "loss: 0.719953  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.997917 \n",
      "\n",
      "loss: 1.020639  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.887601 \n",
      "\n",
      "loss: 0.840444  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.660788 \n",
      "\n",
      "loss: 0.630467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.446547 \n",
      "\n",
      "loss: 1.460539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.349672 \n",
      "\n",
      "loss: 1.260020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.706407 \n",
      "\n",
      "loss: 0.658879  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 1.159475 \n",
      "\n",
      "loss: 1.106558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.125630 \n",
      "\n",
      "loss: 1.205983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 6.567741 \n",
      "\n",
      "loss: 6.092103  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.905030 \n",
      "\n",
      "loss: 1.081318  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 1.839878 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 287/500\n",
      "--------------------\n",
      "{'hl': [220, 582, 340], 'alpha': 0.9828595766125476, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.15694492410903477}\n",
      "loss: 1.126270  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.554588 \n",
      "\n",
      "loss: 5.569356  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.859171 \n",
      "\n",
      "loss: 0.847680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.896954 \n",
      "\n",
      "loss: 0.922656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.589028 \n",
      "\n",
      "loss: 1.570135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.302751 \n",
      "\n",
      "loss: 1.263024  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.891187 \n",
      "\n",
      "loss: 0.891527  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.068820 \n",
      "\n",
      "loss: 1.071575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.156071 \n",
      "\n",
      "loss: 1.172978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.896175 \n",
      "\n",
      "loss: 0.899317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.281324 \n",
      "\n",
      "loss: 1.277762  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.925326 \n",
      "\n",
      "loss: 0.927914  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 1.530014 \n",
      "\n",
      "loss: 1.540792  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.591426 \n",
      "\n",
      "loss: 1.607460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.865130 \n",
      "\n",
      "loss: 0.877980  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.078094 \n",
      "\n",
      "loss: 1.108609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.203875 \n",
      "\n",
      "loss: 1.209548  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 2.079929 \n",
      "\n",
      "loss: 2.084972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 15.955473 \n",
      "\n",
      "loss: 16.349688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 9.719532 \n",
      "\n",
      "loss: 9.803841  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 7.471748 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 288/500\n",
      "--------------------\n",
      "{'hl': [478], 'alpha': 0.44514002278661846, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.33796670142052837}\n",
      "loss: 1.125806  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 41.2%, Avg loss: 2.790784 \n",
      "\n",
      "loss: 2.718982  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.658682 \n",
      "\n",
      "loss: 0.647936  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.667939 \n",
      "\n",
      "loss: 0.662981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.688291 \n",
      "\n",
      "loss: 0.698706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.691408 \n",
      "\n",
      "loss: 0.679115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.668847 \n",
      "\n",
      "loss: 0.680619  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.692181 \n",
      "\n",
      "loss: 0.688027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.693111 \n",
      "\n",
      "loss: 0.697207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.692631 \n",
      "\n",
      "loss: 0.678526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.686958 \n",
      "\n",
      "loss: 0.687997  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.669349 \n",
      "\n",
      "loss: 0.691112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.684332 \n",
      "\n",
      "loss: 0.685194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.697668 \n",
      "\n",
      "loss: 0.682875  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.682782 \n",
      "\n",
      "loss: 0.680775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.676285 \n",
      "\n",
      "loss: 0.690680  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.675503 \n",
      "\n",
      "loss: 0.680199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.711247 \n",
      "\n",
      "loss: 0.727173  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.678953 \n",
      "\n",
      "loss: 0.673087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.661326 \n",
      "\n",
      "loss: 0.664450  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.651381 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 289/500\n",
      "--------------------\n",
      "{'hl': [705, 666, 717], 'alpha': 0.0011414285552741339, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.4786729643570998}\n",
      "loss: 1.155653  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.811400 \n",
      "\n",
      "loss: 0.810846  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.805350 \n",
      "\n",
      "loss: 0.782059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 0.767646 \n",
      "\n",
      "loss: 0.800429  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.727240 \n",
      "\n",
      "loss: 0.742874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.659390 \n",
      "\n",
      "loss: 0.639663  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.597887 \n",
      "\n",
      "loss: 0.570418  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.585118 \n",
      "\n",
      "loss: 0.556571  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.560063 \n",
      "\n",
      "loss: 0.494673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.533670 \n",
      "\n",
      "loss: 0.573869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.518588 \n",
      "\n",
      "loss: 0.517281  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.605828 \n",
      "\n",
      "loss: 0.618417  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.531550 \n",
      "\n",
      "loss: 0.509172  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.543786 \n",
      "\n",
      "loss: 0.556071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.551628 \n",
      "\n",
      "loss: 0.491345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.506450 \n",
      "\n",
      "loss: 0.474712  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.504196 \n",
      "\n",
      "loss: 0.472385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.512046 \n",
      "\n",
      "loss: 0.508330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.519058 \n",
      "\n",
      "loss: 0.542824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.491210 \n",
      "\n",
      "loss: 0.498059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.501184 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 290/500\n",
      "--------------------\n",
      "{'hl': [579, 313], 'alpha': 0.0007933560756244482, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.35247997832460826}\n",
      "loss: 1.114565  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 1362.311293 \n",
      "\n",
      "loss: 1023.095276  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 179.461645 \n",
      "\n",
      "loss: 147.886444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 90.863539 \n",
      "\n",
      "loss: 80.810280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 22.755951 \n",
      "\n",
      "loss: 36.956882  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 34.515582 \n",
      "\n",
      "loss: 23.736492  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 8.519358 \n",
      "\n",
      "loss: 7.896009  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 7.606415 \n",
      "\n",
      "loss: 7.024595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 4.358293 \n",
      "\n",
      "loss: 3.110651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 5.897714 \n",
      "\n",
      "loss: 9.721477  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 1.538187 \n",
      "\n",
      "loss: 1.944749  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 1.295628 \n",
      "\n",
      "loss: 0.815694  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 1.125121 \n",
      "\n",
      "loss: 0.600440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.974666 \n",
      "\n",
      "loss: 1.035716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.851139 \n",
      "\n",
      "loss: 2.652179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.536056 \n",
      "\n",
      "loss: 0.485199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.424268 \n",
      "\n",
      "loss: 0.329461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.792678 \n",
      "\n",
      "loss: 0.457894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.620758 \n",
      "\n",
      "loss: 0.555459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.357138 \n",
      "\n",
      "loss: 0.396970  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.333457 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 291/500\n",
      "--------------------\n",
      "{'hl': [508, 332, 499], 'alpha': 0.0024843495237721197, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.06102486545578426}\n",
      "loss: 1.087626  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 6.511320 \n",
      "\n",
      "loss: 7.062912  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 2.197730 \n",
      "\n",
      "loss: 2.836291  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.491521 \n",
      "\n",
      "loss: 0.529584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.418541 \n",
      "\n",
      "loss: 0.439979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.424015 \n",
      "\n",
      "loss: 0.471675  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.381239 \n",
      "\n",
      "loss: 0.400085  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.374381 \n",
      "\n",
      "loss: 0.361836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.368200 \n",
      "\n",
      "loss: 0.345563  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.343974 \n",
      "\n",
      "loss: 0.315549  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.364670 \n",
      "\n",
      "loss: 0.361360  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.334128 \n",
      "\n",
      "loss: 0.315549  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.326555 \n",
      "\n",
      "loss: 0.356360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.329080 \n",
      "\n",
      "loss: 0.321997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.333342 \n",
      "\n",
      "loss: 0.326325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.318740 \n",
      "\n",
      "loss: 0.329285  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.322204 \n",
      "\n",
      "loss: 0.336576  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.361734 \n",
      "\n",
      "loss: 0.361607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.310911 \n",
      "\n",
      "loss: 0.321273  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.323049 \n",
      "\n",
      "loss: 0.348115  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.319783 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 292/500\n",
      "--------------------\n",
      "{'hl': [564, 396, 412], 'alpha': 0.1877196952622793, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.021129036767679483}\n",
      "loss: 1.079202  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.576790 \n",
      "\n",
      "loss: 0.556817  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.598113 \n",
      "\n",
      "loss: 0.617687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.621395 \n",
      "\n",
      "loss: 0.633900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.633094 \n",
      "\n",
      "loss: 0.630551  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.631262 \n",
      "\n",
      "loss: 0.609838  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.651423 \n",
      "\n",
      "loss: 0.648031  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.602579 \n",
      "\n",
      "loss: 0.597154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.581794 \n",
      "\n",
      "loss: 0.604960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.619086 \n",
      "\n",
      "loss: 0.632893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.611276 \n",
      "\n",
      "loss: 0.628804  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.647687 \n",
      "\n",
      "loss: 0.654334  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.577722 \n",
      "\n",
      "loss: 0.538350  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.679236 \n",
      "\n",
      "loss: 0.676846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.672501 \n",
      "\n",
      "loss: 0.665714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.593824 \n",
      "\n",
      "loss: 0.634636  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.584145 \n",
      "\n",
      "loss: 0.580273  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.624236 \n",
      "\n",
      "loss: 0.612090  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.626262 \n",
      "\n",
      "loss: 0.625978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.725096 \n",
      "\n",
      "loss: 0.714400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 6.277727 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 293/500\n",
      "--------------------\n",
      "{'hl': [88, 362, 460], 'alpha': 0.04206183372173431, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.10111379679957819}\n",
      "loss: 1.123898  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.322171 \n",
      "\n",
      "loss: 1.297115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.157824 \n",
      "\n",
      "loss: 1.205413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.915726 \n",
      "\n",
      "loss: 0.932216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.022314 \n",
      "\n",
      "loss: 1.060692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.972897 \n",
      "\n",
      "loss: 0.951852  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.952815 \n",
      "\n",
      "loss: 0.971003  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.950820 \n",
      "\n",
      "loss: 0.990036  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.891298 \n",
      "\n",
      "loss: 0.900809  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.972989 \n",
      "\n",
      "loss: 1.031709  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.870339 \n",
      "\n",
      "loss: 0.871767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.930794 \n",
      "\n",
      "loss: 0.927717  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.864502 \n",
      "\n",
      "loss: 0.845132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.880802 \n",
      "\n",
      "loss: 0.891333  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.032098 \n",
      "\n",
      "loss: 1.035397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.918304 \n",
      "\n",
      "loss: 0.905953  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.931962 \n",
      "\n",
      "loss: 0.900107  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.963618 \n",
      "\n",
      "loss: 0.944538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.906071 \n",
      "\n",
      "loss: 0.897125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.884355 \n",
      "\n",
      "loss: 0.881122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.900082 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 294/500\n",
      "--------------------\n",
      "{'hl': [285, 583, 720], 'alpha': 0.0012203541063063818, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.12130477340130237}\n",
      "loss: 1.081554  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.534765 \n",
      "\n",
      "loss: 0.516887  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.485196 \n",
      "\n",
      "loss: 0.501326  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.443809 \n",
      "\n",
      "loss: 0.460345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.425548 \n",
      "\n",
      "loss: 0.450889  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.383286 \n",
      "\n",
      "loss: 0.442569  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.401927 \n",
      "\n",
      "loss: 0.385758  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.388147 \n",
      "\n",
      "loss: 0.400811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.367411 \n",
      "\n",
      "loss: 0.399735  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.356665 \n",
      "\n",
      "loss: 0.371305  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.360462 \n",
      "\n",
      "loss: 0.357790  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.342722 \n",
      "\n",
      "loss: 0.344044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364547 \n",
      "\n",
      "loss: 0.339790  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.347043 \n",
      "\n",
      "loss: 0.359963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.335081 \n",
      "\n",
      "loss: 0.313048  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.334821 \n",
      "\n",
      "loss: 0.329972  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.330790 \n",
      "\n",
      "loss: 0.347363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.331576 \n",
      "\n",
      "loss: 0.322495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.332786 \n",
      "\n",
      "loss: 0.327217  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.326000 \n",
      "\n",
      "loss: 0.311604  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.311402 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 295/500\n",
      "--------------------\n",
      "{'hl': [551, 239, 661], 'alpha': 0.0008537805152401879, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.16521378238132067}\n",
      "loss: 1.105751  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 430.059913 \n",
      "\n",
      "loss: 430.121796  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 38.027507 \n",
      "\n",
      "loss: 44.172771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 0.939549 \n",
      "\n",
      "loss: 0.906906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.826208 \n",
      "\n",
      "loss: 0.835118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813900 \n",
      "\n",
      "loss: 0.815742  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.812341 \n",
      "\n",
      "loss: 0.784071  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.824380 \n",
      "\n",
      "loss: 0.813049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.813868 \n",
      "\n",
      "loss: 0.826267  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814264 \n",
      "\n",
      "loss: 0.820993  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.808339 \n",
      "\n",
      "loss: 0.814019  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.822032 \n",
      "\n",
      "loss: 0.813928  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.821114 \n",
      "\n",
      "loss: 0.792508  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.812117 \n",
      "\n",
      "loss: 0.830839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.816739 \n",
      "\n",
      "loss: 0.808226  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.818411 \n",
      "\n",
      "loss: 0.807465  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.821865 \n",
      "\n",
      "loss: 0.791977  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.823270 \n",
      "\n",
      "loss: 0.790693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.818486 \n",
      "\n",
      "loss: 0.802364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.812989 \n",
      "\n",
      "loss: 0.815068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.809813 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 296/500\n",
      "--------------------\n",
      "{'hl': [110, 705], 'alpha': 0.12107771949226372, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.20351303502828705}\n",
      "loss: 1.101498  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.542129 \n",
      "\n",
      "loss: 0.576845  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.537956 \n",
      "\n",
      "loss: 0.551343  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.532805 \n",
      "\n",
      "loss: 0.543503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.524534 \n",
      "\n",
      "loss: 0.554197  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.519196 \n",
      "\n",
      "loss: 0.514629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.514466 \n",
      "\n",
      "loss: 0.496122  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.526865 \n",
      "\n",
      "loss: 0.519800  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.527698 \n",
      "\n",
      "loss: 0.507200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.519757 \n",
      "\n",
      "loss: 0.524120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.516991 \n",
      "\n",
      "loss: 0.520125  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.514034 \n",
      "\n",
      "loss: 0.513282  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.519108 \n",
      "\n",
      "loss: 0.496000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.522801 \n",
      "\n",
      "loss: 0.526043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.520631 \n",
      "\n",
      "loss: 0.533371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.516851 \n",
      "\n",
      "loss: 0.526762  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.521757 \n",
      "\n",
      "loss: 0.498307  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.524319 \n",
      "\n",
      "loss: 0.513067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.514666 \n",
      "\n",
      "loss: 0.517721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.524210 \n",
      "\n",
      "loss: 0.512400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.525110 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 297/500\n",
      "--------------------\n",
      "{'hl': [496, 674], 'alpha': 0.0006278037401253145, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.14277912911686572}\n",
      "loss: 1.100632  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 90.374501 \n",
      "\n",
      "loss: 75.492043  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 30.767735 \n",
      "\n",
      "loss: 48.832771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 3.431657 \n",
      "\n",
      "loss: 2.634985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 3.723798 \n",
      "\n",
      "loss: 2.794372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 2.178827 \n",
      "\n",
      "loss: 2.423162  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.829862 \n",
      "\n",
      "loss: 0.844340  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.743375 \n",
      "\n",
      "loss: 0.745838  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.501164 \n",
      "\n",
      "loss: 0.506588  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.618602 \n",
      "\n",
      "loss: 0.579248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.400245 \n",
      "\n",
      "loss: 0.428144  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.405392 \n",
      "\n",
      "loss: 0.367457  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.592802 \n",
      "\n",
      "loss: 0.512731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.377621 \n",
      "\n",
      "loss: 0.339822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.449387 \n",
      "\n",
      "loss: 0.414995  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.326528 \n",
      "\n",
      "loss: 0.306062  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.302139 \n",
      "\n",
      "loss: 0.317297  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.349778 \n",
      "\n",
      "loss: 0.380460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.314063 \n",
      "\n",
      "loss: 0.304403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.344550 \n",
      "\n",
      "loss: 0.357788  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.289698 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 298/500\n",
      "--------------------\n",
      "{'hl': [99], 'alpha': 0.04066257915264808, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.45662353986235926}\n",
      "loss: 1.099542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.493970 \n",
      "\n",
      "loss: 0.462036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.502411 \n",
      "\n",
      "loss: 0.431653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.489450 \n",
      "\n",
      "loss: 0.522184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.479571 \n",
      "\n",
      "loss: 0.484622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.489040 \n",
      "\n",
      "loss: 0.490706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.479054 \n",
      "\n",
      "loss: 0.494415  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.477557 \n",
      "\n",
      "loss: 0.507510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.491130 \n",
      "\n",
      "loss: 0.484795  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.467056 \n",
      "\n",
      "loss: 0.487148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.483944 \n",
      "\n",
      "loss: 0.472479  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.488472 \n",
      "\n",
      "loss: 0.484135  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.491967 \n",
      "\n",
      "loss: 0.489190  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.477918 \n",
      "\n",
      "loss: 0.481344  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.480822 \n",
      "\n",
      "loss: 0.468924  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.476107 \n",
      "\n",
      "loss: 0.495642  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.477837 \n",
      "\n",
      "loss: 0.507540  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.475521 \n",
      "\n",
      "loss: 0.466554  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.474454 \n",
      "\n",
      "loss: 0.468639  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.483041 \n",
      "\n",
      "loss: 0.473817  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.472397 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 299/500\n",
      "--------------------\n",
      "{'hl': [435], 'alpha': 0.33804918455081523, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.49858618436394614}\n",
      "loss: 1.130693  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.637557 \n",
      "\n",
      "loss: 0.621395  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.629180 \n",
      "\n",
      "loss: 0.634177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.620011 \n",
      "\n",
      "loss: 0.644924  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.615691 \n",
      "\n",
      "loss: 0.621579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.656931 \n",
      "\n",
      "loss: 0.651769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.625926 \n",
      "\n",
      "loss: 0.643697  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.633764 \n",
      "\n",
      "loss: 0.620184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.637733 \n",
      "\n",
      "loss: 0.646616  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.618273 \n",
      "\n",
      "loss: 0.629135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.636587 \n",
      "\n",
      "loss: 0.632766  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.639354 \n",
      "\n",
      "loss: 0.642699  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.626347 \n",
      "\n",
      "loss: 0.616546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.622889 \n",
      "\n",
      "loss: 0.652354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.625681 \n",
      "\n",
      "loss: 0.622844  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.644804 \n",
      "\n",
      "loss: 0.662603  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.627117 \n",
      "\n",
      "loss: 0.646310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.627548 \n",
      "\n",
      "loss: 0.629907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.625248 \n",
      "\n",
      "loss: 0.629881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.629582 \n",
      "\n",
      "loss: 0.627469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.617135 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 300/500\n",
      "--------------------\n",
      "{'hl': [515, 198], 'alpha': 0.5577440926031276, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.004732657523201883}\n",
      "loss: 1.097432  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.983973 \n",
      "\n",
      "loss: 0.989585  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.931752 \n",
      "\n",
      "loss: 0.928560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.904321 \n",
      "\n",
      "loss: 0.902169  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.887805 \n",
      "\n",
      "loss: 0.884196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.882471 \n",
      "\n",
      "loss: 0.880405  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.877160 \n",
      "\n",
      "loss: 0.871325  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.883559 \n",
      "\n",
      "loss: 0.882938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.883160 \n",
      "\n",
      "loss: 0.885478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.885017 \n",
      "\n",
      "loss: 0.883457  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.888080 \n",
      "\n",
      "loss: 0.901894  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.897913 \n",
      "\n",
      "loss: 0.896025  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.904212 \n",
      "\n",
      "loss: 0.894459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.904105 \n",
      "\n",
      "loss: 0.905589  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.9%, Avg loss: 0.911130 \n",
      "\n",
      "loss: 0.912375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.915977 \n",
      "\n",
      "loss: 0.915929  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.922971 \n",
      "\n",
      "loss: 0.931269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.929557 \n",
      "\n",
      "loss: 0.920948  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.929023 \n",
      "\n",
      "loss: 0.930750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.933402 \n",
      "\n",
      "loss: 0.936364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.937493 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 301/500\n",
      "--------------------\n",
      "{'hl': [625, 117, 351], 'alpha': 0.0013748224313762062, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.4255447633151405}\n",
      "loss: 1.132678  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.830477 \n",
      "\n",
      "loss: 0.814399  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.836649 \n",
      "\n",
      "loss: 0.818554  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.817023 \n",
      "\n",
      "loss: 0.803248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.812232 \n",
      "\n",
      "loss: 0.843080  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.811613 \n",
      "\n",
      "loss: 0.818769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.841334 \n",
      "\n",
      "loss: 0.832562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.825234 \n",
      "\n",
      "loss: 0.816274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.803298 \n",
      "\n",
      "loss: 0.781391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.790879 \n",
      "\n",
      "loss: 0.804017  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.783111 \n",
      "\n",
      "loss: 0.781063  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.755395 \n",
      "\n",
      "loss: 0.736103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.681219 \n",
      "\n",
      "loss: 0.649161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.567124 \n",
      "\n",
      "loss: 0.574510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.562551 \n",
      "\n",
      "loss: 0.536132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.518916 \n",
      "\n",
      "loss: 0.512817  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.514432 \n",
      "\n",
      "loss: 0.545743  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.518461 \n",
      "\n",
      "loss: 0.562197  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.624607 \n",
      "\n",
      "loss: 0.622140  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.508248 \n",
      "\n",
      "loss: 0.524603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.520299 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 302/500\n",
      "--------------------\n",
      "{'hl': [287, 205], 'alpha': 0.17189193993780105, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.3655865049810062}\n",
      "loss: 1.052331  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.586435 \n",
      "\n",
      "loss: 0.557685  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.576818 \n",
      "\n",
      "loss: 0.571298  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.573459 \n",
      "\n",
      "loss: 0.568568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.570605 \n",
      "\n",
      "loss: 0.562353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.571469 \n",
      "\n",
      "loss: 0.587147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.570596 \n",
      "\n",
      "loss: 0.574298  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.575183 \n",
      "\n",
      "loss: 0.551030  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.580644 \n",
      "\n",
      "loss: 0.582675  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.559795 \n",
      "\n",
      "loss: 0.579598  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.563320 \n",
      "\n",
      "loss: 0.529271  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.578261 \n",
      "\n",
      "loss: 0.593044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.580376 \n",
      "\n",
      "loss: 0.571208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.571972 \n",
      "\n",
      "loss: 0.583745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.574931 \n",
      "\n",
      "loss: 0.588308  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.563334 \n",
      "\n",
      "loss: 0.582599  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.571583 \n",
      "\n",
      "loss: 0.541729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.574076 \n",
      "\n",
      "loss: 0.574783  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.572158 \n",
      "\n",
      "loss: 0.595532  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.560480 \n",
      "\n",
      "loss: 0.563232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.583540 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 303/500\n",
      "--------------------\n",
      "{'hl': [271, 198, 22], 'alpha': 0.0884039320252839, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.08782990742784852}\n",
      "loss: 1.145412  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.694050 \n",
      "\n",
      "loss: 0.693013  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.571878 \n",
      "\n",
      "loss: 0.551917  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.537105 \n",
      "\n",
      "loss: 0.536507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.509097 \n",
      "\n",
      "loss: 0.534858  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.522388 \n",
      "\n",
      "loss: 0.511451  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.521660 \n",
      "\n",
      "loss: 0.510638  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.508346 \n",
      "\n",
      "loss: 0.529584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.511192 \n",
      "\n",
      "loss: 0.476554  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.489897 \n",
      "\n",
      "loss: 0.491030  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.496641 \n",
      "\n",
      "loss: 0.483267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.487331 \n",
      "\n",
      "loss: 0.480096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.513166 \n",
      "\n",
      "loss: 0.475765  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.487116 \n",
      "\n",
      "loss: 0.501148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.500644 \n",
      "\n",
      "loss: 0.530153  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.495868 \n",
      "\n",
      "loss: 0.501154  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.494106 \n",
      "\n",
      "loss: 0.482658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.504622 \n",
      "\n",
      "loss: 0.495874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.501983 \n",
      "\n",
      "loss: 0.467519  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.495190 \n",
      "\n",
      "loss: 0.481813  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.483247 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 304/500\n",
      "--------------------\n",
      "{'hl': [423, 445, 535], 'alpha': 0.0020497770908099776, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.09247212240356525}\n",
      "loss: 1.015768  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.641871 \n",
      "\n",
      "loss: 1.615190  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.967367 \n",
      "\n",
      "loss: 0.952671  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.824302 \n",
      "\n",
      "loss: 0.836735  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.810347 \n",
      "\n",
      "loss: 0.819114  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.856628 \n",
      "\n",
      "loss: 0.878643  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.817921 \n",
      "\n",
      "loss: 0.800748  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.908983 \n",
      "\n",
      "loss: 0.936470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.820190 \n",
      "\n",
      "loss: 0.807583  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814835 \n",
      "\n",
      "loss: 0.813384  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.802190 \n",
      "\n",
      "loss: 0.823002  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.808964 \n",
      "\n",
      "loss: 0.798840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.826156 \n",
      "\n",
      "loss: 0.816991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.807718 \n",
      "\n",
      "loss: 0.796617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 0.807406 \n",
      "\n",
      "loss: 0.824335  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.805848 \n",
      "\n",
      "loss: 0.808945  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.798171 \n",
      "\n",
      "loss: 0.803617  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.815931 \n",
      "\n",
      "loss: 0.821808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.832690 \n",
      "\n",
      "loss: 0.799021  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.782970 \n",
      "\n",
      "loss: 0.794484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.827346 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 305/500\n",
      "--------------------\n",
      "{'hl': [496], 'alpha': 0.0019697299131549717, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.1304665600050154}\n",
      "loss: 1.092978  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.508296 \n",
      "\n",
      "loss: 0.435519  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.487953 \n",
      "\n",
      "loss: 0.521534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.468662 \n",
      "\n",
      "loss: 0.461845  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.448333 \n",
      "\n",
      "loss: 0.463460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.443946 \n",
      "\n",
      "loss: 0.473186  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.426712 \n",
      "\n",
      "loss: 0.432186  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.445048 \n",
      "\n",
      "loss: 0.443335  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.440126 \n",
      "\n",
      "loss: 0.423263  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.422373 \n",
      "\n",
      "loss: 0.419816  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.408891 \n",
      "\n",
      "loss: 0.394479  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.411423 \n",
      "\n",
      "loss: 0.433216  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.418869 \n",
      "\n",
      "loss: 0.412574  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.413750 \n",
      "\n",
      "loss: 0.393932  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.424680 \n",
      "\n",
      "loss: 0.384037  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.388224 \n",
      "\n",
      "loss: 0.439531  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.393582 \n",
      "\n",
      "loss: 0.368345  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.402202 \n",
      "\n",
      "loss: 0.389495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.402836 \n",
      "\n",
      "loss: 0.377002  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.389861 \n",
      "\n",
      "loss: 0.416065  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.380036 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 306/500\n",
      "--------------------\n",
      "{'hl': [465], 'alpha': 0.10352055867842062, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.2912721297023369}\n",
      "loss: 1.097358  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 9.045581 \n",
      "\n",
      "loss: 8.731333  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 4.448087 \n",
      "\n",
      "loss: 4.242689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 6.565216 \n",
      "\n",
      "loss: 6.916135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 16.554995 \n",
      "\n",
      "loss: 18.688288  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 15.611045 \n",
      "\n",
      "loss: 16.757902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 13.465121 \n",
      "\n",
      "loss: 11.731342  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 4.271870 \n",
      "\n",
      "loss: 4.557050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 1.281777 \n",
      "\n",
      "loss: 1.158180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 7.411771 \n",
      "\n",
      "loss: 8.354176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 47.295481 \n",
      "\n",
      "loss: 47.957462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 16.053111 \n",
      "\n",
      "loss: 19.057095  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 28.530779 \n",
      "\n",
      "loss: 29.142288  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 15.544860 \n",
      "\n",
      "loss: 16.624313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.9%, Avg loss: 5.527002 \n",
      "\n",
      "loss: 5.334802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 3.769347 \n",
      "\n",
      "loss: 3.354824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 9.771384 \n",
      "\n",
      "loss: 8.482737  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 7.972874 \n",
      "\n",
      "loss: 7.139652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 8.974604 \n",
      "\n",
      "loss: 10.123839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 22.235165 \n",
      "\n",
      "loss: 23.457869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 13.724627 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 307/500\n",
      "--------------------\n",
      "{'hl': [19, 275, 677], 'alpha': 0.0027428898174784106, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3339262787878558}\n",
      "loss: 1.111123  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.518600 \n",
      "\n",
      "loss: 0.537008  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.502284 \n",
      "\n",
      "loss: 0.484404  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.475653 \n",
      "\n",
      "loss: 0.484899  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.425741 \n",
      "\n",
      "loss: 0.424194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.409257 \n",
      "\n",
      "loss: 0.430250  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.396733 \n",
      "\n",
      "loss: 0.423608  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.421729 \n",
      "\n",
      "loss: 0.389503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.412640 \n",
      "\n",
      "loss: 0.439682  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.402357 \n",
      "\n",
      "loss: 0.416862  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.371206 \n",
      "\n",
      "loss: 0.377577  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.367859 \n",
      "\n",
      "loss: 0.345161  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.362870 \n",
      "\n",
      "loss: 0.365757  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.373534 \n",
      "\n",
      "loss: 0.376449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.349300 \n",
      "\n",
      "loss: 0.351726  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.359583 \n",
      "\n",
      "loss: 0.351532  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.354176 \n",
      "\n",
      "loss: 0.355023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.374810 \n",
      "\n",
      "loss: 0.364264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.372179 \n",
      "\n",
      "loss: 0.364332  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.362041 \n",
      "\n",
      "loss: 0.312775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.372486 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 308/500\n",
      "--------------------\n",
      "{'hl': [322, 171], 'alpha': 0.004184720455342593, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.3193917914671717}\n",
      "loss: 1.129630  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.467420 \n",
      "\n",
      "loss: 0.497980  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.423884 \n",
      "\n",
      "loss: 0.434381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.412567 \n",
      "\n",
      "loss: 0.419679  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.391969 \n",
      "\n",
      "loss: 0.336549  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.363423 \n",
      "\n",
      "loss: 0.401787  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.355150 \n",
      "\n",
      "loss: 0.372649  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.381665 \n",
      "\n",
      "loss: 0.392435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.348354 \n",
      "\n",
      "loss: 0.319725  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.343913 \n",
      "\n",
      "loss: 0.345255  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.348753 \n",
      "\n",
      "loss: 0.348556  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.338992 \n",
      "\n",
      "loss: 0.327601  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.339965 \n",
      "\n",
      "loss: 0.335882  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.332230 \n",
      "\n",
      "loss: 0.322492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.339129 \n",
      "\n",
      "loss: 0.383600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.307362 \n",
      "\n",
      "loss: 0.339657  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.331199 \n",
      "\n",
      "loss: 0.343077  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.336221 \n",
      "\n",
      "loss: 0.307817  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.373759 \n",
      "\n",
      "loss: 0.340118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.312209 \n",
      "\n",
      "loss: 0.299965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.311441 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 309/500\n",
      "--------------------\n",
      "{'hl': [384, 637], 'alpha': 0.0007645342745441812, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.0766774637881207}\n",
      "loss: 1.143411  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 1.206065 \n",
      "\n",
      "loss: 1.175746  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.683318 \n",
      "\n",
      "loss: 0.665929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510138 \n",
      "\n",
      "loss: 0.536684  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.948083 \n",
      "\n",
      "loss: 1.054700  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.828482 \n",
      "\n",
      "loss: 0.818702  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.555493 \n",
      "\n",
      "loss: 0.601340  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.940506 \n",
      "\n",
      "loss: 1.008385  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.683717 \n",
      "\n",
      "loss: 0.694946  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.418342 \n",
      "\n",
      "loss: 1.354822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 2.175829 \n",
      "\n",
      "loss: 2.159957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 1.068597 \n",
      "\n",
      "loss: 1.051647  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.793394 \n",
      "\n",
      "loss: 0.663553  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.886412 \n",
      "\n",
      "loss: 0.860944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.762284 \n",
      "\n",
      "loss: 0.679630  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.886869 \n",
      "\n",
      "loss: 0.840453  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.888044 \n",
      "\n",
      "loss: 0.918598  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.295906 \n",
      "\n",
      "loss: 1.277746  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 1.785548 \n",
      "\n",
      "loss: 1.728565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.494619 \n",
      "\n",
      "loss: 0.510721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 1.255396 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 310/500\n",
      "--------------------\n",
      "{'hl': [628, 390, 433], 'alpha': 0.06423369532430187, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.3809536240235564}\n",
      "loss: 1.064626  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.842542 \n",
      "\n",
      "loss: 0.855549  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.020658 \n",
      "\n",
      "loss: 1.059027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.911586 \n",
      "\n",
      "loss: 0.888165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.033262 \n",
      "\n",
      "loss: 1.075463  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.943074 \n",
      "\n",
      "loss: 0.889060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.898803 \n",
      "\n",
      "loss: 0.919542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.120759 \n",
      "\n",
      "loss: 1.107889  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.011907 \n",
      "\n",
      "loss: 1.008565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.865617 \n",
      "\n",
      "loss: 0.863791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.037134 \n",
      "\n",
      "loss: 1.041241  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.972644 \n",
      "\n",
      "loss: 0.976117  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.972348 \n",
      "\n",
      "loss: 0.952013  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.992821 \n",
      "\n",
      "loss: 1.015911  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.956104 \n",
      "\n",
      "loss: 0.929874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.121962 \n",
      "\n",
      "loss: 1.140722  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.913327 \n",
      "\n",
      "loss: 0.926504  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.980323 \n",
      "\n",
      "loss: 0.968728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.045644 \n",
      "\n",
      "loss: 1.004389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.994383 \n",
      "\n",
      "loss: 0.958279  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.043363 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 311/500\n",
      "--------------------\n",
      "{'hl': [618, 91, 546], 'alpha': 0.006123389850011128, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.45863062891980966}\n",
      "loss: 1.090735  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.467009 \n",
      "\n",
      "loss: 0.501827  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.401718 \n",
      "\n",
      "loss: 0.386996  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.436876 \n",
      "\n",
      "loss: 0.438001  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.380118 \n",
      "\n",
      "loss: 0.363699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.353746 \n",
      "\n",
      "loss: 0.370470  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.362795 \n",
      "\n",
      "loss: 0.367946  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.427600 \n",
      "\n",
      "loss: 0.422949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.341423 \n",
      "\n",
      "loss: 0.325687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.328329 \n",
      "\n",
      "loss: 0.341538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.334330 \n",
      "\n",
      "loss: 0.349286  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.330862 \n",
      "\n",
      "loss: 0.354049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.402972 \n",
      "\n",
      "loss: 0.371561  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.353372 \n",
      "\n",
      "loss: 0.350794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.371470 \n",
      "\n",
      "loss: 0.384005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.320845 \n",
      "\n",
      "loss: 0.334310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.353122 \n",
      "\n",
      "loss: 0.361491  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.325516 \n",
      "\n",
      "loss: 0.326237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.361119 \n",
      "\n",
      "loss: 0.368851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.327960 \n",
      "\n",
      "loss: 0.344657  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.344903 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 312/500\n",
      "--------------------\n",
      "{'hl': [71], 'alpha': 0.20658377814458642, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.08235212457571925}\n",
      "loss: 1.122913  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.602662 \n",
      "\n",
      "loss: 0.632586  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.590169 \n",
      "\n",
      "loss: 0.598003  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.586083 \n",
      "\n",
      "loss: 0.583193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.574775 \n",
      "\n",
      "loss: 0.549213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.590139 \n",
      "\n",
      "loss: 0.587574  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.581408 \n",
      "\n",
      "loss: 0.570840  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.587805 \n",
      "\n",
      "loss: 0.608077  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.577412 \n",
      "\n",
      "loss: 0.584467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.580629 \n",
      "\n",
      "loss: 0.592748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.581146 \n",
      "\n",
      "loss: 0.561720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.584211 \n",
      "\n",
      "loss: 0.596227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.585887 \n",
      "\n",
      "loss: 0.586484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.579147 \n",
      "\n",
      "loss: 0.604632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.580347 \n",
      "\n",
      "loss: 0.617133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.577763 \n",
      "\n",
      "loss: 0.552191  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.572659 \n",
      "\n",
      "loss: 0.572660  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.578771 \n",
      "\n",
      "loss: 0.548177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.579468 \n",
      "\n",
      "loss: 0.572583  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.574399 \n",
      "\n",
      "loss: 0.582991  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.584817 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 313/500\n",
      "--------------------\n",
      "{'hl': [460, 127, 704], 'alpha': 0.0006631410951322426, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.44945478692156554}\n",
      "loss: 1.037886  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.833618 \n",
      "\n",
      "loss: 0.831851  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.828698 \n",
      "\n",
      "loss: 0.812638  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.810729 \n",
      "\n",
      "loss: 0.801553  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.865172 \n",
      "\n",
      "loss: 0.881807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.811687 \n",
      "\n",
      "loss: 0.842668  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.818859 \n",
      "\n",
      "loss: 0.796446  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.813986 \n",
      "\n",
      "loss: 0.794182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.798314 \n",
      "\n",
      "loss: 0.803417  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.784604 \n",
      "\n",
      "loss: 0.797068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.764113 \n",
      "\n",
      "loss: 0.766324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.777839 \n",
      "\n",
      "loss: 0.773148  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.675846 \n",
      "\n",
      "loss: 0.695134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.553777 \n",
      "\n",
      "loss: 0.548969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.529514 \n",
      "\n",
      "loss: 0.579029  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.563473 \n",
      "\n",
      "loss: 0.578624  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.556357 \n",
      "\n",
      "loss: 0.539735  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.532691 \n",
      "\n",
      "loss: 0.566809  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.508114 \n",
      "\n",
      "loss: 0.522634  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.522206 \n",
      "\n",
      "loss: 0.522905  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.534107 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 314/500\n",
      "--------------------\n",
      "{'hl': [64, 472], 'alpha': 0.00033711444290585886, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.28199920143084684}\n",
      "loss: 1.021698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 1.008190 \n",
      "\n",
      "loss: 0.999028  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 2.030568 \n",
      "\n",
      "loss: 2.447945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 3.622803 \n",
      "\n",
      "loss: 4.093795  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.589754 \n",
      "\n",
      "loss: 0.638083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 2.031832 \n",
      "\n",
      "loss: 2.681923  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 1.292814 \n",
      "\n",
      "loss: 1.364376  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 27.1%, Avg loss: 2.247461 \n",
      "\n",
      "loss: 2.209534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.163991 \n",
      "\n",
      "loss: 2.182212  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 3.564224 \n",
      "\n",
      "loss: 3.878516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 2.139048 \n",
      "\n",
      "loss: 2.342237  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.678205 \n",
      "\n",
      "loss: 1.661260  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.504500 \n",
      "\n",
      "loss: 0.535248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 1.274680 \n",
      "\n",
      "loss: 1.355786  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.917011 \n",
      "\n",
      "loss: 2.143681  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 2.754311 \n",
      "\n",
      "loss: 2.952904  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.555628 \n",
      "\n",
      "loss: 0.604348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.532182 \n",
      "\n",
      "loss: 0.540358  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.802475 \n",
      "\n",
      "loss: 0.786104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.557522 \n",
      "\n",
      "loss: 0.558023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 1.681647 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 315/500\n",
      "--------------------\n",
      "{'hl': [481, 696, 323], 'alpha': 0.07818443809962612, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.40824496764397195}\n",
      "loss: 1.082025  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 9.761690 \n",
      "\n",
      "loss: 8.522675  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 9.727403 \n",
      "\n",
      "loss: 10.151836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.886336 \n",
      "\n",
      "loss: 2.756922  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 13.166038 \n",
      "\n",
      "loss: 13.381470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 15.709274 \n",
      "\n",
      "loss: 16.408358  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.168678 \n",
      "\n",
      "loss: 5.856774  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.510408 \n",
      "\n",
      "loss: 2.436871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 5.220769 \n",
      "\n",
      "loss: 4.874760  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 12.016143 \n",
      "\n",
      "loss: 12.172581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 17.801649 \n",
      "\n",
      "loss: 19.206573  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 19.557375 \n",
      "\n",
      "loss: 18.815546  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 7.668382 \n",
      "\n",
      "loss: 7.848469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 5.378682 \n",
      "\n",
      "loss: 5.716790  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 6.628861 \n",
      "\n",
      "loss: 6.570764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 16.777267 \n",
      "\n",
      "loss: 17.301680  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 4.795549 \n",
      "\n",
      "loss: 4.526514  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.347889 \n",
      "\n",
      "loss: 5.369033  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 13.480147 \n",
      "\n",
      "loss: 13.286930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 12.748837 \n",
      "\n",
      "loss: 13.216510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.275288 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 316/500\n",
      "--------------------\n",
      "{'hl': [231, 600, 82], 'alpha': 0.00015176066150268653, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.2706276356895448}\n",
      "loss: 1.060948  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.457895 \n",
      "\n",
      "loss: 0.488535  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.547209 \n",
      "\n",
      "loss: 0.573799  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.424000 \n",
      "\n",
      "loss: 0.420619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.370738 \n",
      "\n",
      "loss: 0.426837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.355572 \n",
      "\n",
      "loss: 0.387715  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.351035 \n",
      "\n",
      "loss: 0.375934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.358431 \n",
      "\n",
      "loss: 0.366047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.363134 \n",
      "\n",
      "loss: 0.330348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.343502 \n",
      "\n",
      "loss: 0.332070  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.354528 \n",
      "\n",
      "loss: 0.396140  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.330637 \n",
      "\n",
      "loss: 0.324294  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.323925 \n",
      "\n",
      "loss: 0.325387  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.302879 \n",
      "\n",
      "loss: 0.274587  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.326142 \n",
      "\n",
      "loss: 0.341245  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.308945 \n",
      "\n",
      "loss: 0.315795  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.311314 \n",
      "\n",
      "loss: 0.317112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.391704 \n",
      "\n",
      "loss: 0.335567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.304385 \n",
      "\n",
      "loss: 0.288382  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.291700 \n",
      "\n",
      "loss: 0.290565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.295757 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 317/500\n",
      "--------------------\n",
      "{'hl': [78], 'alpha': 0.8801343931739282, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.1436166443749709}\n",
      "loss: 1.284581  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.834802 \n",
      "\n",
      "loss: 0.830750  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.842251 \n",
      "\n",
      "loss: 0.844799  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.836814 \n",
      "\n",
      "loss: 0.839947  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.830540 \n",
      "\n",
      "loss: 0.838377  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.831127 \n",
      "\n",
      "loss: 0.851139  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.835098 \n",
      "\n",
      "loss: 0.841167  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.847336 \n",
      "\n",
      "loss: 0.843056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.832585 \n",
      "\n",
      "loss: 0.831747  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.827689 \n",
      "\n",
      "loss: 0.817953  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.834637 \n",
      "\n",
      "loss: 0.843015  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.834657 \n",
      "\n",
      "loss: 0.842456  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.845961 \n",
      "\n",
      "loss: 0.831900  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.836790 \n",
      "\n",
      "loss: 0.821742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.843585 \n",
      "\n",
      "loss: 0.853985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.845300 \n",
      "\n",
      "loss: 0.832118  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.837631 \n",
      "\n",
      "loss: 0.860060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.839796 \n",
      "\n",
      "loss: 0.846393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.833948 \n",
      "\n",
      "loss: 0.849249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.841698 \n",
      "\n",
      "loss: 0.832132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.837323 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 318/500\n",
      "--------------------\n",
      "{'hl': [146], 'alpha': 0.11569397204999339, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4964290136305814}\n",
      "loss: 1.102017  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 1.797572 \n",
      "\n",
      "loss: 1.993321  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.983954 \n",
      "\n",
      "loss: 1.960919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.998848 \n",
      "\n",
      "loss: 0.932268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 2.125231 \n",
      "\n",
      "loss: 2.229660  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 1.421461 \n",
      "\n",
      "loss: 1.513211  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.631662 \n",
      "\n",
      "loss: 3.719031  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.177516 \n",
      "\n",
      "loss: 2.951363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.736371 \n",
      "\n",
      "loss: 0.726471  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.608275 \n",
      "\n",
      "loss: 1.609526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.958109 \n",
      "\n",
      "loss: 1.062767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 1.073457 \n",
      "\n",
      "loss: 1.170829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 2.772350 \n",
      "\n",
      "loss: 2.728067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.785058 \n",
      "\n",
      "loss: 0.770455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.6%, Avg loss: 2.343568 \n",
      "\n",
      "loss: 2.437007  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.673605 \n",
      "\n",
      "loss: 0.742076  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.087165 \n",
      "\n",
      "loss: 1.070083  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 1.196475 \n",
      "\n",
      "loss: 1.120756  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 4.049847 \n",
      "\n",
      "loss: 4.273827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 3.286760 \n",
      "\n",
      "loss: 3.165704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 6.1%, Avg loss: 4.206579 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 319/500\n",
      "--------------------\n",
      "{'hl': [467, 394], 'alpha': 0.003181135258257364, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.05940472032590929}\n",
      "loss: 1.112748  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.942339 \n",
      "\n",
      "loss: 0.974263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.927948 \n",
      "\n",
      "loss: 0.948724  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.585900 \n",
      "\n",
      "loss: 0.622330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.498986 \n",
      "\n",
      "loss: 0.523522  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.410884 \n",
      "\n",
      "loss: 0.480159  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.494883 \n",
      "\n",
      "loss: 0.477063  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.433941 \n",
      "\n",
      "loss: 0.441000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.119904 \n",
      "\n",
      "loss: 1.045884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.557762 \n",
      "\n",
      "loss: 0.561793  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.607363 \n",
      "\n",
      "loss: 0.602030  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.227737 \n",
      "\n",
      "loss: 1.147672  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.908187 \n",
      "\n",
      "loss: 0.897229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 1.649181 \n",
      "\n",
      "loss: 1.680195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.143371 \n",
      "\n",
      "loss: 1.078709  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.489000 \n",
      "\n",
      "loss: 0.493665  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.440824 \n",
      "\n",
      "loss: 0.434011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.416311 \n",
      "\n",
      "loss: 0.415810  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.419364 \n",
      "\n",
      "loss: 0.395886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.604617 \n",
      "\n",
      "loss: 0.612781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.806046 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 320/500\n",
      "--------------------\n",
      "{'hl': [410, 549, 138], 'alpha': 0.08155161455904357, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3781140894879802}\n",
      "loss: 1.128132  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.523801 \n",
      "\n",
      "loss: 0.518012  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.539174 \n",
      "\n",
      "loss: 0.550930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.526059 \n",
      "\n",
      "loss: 0.524481  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.519233 \n",
      "\n",
      "loss: 0.509113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.521176 \n",
      "\n",
      "loss: 0.561858  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.536378 \n",
      "\n",
      "loss: 0.476254  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.527771 \n",
      "\n",
      "loss: 0.539606  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.533869 \n",
      "\n",
      "loss: 0.522720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.523983 \n",
      "\n",
      "loss: 0.557495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.535269 \n",
      "\n",
      "loss: 0.533942  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.527329 \n",
      "\n",
      "loss: 0.524562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.539339 \n",
      "\n",
      "loss: 0.519753  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.533753 \n",
      "\n",
      "loss: 0.518260  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.522212 \n",
      "\n",
      "loss: 0.488689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.531325 \n",
      "\n",
      "loss: 0.527242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.529035 \n",
      "\n",
      "loss: 0.577134  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.541060 \n",
      "\n",
      "loss: 0.531804  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.538292 \n",
      "\n",
      "loss: 0.535154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.529631 \n",
      "\n",
      "loss: 0.529976  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.533255 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 321/500\n",
      "--------------------\n",
      "{'hl': [482, 697], 'alpha': 0.0752273736703334, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4116978826441546}\n",
      "loss: 1.131567  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 15.307135 \n",
      "\n",
      "loss: 15.312463  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 7.219415 \n",
      "\n",
      "loss: 7.126415  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 21.851864 \n",
      "\n",
      "loss: 22.163820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.859437 \n",
      "\n",
      "loss: 5.106825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 42.396823 \n",
      "\n",
      "loss: 41.359787  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 35.838861 \n",
      "\n",
      "loss: 35.818832  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 57.917235 \n",
      "\n",
      "loss: 55.524860  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 19.755273 \n",
      "\n",
      "loss: 20.189354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 54.607430 \n",
      "\n",
      "loss: 55.930069  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 56.184785 \n",
      "\n",
      "loss: 55.275253  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 39.852138 \n",
      "\n",
      "loss: 37.722698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 21.698744 \n",
      "\n",
      "loss: 21.307411  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 76.345858 \n",
      "\n",
      "loss: 73.435715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 66.259935 \n",
      "\n",
      "loss: 69.176315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 21.777464 \n",
      "\n",
      "loss: 21.554140  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 30.382497 \n",
      "\n",
      "loss: 31.388784  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 13.968925 \n",
      "\n",
      "loss: 14.085752  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 32.079400 \n",
      "\n",
      "loss: 32.707264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 23.857922 \n",
      "\n",
      "loss: 24.259659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 18.189356 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 322/500\n",
      "--------------------\n",
      "{'hl': [479], 'alpha': 0.002424593519015822, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4687114395314199}\n",
      "loss: 1.147096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.426239 \n",
      "\n",
      "loss: 0.453557  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.397671 \n",
      "\n",
      "loss: 0.385758  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.387950 \n",
      "\n",
      "loss: 0.352558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.402389 \n",
      "\n",
      "loss: 0.419958  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.346976 \n",
      "\n",
      "loss: 0.323416  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.346383 \n",
      "\n",
      "loss: 0.338387  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.361976 \n",
      "\n",
      "loss: 0.375287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.349215 \n",
      "\n",
      "loss: 0.385635  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.345206 \n",
      "\n",
      "loss: 0.330321  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.333329 \n",
      "\n",
      "loss: 0.361584  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.330669 \n",
      "\n",
      "loss: 0.334631  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.324335 \n",
      "\n",
      "loss: 0.300803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.320695 \n",
      "\n",
      "loss: 0.342221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.340274 \n",
      "\n",
      "loss: 0.350960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.310993 \n",
      "\n",
      "loss: 0.365397  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.317711 \n",
      "\n",
      "loss: 0.316451  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.316574 \n",
      "\n",
      "loss: 0.346376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.335419 \n",
      "\n",
      "loss: 0.343174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.333995 \n",
      "\n",
      "loss: 0.345648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.306170 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 323/500\n",
      "--------------------\n",
      "{'hl': [123, 40, 684], 'alpha': 0.004752940679289974, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.10312020276292207}\n",
      "loss: 1.079242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.521940 \n",
      "\n",
      "loss: 0.533036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.488746 \n",
      "\n",
      "loss: 0.484754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.462027 \n",
      "\n",
      "loss: 0.449176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.412887 \n",
      "\n",
      "loss: 0.420980  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.395683 \n",
      "\n",
      "loss: 0.443282  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.396319 \n",
      "\n",
      "loss: 0.387636  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.399343 \n",
      "\n",
      "loss: 0.373160  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.383115 \n",
      "\n",
      "loss: 0.390594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.377941 \n",
      "\n",
      "loss: 0.421819  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.361443 \n",
      "\n",
      "loss: 0.364928  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.361256 \n",
      "\n",
      "loss: 0.358778  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360179 \n",
      "\n",
      "loss: 0.372825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.347096 \n",
      "\n",
      "loss: 0.318326  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.351098 \n",
      "\n",
      "loss: 0.363787  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.323717 \n",
      "\n",
      "loss: 0.358029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.332953 \n",
      "\n",
      "loss: 0.366979  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.345065 \n",
      "\n",
      "loss: 0.344778  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.329665 \n",
      "\n",
      "loss: 0.380354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.331525 \n",
      "\n",
      "loss: 0.300561  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.325463 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 324/500\n",
      "--------------------\n",
      "{'hl': [616], 'alpha': 0.00013624014683327263, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3702964851320828}\n",
      "loss: 1.060843  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.444281 \n",
      "\n",
      "loss: 0.437861  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.397799 \n",
      "\n",
      "loss: 0.432982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.421076 \n",
      "\n",
      "loss: 0.399164  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.365726 \n",
      "\n",
      "loss: 0.406977  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.373940 \n",
      "\n",
      "loss: 0.336001  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.340906 \n",
      "\n",
      "loss: 0.329608  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.351254 \n",
      "\n",
      "loss: 0.330701  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.348957 \n",
      "\n",
      "loss: 0.321525  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387938 \n",
      "\n",
      "loss: 0.451587  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.328486 \n",
      "\n",
      "loss: 0.356056  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.317246 \n",
      "\n",
      "loss: 0.298103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.364764 \n",
      "\n",
      "loss: 0.345954  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.311544 \n",
      "\n",
      "loss: 0.299224  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.332948 \n",
      "\n",
      "loss: 0.330701  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.298018 \n",
      "\n",
      "loss: 0.294483  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.301053 \n",
      "\n",
      "loss: 0.307388  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.312886 \n",
      "\n",
      "loss: 0.274927  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.330036 \n",
      "\n",
      "loss: 0.303186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.306431 \n",
      "\n",
      "loss: 0.283060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.281757 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 325/500\n",
      "--------------------\n",
      "{'hl': [457, 247], 'alpha': 0.014422456429798365, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2519975348855732}\n",
      "loss: 1.113882  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.472507 \n",
      "\n",
      "loss: 0.440076  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.443338 \n",
      "\n",
      "loss: 0.427787  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.424415 \n",
      "\n",
      "loss: 0.408142  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.385276 \n",
      "\n",
      "loss: 0.401496  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.387164 \n",
      "\n",
      "loss: 0.405010  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.375564 \n",
      "\n",
      "loss: 0.373829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.375956 \n",
      "\n",
      "loss: 0.373699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.381154 \n",
      "\n",
      "loss: 0.363899  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.366648 \n",
      "\n",
      "loss: 0.354458  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.350463 \n",
      "\n",
      "loss: 0.340779  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364504 \n",
      "\n",
      "loss: 0.332654  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.377418 \n",
      "\n",
      "loss: 0.386208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.377825 \n",
      "\n",
      "loss: 0.362342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.394480 \n",
      "\n",
      "loss: 0.367720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.352881 \n",
      "\n",
      "loss: 0.364688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.360483 \n",
      "\n",
      "loss: 0.367293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.378631 \n",
      "\n",
      "loss: 0.370397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.356467 \n",
      "\n",
      "loss: 0.350810  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.354648 \n",
      "\n",
      "loss: 0.339738  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.357758 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 326/500\n",
      "--------------------\n",
      "{'hl': [247, 597], 'alpha': 0.0018863174635934015, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.1509520411285872}\n",
      "loss: 1.092013  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.499127 \n",
      "\n",
      "loss: 0.481469  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.457614 \n",
      "\n",
      "loss: 0.449793  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.429710 \n",
      "\n",
      "loss: 0.459059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.409325 \n",
      "\n",
      "loss: 0.428574  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.390526 \n",
      "\n",
      "loss: 0.404835  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.392229 \n",
      "\n",
      "loss: 0.372016  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.383338 \n",
      "\n",
      "loss: 0.340152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.367127 \n",
      "\n",
      "loss: 0.365417  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.353308 \n",
      "\n",
      "loss: 0.331643  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.350238 \n",
      "\n",
      "loss: 0.405055  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.356451 \n",
      "\n",
      "loss: 0.353017  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.336871 \n",
      "\n",
      "loss: 0.332959  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.352216 \n",
      "\n",
      "loss: 0.375603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.346940 \n",
      "\n",
      "loss: 0.344905  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.327848 \n",
      "\n",
      "loss: 0.314202  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.330320 \n",
      "\n",
      "loss: 0.309125  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.345362 \n",
      "\n",
      "loss: 0.343182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.324629 \n",
      "\n",
      "loss: 0.378148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.350881 \n",
      "\n",
      "loss: 0.354467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.310362 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 327/500\n",
      "--------------------\n",
      "{'hl': [684], 'alpha': 0.012161978100385608, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.13764944486225184}\n",
      "loss: 1.172908  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 1.539450 \n",
      "\n",
      "loss: 1.533745  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.554510 \n",
      "\n",
      "loss: 1.585216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 2.528917 \n",
      "\n",
      "loss: 2.524640  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 2.137952 \n",
      "\n",
      "loss: 2.124598  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.853981 \n",
      "\n",
      "loss: 1.672666  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 1.235247 \n",
      "\n",
      "loss: 1.282796  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 3.180661 \n",
      "\n",
      "loss: 3.338531  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 2.118079 \n",
      "\n",
      "loss: 2.093967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 1.711768 \n",
      "\n",
      "loss: 1.730638  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 1.112771 \n",
      "\n",
      "loss: 1.131579  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.835443 \n",
      "\n",
      "loss: 1.841188  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 2.422228 \n",
      "\n",
      "loss: 2.135626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 3.609013 \n",
      "\n",
      "loss: 3.483024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 1.825033 \n",
      "\n",
      "loss: 1.904212  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 3.199861 \n",
      "\n",
      "loss: 3.087287  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 1.461027 \n",
      "\n",
      "loss: 1.577074  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 4.454903 \n",
      "\n",
      "loss: 4.040051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 3.286710 \n",
      "\n",
      "loss: 3.375005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 1.676005 \n",
      "\n",
      "loss: 1.803211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.842926 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 328/500\n",
      "--------------------\n",
      "{'hl': [613, 187, 649], 'alpha': 0.051880062803106634, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.48614788864830855}\n",
      "loss: 1.179389  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.094456 \n",
      "\n",
      "loss: 1.146009  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.284962 \n",
      "\n",
      "loss: 1.283571  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.290640 \n",
      "\n",
      "loss: 1.311178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.180886 \n",
      "\n",
      "loss: 1.146996  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.090177 \n",
      "\n",
      "loss: 1.112314  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.240886 \n",
      "\n",
      "loss: 1.210544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.117641 \n",
      "\n",
      "loss: 1.103062  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.066486 \n",
      "\n",
      "loss: 1.116409  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.252595 \n",
      "\n",
      "loss: 1.263594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.114900 \n",
      "\n",
      "loss: 1.182640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.041794 \n",
      "\n",
      "loss: 0.996136  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.229721 \n",
      "\n",
      "loss: 1.231807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.067512 \n",
      "\n",
      "loss: 1.101600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.170017 \n",
      "\n",
      "loss: 1.196958  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.049102 \n",
      "\n",
      "loss: 1.098678  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.119005 \n",
      "\n",
      "loss: 1.113517  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.057024 \n",
      "\n",
      "loss: 1.113274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.247059 \n",
      "\n",
      "loss: 1.273390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.309258 \n",
      "\n",
      "loss: 1.361669  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.114479 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 329/500\n",
      "--------------------\n",
      "{'hl': [695, 398, 545], 'alpha': 0.001883379458004731, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.07469388215179933}\n",
      "loss: 1.149528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.434395 \n",
      "\n",
      "loss: 1.353435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 4.290375 \n",
      "\n",
      "loss: 4.295049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.301910 \n",
      "\n",
      "loss: 3.077042  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 1.569187 \n",
      "\n",
      "loss: 1.530052  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.488823 \n",
      "\n",
      "loss: 1.536275  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.206852 \n",
      "\n",
      "loss: 2.158368  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.648345 \n",
      "\n",
      "loss: 2.480330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.844641 \n",
      "\n",
      "loss: 0.831324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.018120 \n",
      "\n",
      "loss: 1.013429  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.866906 \n",
      "\n",
      "loss: 0.882893  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.834139 \n",
      "\n",
      "loss: 0.812708  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.892520 \n",
      "\n",
      "loss: 0.904719  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.840577 \n",
      "\n",
      "loss: 0.864623  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.402758 \n",
      "\n",
      "loss: 1.406388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.375179 \n",
      "\n",
      "loss: 1.296883  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.976303 \n",
      "\n",
      "loss: 0.974464  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.857729 \n",
      "\n",
      "loss: 0.862108  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.832614 \n",
      "\n",
      "loss: 0.872015  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.083850 \n",
      "\n",
      "loss: 1.099990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.857375 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 330/500\n",
      "--------------------\n",
      "{'hl': [196, 558], 'alpha': 0.007835654561134338, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.428784865162653}\n",
      "loss: 1.100951  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 10.007295 \n",
      "\n",
      "loss: 9.713598  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 10.397890 \n",
      "\n",
      "loss: 10.414339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 5.115577 \n",
      "\n",
      "loss: 4.711825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 6.526725 \n",
      "\n",
      "loss: 7.172132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 23.988248 \n",
      "\n",
      "loss: 25.064970  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 13.697762 \n",
      "\n",
      "loss: 13.670744  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 14.098798 \n",
      "\n",
      "loss: 11.850371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 4.611491 \n",
      "\n",
      "loss: 4.805152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 7.267604 \n",
      "\n",
      "loss: 7.927317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 7.629437 \n",
      "\n",
      "loss: 7.946713  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 9.802710 \n",
      "\n",
      "loss: 10.258214  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 7.084457 \n",
      "\n",
      "loss: 6.942434  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 10.687370 \n",
      "\n",
      "loss: 10.285748  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 8.645656 \n",
      "\n",
      "loss: 9.129047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 7.311426 \n",
      "\n",
      "loss: 7.886207  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 10.865966 \n",
      "\n",
      "loss: 11.323174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 13.564702 \n",
      "\n",
      "loss: 13.583858  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 22.014027 \n",
      "\n",
      "loss: 22.177366  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 6.667273 \n",
      "\n",
      "loss: 6.727825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 4.653390 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 331/500\n",
      "--------------------\n",
      "{'hl': [482], 'alpha': 0.4559998452322971, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2786876504238166}\n",
      "loss: 1.005770  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.613705 \n",
      "\n",
      "loss: 11.930103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 13.387143 \n",
      "\n",
      "loss: 12.985982  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.189891 \n",
      "\n",
      "loss: 2.220615  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.829157 \n",
      "\n",
      "loss: 1.647379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.761426 \n",
      "\n",
      "loss: 2.396655  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 6.208646 \n",
      "\n",
      "loss: 6.346903  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 8.202178 \n",
      "\n",
      "loss: 8.477067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.562861 \n",
      "\n",
      "loss: 3.736245  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 8.970090 \n",
      "\n",
      "loss: 9.211271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 11.143103 \n",
      "\n",
      "loss: 10.583429  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.708880 \n",
      "\n",
      "loss: 11.862826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.348950 \n",
      "\n",
      "loss: 5.145516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 5.479226 \n",
      "\n",
      "loss: 5.444315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 7.868036 \n",
      "\n",
      "loss: 7.933806  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.910972 \n",
      "\n",
      "loss: 3.864522  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.638995 \n",
      "\n",
      "loss: 1.817508  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.905469 \n",
      "\n",
      "loss: 2.005435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.336943 \n",
      "\n",
      "loss: 2.368699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 10.311252 \n",
      "\n",
      "loss: 10.879972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.233559 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 332/500\n",
      "--------------------\n",
      "{'hl': [405], 'alpha': 0.0009363410515328106, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.32338825518881753}\n",
      "loss: 1.157688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 3.270198 \n",
      "\n",
      "loss: 3.238726  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.807152 \n",
      "\n",
      "loss: 1.742384  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.512428 \n",
      "\n",
      "loss: 1.498288  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 1.101130 \n",
      "\n",
      "loss: 1.255930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 2.126788 \n",
      "\n",
      "loss: 2.142454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 1.907857 \n",
      "\n",
      "loss: 1.966446  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 1.949872 \n",
      "\n",
      "loss: 1.702966  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 4.632383 \n",
      "\n",
      "loss: 4.463424  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 3.424836 \n",
      "\n",
      "loss: 3.612471  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.0%, Avg loss: 2.627670 \n",
      "\n",
      "loss: 2.786693  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 1.505799 \n",
      "\n",
      "loss: 1.476844  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 3.461659 \n",
      "\n",
      "loss: 3.532249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 3.542623 \n",
      "\n",
      "loss: 3.118847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 2.943412 \n",
      "\n",
      "loss: 2.922542  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 2.005291 \n",
      "\n",
      "loss: 1.960955  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 2.185078 \n",
      "\n",
      "loss: 2.484033  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 2.232936 \n",
      "\n",
      "loss: 2.133569  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 2.484199 \n",
      "\n",
      "loss: 2.355137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 2.078330 \n",
      "\n",
      "loss: 2.364557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 2.277925 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 333/500\n",
      "--------------------\n",
      "{'hl': [387, 102], 'alpha': 0.013884880469146373, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.1343039477687051}\n",
      "loss: 1.125469  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.520468 \n",
      "\n",
      "loss: 0.536182  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.493043 \n",
      "\n",
      "loss: 0.465810  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.469406 \n",
      "\n",
      "loss: 0.460759  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.470342 \n",
      "\n",
      "loss: 0.487176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.453878 \n",
      "\n",
      "loss: 0.453934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.453394 \n",
      "\n",
      "loss: 0.448086  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.458665 \n",
      "\n",
      "loss: 0.447712  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.455039 \n",
      "\n",
      "loss: 0.438046  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.456761 \n",
      "\n",
      "loss: 0.455990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.448046 \n",
      "\n",
      "loss: 0.427800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.436335 \n",
      "\n",
      "loss: 0.447333  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.460864 \n",
      "\n",
      "loss: 0.456016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.443798 \n",
      "\n",
      "loss: 0.448066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.430952 \n",
      "\n",
      "loss: 0.414867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.431617 \n",
      "\n",
      "loss: 0.420267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.428951 \n",
      "\n",
      "loss: 0.425081  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.439600 \n",
      "\n",
      "loss: 0.423961  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.438819 \n",
      "\n",
      "loss: 0.428994  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.418583 \n",
      "\n",
      "loss: 0.427985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.410500 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 334/500\n",
      "--------------------\n",
      "{'hl': [627, 625, 48], 'alpha': 0.31223517990843624, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.2397491638148103}\n",
      "loss: 1.043830  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.707195 \n",
      "\n",
      "loss: 0.700266  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.704126 \n",
      "\n",
      "loss: 0.701823  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.693191 \n",
      "\n",
      "loss: 0.690612  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.694886 \n",
      "\n",
      "loss: 0.700632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.691172 \n",
      "\n",
      "loss: 0.694521  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.695133 \n",
      "\n",
      "loss: 0.687909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.707933 \n",
      "\n",
      "loss: 0.702333  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.694125 \n",
      "\n",
      "loss: 0.660903  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.687721 \n",
      "\n",
      "loss: 0.682820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.690585 \n",
      "\n",
      "loss: 0.696215  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.691008 \n",
      "\n",
      "loss: 0.660819  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.695714 \n",
      "\n",
      "loss: 0.677711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.698667 \n",
      "\n",
      "loss: 0.703957  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.704874 \n",
      "\n",
      "loss: 0.711241  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.689562 \n",
      "\n",
      "loss: 0.709997  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.699854 \n",
      "\n",
      "loss: 0.689665  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.692288 \n",
      "\n",
      "loss: 0.710808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.691440 \n",
      "\n",
      "loss: 0.688949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.690207 \n",
      "\n",
      "loss: 0.700102  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.690446 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 335/500\n",
      "--------------------\n",
      "{'hl': [318, 23], 'alpha': 0.0007034465243790329, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.37346492580537527}\n",
      "loss: 1.063140  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.473576 \n",
      "\n",
      "loss: 0.469897  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.453372 \n",
      "\n",
      "loss: 0.439023  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.545336 \n",
      "\n",
      "loss: 0.487602  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.413115 \n",
      "\n",
      "loss: 0.388703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.388353 \n",
      "\n",
      "loss: 0.395179  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.400472 \n",
      "\n",
      "loss: 0.386243  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.394138 \n",
      "\n",
      "loss: 0.398076  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.372862 \n",
      "\n",
      "loss: 0.403306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.383058 \n",
      "\n",
      "loss: 0.369841  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.365152 \n",
      "\n",
      "loss: 0.365623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.358979 \n",
      "\n",
      "loss: 0.383836  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.373314 \n",
      "\n",
      "loss: 0.342627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.365489 \n",
      "\n",
      "loss: 0.374205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.361196 \n",
      "\n",
      "loss: 0.336950  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.363584 \n",
      "\n",
      "loss: 0.374227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.341166 \n",
      "\n",
      "loss: 0.311380  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.335188 \n",
      "\n",
      "loss: 0.301556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.344554 \n",
      "\n",
      "loss: 0.376183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.327143 \n",
      "\n",
      "loss: 0.322394  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.353135 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 336/500\n",
      "--------------------\n",
      "{'hl': [256, 720], 'alpha': 0.026158096422466668, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.45757171715081885}\n",
      "loss: 1.079614  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 10.948122 \n",
      "\n",
      "loss: 11.177787  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 7.869319 \n",
      "\n",
      "loss: 7.428132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 6.385565 \n",
      "\n",
      "loss: 5.652514  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 8.755607 \n",
      "\n",
      "loss: 10.132518  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 19.650141 \n",
      "\n",
      "loss: 18.413363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 14.464056 \n",
      "\n",
      "loss: 14.150695  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 16.302326 \n",
      "\n",
      "loss: 16.574230  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 12.149997 \n",
      "\n",
      "loss: 12.144640  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 25.922401 \n",
      "\n",
      "loss: 26.085003  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 38.598393 \n",
      "\n",
      "loss: 38.315430  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 6.403168 \n",
      "\n",
      "loss: 6.173171  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 25.214379 \n",
      "\n",
      "loss: 23.362873  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 28.020115 \n",
      "\n",
      "loss: 27.750433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 20.852957 \n",
      "\n",
      "loss: 20.128326  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 10.867469 \n",
      "\n",
      "loss: 11.695370  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 24.974523 \n",
      "\n",
      "loss: 26.645325  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 7.605554 \n",
      "\n",
      "loss: 7.267177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 15.547272 \n",
      "\n",
      "loss: 14.934967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 20.574759 \n",
      "\n",
      "loss: 20.708366  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 9.904424 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 337/500\n",
      "--------------------\n",
      "{'hl': [337, 297, 397], 'alpha': 0.007328276436521289, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.13085465752993775}\n",
      "loss: 1.090791  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 42.6%, Avg loss: 697.158956 \n",
      "\n",
      "loss: 755.345825  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 98.640097 \n",
      "\n",
      "loss: 102.390182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 7.464421 \n",
      "\n",
      "loss: 8.740316  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 1.851952 \n",
      "\n",
      "loss: 2.296801  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.519456 \n",
      "\n",
      "loss: 0.564542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.423687 \n",
      "\n",
      "loss: 0.437414  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.424819 \n",
      "\n",
      "loss: 0.407811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.420261 \n",
      "\n",
      "loss: 0.370869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.397108 \n",
      "\n",
      "loss: 0.410906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.389211 \n",
      "\n",
      "loss: 0.424072  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.373463 \n",
      "\n",
      "loss: 0.345221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.385162 \n",
      "\n",
      "loss: 0.347153  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.368663 \n",
      "\n",
      "loss: 0.354922  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.348634 \n",
      "\n",
      "loss: 0.365912  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.338641 \n",
      "\n",
      "loss: 0.338738  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.341988 \n",
      "\n",
      "loss: 0.333820  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.357840 \n",
      "\n",
      "loss: 0.334869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.348478 \n",
      "\n",
      "loss: 0.344649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.330808 \n",
      "\n",
      "loss: 0.346092  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.329059 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 338/500\n",
      "--------------------\n",
      "{'hl': [517, 485, 108], 'alpha': 0.1626546514220818, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4571738163988548}\n",
      "loss: 1.119993  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.838819 \n",
      "\n",
      "loss: 2.855656  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 4.294766 \n",
      "\n",
      "loss: 3.950734  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.122124 \n",
      "\n",
      "loss: 1.089050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 8.369769 \n",
      "\n",
      "loss: 8.062145  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 3.920708 \n",
      "\n",
      "loss: 4.027206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.934485 \n",
      "\n",
      "loss: 0.950696  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.997693 \n",
      "\n",
      "loss: 1.021027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.479468 \n",
      "\n",
      "loss: 2.472135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.629502 \n",
      "\n",
      "loss: 3.769680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.847455 \n",
      "\n",
      "loss: 1.824024  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.949531 \n",
      "\n",
      "loss: 3.949848  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 5.336260 \n",
      "\n",
      "loss: 4.856342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 4.639694 \n",
      "\n",
      "loss: 4.753227  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.715237 \n",
      "\n",
      "loss: 2.652932  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 3.588824 \n",
      "\n",
      "loss: 3.591596  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 4.887050 \n",
      "\n",
      "loss: 4.674115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.733017 \n",
      "\n",
      "loss: 3.856364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.415722 \n",
      "\n",
      "loss: 1.426205  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.138873 \n",
      "\n",
      "loss: 2.289693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.618069 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 339/500\n",
      "--------------------\n",
      "{'hl': [328, 431], 'alpha': 0.00015235678227319636, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.00820832851053011}\n",
      "loss: 1.083646  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.792028 \n",
      "\n",
      "loss: 0.801581  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.678776 \n",
      "\n",
      "loss: 0.694645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.635553 \n",
      "\n",
      "loss: 0.626697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.585785 \n",
      "\n",
      "loss: 0.598221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.575632 \n",
      "\n",
      "loss: 0.592200  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.579924 \n",
      "\n",
      "loss: 0.556537  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.544699 \n",
      "\n",
      "loss: 0.581432  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.547073 \n",
      "\n",
      "loss: 0.515648  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.539532 \n",
      "\n",
      "loss: 0.524356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.527650 \n",
      "\n",
      "loss: 0.519441  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.530173 \n",
      "\n",
      "loss: 0.525860  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.518571 \n",
      "\n",
      "loss: 0.523913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.522890 \n",
      "\n",
      "loss: 0.489649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.490766 \n",
      "\n",
      "loss: 0.498689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.509392 \n",
      "\n",
      "loss: 0.439796  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.489277 \n",
      "\n",
      "loss: 0.459522  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.502187 \n",
      "\n",
      "loss: 0.494038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.496336 \n",
      "\n",
      "loss: 0.473471  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.496928 \n",
      "\n",
      "loss: 0.492455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.499776 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 340/500\n",
      "--------------------\n",
      "{'hl': [606, 601, 435], 'alpha': 0.0015162441910426053, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.11508631113903149}\n",
      "loss: 1.093019  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 2.425543 \n",
      "\n",
      "loss: 2.180512  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 1.013017 \n",
      "\n",
      "loss: 1.039132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 2.697401 \n",
      "\n",
      "loss: 2.587469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 1.065312 \n",
      "\n",
      "loss: 1.105929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.862531 \n",
      "\n",
      "loss: 0.885305  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 1.038319 \n",
      "\n",
      "loss: 1.072967  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 2.715635 \n",
      "\n",
      "loss: 2.741278  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 1.108831 \n",
      "\n",
      "loss: 1.021630  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 1.379318 \n",
      "\n",
      "loss: 1.430304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 1.419955 \n",
      "\n",
      "loss: 1.468051  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 2.043855 \n",
      "\n",
      "loss: 2.252548  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 1.353657 \n",
      "\n",
      "loss: 1.409914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 21.8%, Avg loss: 3.337998 \n",
      "\n",
      "loss: 3.318979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.333491 \n",
      "\n",
      "loss: 1.406505  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 1.784535 \n",
      "\n",
      "loss: 1.783883  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 1.138927 \n",
      "\n",
      "loss: 1.080291  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.592858 \n",
      "\n",
      "loss: 0.617828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.932043 \n",
      "\n",
      "loss: 0.957114  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 1.067611 \n",
      "\n",
      "loss: 1.220719  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.674986 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 341/500\n",
      "--------------------\n",
      "{'hl': [259, 519, 571], 'alpha': 0.04153668801240474, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.38170397677059326}\n",
      "loss: 1.090462  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 11204.452148 \n",
      "\n",
      "loss: 9807.264648  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 4273.796088 \n",
      "\n",
      "loss: 4699.322266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 287.744273 \n",
      "\n",
      "loss: 341.678345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 123.474114 \n",
      "\n",
      "loss: 114.064041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 58.882752 \n",
      "\n",
      "loss: 80.870758  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 27.897185 \n",
      "\n",
      "loss: 29.031658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 30.990712 \n",
      "\n",
      "loss: 25.625647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 249.450507 \n",
      "\n",
      "loss: 213.316269  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 25.368089 \n",
      "\n",
      "loss: 23.307390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 7.310447 \n",
      "\n",
      "loss: 6.908659  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 5.823656 \n",
      "\n",
      "loss: 7.522135  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 4.001086 \n",
      "\n",
      "loss: 4.053265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 2.352890 \n",
      "\n",
      "loss: 1.834790  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 8.869076 \n",
      "\n",
      "loss: 7.348032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.849064 \n",
      "\n",
      "loss: 1.913854  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 13.781147 \n",
      "\n",
      "loss: 17.135660  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 3.444419 \n",
      "\n",
      "loss: 2.441938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 9.298890 \n",
      "\n",
      "loss: 8.656896  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 1.059055 \n",
      "\n",
      "loss: 0.977668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.739376 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 342/500\n",
      "--------------------\n",
      "{'hl': [665, 510], 'alpha': 0.006971335658151538, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.07006526843745059}\n",
      "loss: 1.102639  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.533579 \n",
      "\n",
      "loss: 0.528440  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.498803 \n",
      "\n",
      "loss: 0.499383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.470780 \n",
      "\n",
      "loss: 0.457824  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.441408 \n",
      "\n",
      "loss: 0.472133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.428421 \n",
      "\n",
      "loss: 0.466904  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.441352 \n",
      "\n",
      "loss: 0.416663  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.430677 \n",
      "\n",
      "loss: 0.460596  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.422950 \n",
      "\n",
      "loss: 0.451721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.393421 \n",
      "\n",
      "loss: 0.403420  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.385165 \n",
      "\n",
      "loss: 0.374573  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.386633 \n",
      "\n",
      "loss: 0.397093  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.386953 \n",
      "\n",
      "loss: 0.382373  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.382757 \n",
      "\n",
      "loss: 0.365441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.378003 \n",
      "\n",
      "loss: 0.389561  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.378611 \n",
      "\n",
      "loss: 0.376341  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.365739 \n",
      "\n",
      "loss: 0.383562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.377748 \n",
      "\n",
      "loss: 0.363990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.355376 \n",
      "\n",
      "loss: 0.356433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364828 \n",
      "\n",
      "loss: 0.386885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.366455 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 343/500\n",
      "--------------------\n",
      "{'hl': [508, 196, 563], 'alpha': 0.914732613503554, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.41955033994811786}\n",
      "loss: 1.097277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.003388 \n",
      "\n",
      "loss: 1.007632  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.004955 \n",
      "\n",
      "loss: 1.004566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.000576 \n",
      "\n",
      "loss: 1.004931  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.002976 \n",
      "\n",
      "loss: 1.001024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.001867 \n",
      "\n",
      "loss: 1.004607  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.999048 \n",
      "\n",
      "loss: 1.001033  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.002255 \n",
      "\n",
      "loss: 1.000150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.999616 \n",
      "\n",
      "loss: 1.004974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.000850 \n",
      "\n",
      "loss: 1.002336  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.003238 \n",
      "\n",
      "loss: 1.007478  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.003935 \n",
      "\n",
      "loss: 1.002968  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.002282 \n",
      "\n",
      "loss: 0.996311  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.000165 \n",
      "\n",
      "loss: 1.001738  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.003361 \n",
      "\n",
      "loss: 1.002652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.000657 \n",
      "\n",
      "loss: 1.001576  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.998358 \n",
      "\n",
      "loss: 1.001442  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.001220 \n",
      "\n",
      "loss: 1.002455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.000826 \n",
      "\n",
      "loss: 1.006360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.999873 \n",
      "\n",
      "loss: 0.997763  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.999191 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 344/500\n",
      "--------------------\n",
      "{'hl': [692], 'alpha': 0.0001563354891378239, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.0688320160954304}\n",
      "loss: 1.049683  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 4.212103 \n",
      "\n",
      "loss: 2.700316  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 1.094043 \n",
      "\n",
      "loss: 0.533846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.455880 \n",
      "\n",
      "loss: 0.453097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.426263 \n",
      "\n",
      "loss: 0.394384  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.383670 \n",
      "\n",
      "loss: 0.350160  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.410095 \n",
      "\n",
      "loss: 0.377115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.373437 \n",
      "\n",
      "loss: 0.297651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.385920 \n",
      "\n",
      "loss: 0.390064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.354092 \n",
      "\n",
      "loss: 0.295806  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.325106 \n",
      "\n",
      "loss: 0.337123  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.328741 \n",
      "\n",
      "loss: 0.355074  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.364506 \n",
      "\n",
      "loss: 0.341870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.329026 \n",
      "\n",
      "loss: 0.250434  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.333996 \n",
      "\n",
      "loss: 0.304556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.373915 \n",
      "\n",
      "loss: 0.403434  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.339729 \n",
      "\n",
      "loss: 0.296124  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.333521 \n",
      "\n",
      "loss: 0.364796  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.323724 \n",
      "\n",
      "loss: 0.294695  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.338674 \n",
      "\n",
      "loss: 0.304235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.315455 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 345/500\n",
      "--------------------\n",
      "{'hl': [244, 77, 162], 'alpha': 0.00010878420613199046, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.03031901444461814}\n",
      "loss: 1.087151  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.469068 \n",
      "\n",
      "loss: 0.512892  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.445331 \n",
      "\n",
      "loss: 0.408089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.388477 \n",
      "\n",
      "loss: 0.381866  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.374892 \n",
      "\n",
      "loss: 0.403151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.344686 \n",
      "\n",
      "loss: 0.334927  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.341773 \n",
      "\n",
      "loss: 0.323632  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.378357 \n",
      "\n",
      "loss: 0.370233  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.336656 \n",
      "\n",
      "loss: 0.315136  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.331462 \n",
      "\n",
      "loss: 0.305727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.320414 \n",
      "\n",
      "loss: 0.298092  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.328352 \n",
      "\n",
      "loss: 0.310261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.343186 \n",
      "\n",
      "loss: 0.321215  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.334952 \n",
      "\n",
      "loss: 0.354864  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.371444 \n",
      "\n",
      "loss: 0.352514  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.349320 \n",
      "\n",
      "loss: 0.427110  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.327936 \n",
      "\n",
      "loss: 0.297608  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.313453 \n",
      "\n",
      "loss: 0.313883  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.315841 \n",
      "\n",
      "loss: 0.347117  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.350895 \n",
      "\n",
      "loss: 0.370520  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.317980 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 346/500\n",
      "--------------------\n",
      "{'hl': [690, 639, 502], 'alpha': 0.043364802018000664, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.266153021257867}\n",
      "loss: 1.092459  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.521681 \n",
      "\n",
      "loss: 0.498452  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.465272 \n",
      "\n",
      "loss: 0.462296  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.432674 \n",
      "\n",
      "loss: 0.423616  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.426128 \n",
      "\n",
      "loss: 0.440902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.413531 \n",
      "\n",
      "loss: 0.435408  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.419611 \n",
      "\n",
      "loss: 0.372484  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.431394 \n",
      "\n",
      "loss: 0.414713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.420976 \n",
      "\n",
      "loss: 0.431789  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.426972 \n",
      "\n",
      "loss: 0.411937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.401842 \n",
      "\n",
      "loss: 0.450175  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.414373 \n",
      "\n",
      "loss: 0.415037  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.427081 \n",
      "\n",
      "loss: 0.413725  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.435321 \n",
      "\n",
      "loss: 0.408898  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.406198 \n",
      "\n",
      "loss: 0.409081  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.411587 \n",
      "\n",
      "loss: 0.398869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.416568 \n",
      "\n",
      "loss: 0.374303  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.418356 \n",
      "\n",
      "loss: 0.404352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.411579 \n",
      "\n",
      "loss: 0.390921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.416103 \n",
      "\n",
      "loss: 0.423421  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.406509 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 347/500\n",
      "--------------------\n",
      "{'hl': [20, 25], 'alpha': 0.013112049719575039, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.008669584541453357}\n",
      "loss: 1.100111  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.459664 \n",
      "\n",
      "loss: 0.467094  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.397192 \n",
      "\n",
      "loss: 0.401773  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.386170 \n",
      "\n",
      "loss: 0.384248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.386271 \n",
      "\n",
      "loss: 0.381784  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.370432 \n",
      "\n",
      "loss: 0.383999  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.383208 \n",
      "\n",
      "loss: 0.395390  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.380692 \n",
      "\n",
      "loss: 0.351481  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.378048 \n",
      "\n",
      "loss: 0.378390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.377328 \n",
      "\n",
      "loss: 0.343898  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.374178 \n",
      "\n",
      "loss: 0.390800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.376943 \n",
      "\n",
      "loss: 0.394625  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.387079 \n",
      "\n",
      "loss: 0.353592  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.370855 \n",
      "\n",
      "loss: 0.392985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.368946 \n",
      "\n",
      "loss: 0.365339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.376093 \n",
      "\n",
      "loss: 0.392209  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.378702 \n",
      "\n",
      "loss: 0.381464  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.375408 \n",
      "\n",
      "loss: 0.367297  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.381894 \n",
      "\n",
      "loss: 0.348871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.370187 \n",
      "\n",
      "loss: 0.372275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.372294 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 348/500\n",
      "--------------------\n",
      "{'hl': [698, 448, 191], 'alpha': 0.0002679573750814191, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.12056031927352275}\n",
      "loss: 1.117291  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.535324 \n",
      "\n",
      "loss: 0.535589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.484936 \n",
      "\n",
      "loss: 0.508698  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.437995 \n",
      "\n",
      "loss: 0.456549  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.397291 \n",
      "\n",
      "loss: 0.395503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.394274 \n",
      "\n",
      "loss: 0.455938  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.393344 \n",
      "\n",
      "loss: 0.358190  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.385501 \n",
      "\n",
      "loss: 0.371913  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.364654 \n",
      "\n",
      "loss: 0.352258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.359647 \n",
      "\n",
      "loss: 0.333339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.351810 \n",
      "\n",
      "loss: 0.354310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346877 \n",
      "\n",
      "loss: 0.325852  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.348409 \n",
      "\n",
      "loss: 0.357742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.359520 \n",
      "\n",
      "loss: 0.381352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.346576 \n",
      "\n",
      "loss: 0.353867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.330689 \n",
      "\n",
      "loss: 0.368614  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.308381 \n",
      "\n",
      "loss: 0.324983  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.366319 \n",
      "\n",
      "loss: 0.336897  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.328617 \n",
      "\n",
      "loss: 0.351781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.309017 \n",
      "\n",
      "loss: 0.325929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.303444 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 349/500\n",
      "--------------------\n",
      "{'hl': [547, 266, 370], 'alpha': 0.0011730025242697863, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.18658848657349472}\n",
      "loss: 1.262869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.884288 \n",
      "\n",
      "loss: 0.883924  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.818084 \n",
      "\n",
      "loss: 0.807728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815299 \n",
      "\n",
      "loss: 0.811088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.826947 \n",
      "\n",
      "loss: 0.805882  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.808712 \n",
      "\n",
      "loss: 0.801942  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.826748 \n",
      "\n",
      "loss: 0.821066  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824599 \n",
      "\n",
      "loss: 0.806405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 0.816018 \n",
      "\n",
      "loss: 0.853750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.818364 \n",
      "\n",
      "loss: 0.842769  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.832784 \n",
      "\n",
      "loss: 0.821330  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817536 \n",
      "\n",
      "loss: 0.800977  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.802728 \n",
      "\n",
      "loss: 0.798493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.804133 \n",
      "\n",
      "loss: 0.831603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.8%, Avg loss: 0.773621 \n",
      "\n",
      "loss: 0.778747  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.713137 \n",
      "\n",
      "loss: 0.709594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.733866 \n",
      "\n",
      "loss: 0.742629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.614322 \n",
      "\n",
      "loss: 0.600035  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.595549 \n",
      "\n",
      "loss: 0.629712  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.609842 \n",
      "\n",
      "loss: 0.662134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.533575 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 350/500\n",
      "--------------------\n",
      "{'hl': [478, 586], 'alpha': 0.0009393589482369861, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3420524085726457}\n",
      "loss: 1.043884  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 11.365285 \n",
      "\n",
      "loss: 11.945710  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 6.241439 \n",
      "\n",
      "loss: 7.197989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 3.497901 \n",
      "\n",
      "loss: 3.078683  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 5.238030 \n",
      "\n",
      "loss: 5.224669  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 4.633807 \n",
      "\n",
      "loss: 4.492394  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 3.803828 \n",
      "\n",
      "loss: 3.876829  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 6.063422 \n",
      "\n",
      "loss: 5.887314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 8.419846 \n",
      "\n",
      "loss: 7.489962  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 5.294110 \n",
      "\n",
      "loss: 5.117335  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 10.335444 \n",
      "\n",
      "loss: 10.445940  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 10.113334 \n",
      "\n",
      "loss: 9.869022  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 3.425562 \n",
      "\n",
      "loss: 3.639831  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 2.940513 \n",
      "\n",
      "loss: 3.295435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 6.776204 \n",
      "\n",
      "loss: 6.422239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 8.016585 \n",
      "\n",
      "loss: 7.538640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 8.444200 \n",
      "\n",
      "loss: 8.735001  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 8.560814 \n",
      "\n",
      "loss: 7.318187  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 11.500848 \n",
      "\n",
      "loss: 12.106835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 2.572662 \n",
      "\n",
      "loss: 2.191236  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 17.817023 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 351/500\n",
      "--------------------\n",
      "{'hl': [677], 'alpha': 0.9261872990132916, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2026986212223327}\n",
      "loss: 1.060675  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.886781 \n",
      "\n",
      "loss: 0.881320  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.891747 \n",
      "\n",
      "loss: 0.896245  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.894838 \n",
      "\n",
      "loss: 0.889389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.892717 \n",
      "\n",
      "loss: 0.884330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.894557 \n",
      "\n",
      "loss: 0.892692  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.891762 \n",
      "\n",
      "loss: 0.887197  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.890726 \n",
      "\n",
      "loss: 0.879546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.891099 \n",
      "\n",
      "loss: 0.892142  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.889612 \n",
      "\n",
      "loss: 0.898506  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.890262 \n",
      "\n",
      "loss: 0.889985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.887151 \n",
      "\n",
      "loss: 0.893809  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.892499 \n",
      "\n",
      "loss: 0.896135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.888431 \n",
      "\n",
      "loss: 0.894674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.892365 \n",
      "\n",
      "loss: 0.888506  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.894889 \n",
      "\n",
      "loss: 0.896111  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.890407 \n",
      "\n",
      "loss: 0.883385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.889581 \n",
      "\n",
      "loss: 0.889257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.894594 \n",
      "\n",
      "loss: 0.896767  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.895520 \n",
      "\n",
      "loss: 0.892664  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.890526 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 352/500\n",
      "--------------------\n",
      "{'hl': [573, 495], 'alpha': 0.00016767169571713374, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.0414347926406503}\n",
      "loss: 1.110706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.561102 \n",
      "\n",
      "loss: 0.563392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.514266 \n",
      "\n",
      "loss: 0.528985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.480187 \n",
      "\n",
      "loss: 0.504803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.475152 \n",
      "\n",
      "loss: 0.477806  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.453672 \n",
      "\n",
      "loss: 0.469717  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.443570 \n",
      "\n",
      "loss: 0.431444  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.454904 \n",
      "\n",
      "loss: 0.454555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.432876 \n",
      "\n",
      "loss: 0.449751  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.419542 \n",
      "\n",
      "loss: 0.424742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.416235 \n",
      "\n",
      "loss: 0.414192  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.423368 \n",
      "\n",
      "loss: 0.406589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.422036 \n",
      "\n",
      "loss: 0.411353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.390659 \n",
      "\n",
      "loss: 0.379105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.383800 \n",
      "\n",
      "loss: 0.402104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.383444 \n",
      "\n",
      "loss: 0.393658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.383623 \n",
      "\n",
      "loss: 0.390069  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.388628 \n",
      "\n",
      "loss: 0.398453  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.378865 \n",
      "\n",
      "loss: 0.391437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.392874 \n",
      "\n",
      "loss: 0.400273  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.357258 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 353/500\n",
      "--------------------\n",
      "{'hl': [668, 347], 'alpha': 0.018341147851152848, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.11496027190079826}\n",
      "loss: 1.056696  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.523030 \n",
      "\n",
      "loss: 0.508673  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.470855 \n",
      "\n",
      "loss: 0.434355  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.447651 \n",
      "\n",
      "loss: 0.441325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.430463 \n",
      "\n",
      "loss: 0.428663  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.409663 \n",
      "\n",
      "loss: 0.411620  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.414234 \n",
      "\n",
      "loss: 0.409402  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.409261 \n",
      "\n",
      "loss: 0.394460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.394931 \n",
      "\n",
      "loss: 0.376418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.391101 \n",
      "\n",
      "loss: 0.391587  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.387447 \n",
      "\n",
      "loss: 0.409651  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.380846 \n",
      "\n",
      "loss: 0.344594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.378466 \n",
      "\n",
      "loss: 0.370556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.382319 \n",
      "\n",
      "loss: 0.371725  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.389138 \n",
      "\n",
      "loss: 0.333252  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.371437 \n",
      "\n",
      "loss: 0.386352  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.386842 \n",
      "\n",
      "loss: 0.389166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.375427 \n",
      "\n",
      "loss: 0.376201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.387878 \n",
      "\n",
      "loss: 0.361906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.371297 \n",
      "\n",
      "loss: 0.337531  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.353704 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 354/500\n",
      "--------------------\n",
      "{'hl': [588, 494, 285], 'alpha': 0.00015354931486491596, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4496658942674178}\n",
      "loss: 1.099092  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 9820.782444 \n",
      "\n",
      "loss: 7538.300293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.077403 \n",
      "\n",
      "loss: 0.853483  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.382024 \n",
      "\n",
      "loss: 1.449065  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814568 \n",
      "\n",
      "loss: 0.839444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.814188 \n",
      "\n",
      "loss: 0.800524  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.828267 \n",
      "\n",
      "loss: 0.825976  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.821162 \n",
      "\n",
      "loss: 0.823025  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.811348 \n",
      "\n",
      "loss: 0.808379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.823319 \n",
      "\n",
      "loss: 0.824089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.812668 \n",
      "\n",
      "loss: 0.828346  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.821605 \n",
      "\n",
      "loss: 0.823185  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.829662 \n",
      "\n",
      "loss: 0.840359  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.814441 \n",
      "\n",
      "loss: 0.815585  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.817255 \n",
      "\n",
      "loss: 0.805377  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.816889 \n",
      "\n",
      "loss: 0.820256  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.816244 \n",
      "\n",
      "loss: 0.816308  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.834964 \n",
      "\n",
      "loss: 0.817426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.866396 \n",
      "\n",
      "loss: 0.820970  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.816811 \n",
      "\n",
      "loss: 0.823068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.820178 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 355/500\n",
      "--------------------\n",
      "{'hl': [681, 41, 191], 'alpha': 0.5188782242110356, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.48073844801901533}\n",
      "loss: 1.078992  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.962974 \n",
      "\n",
      "loss: 0.957522  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.967431 \n",
      "\n",
      "loss: 0.964270  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.964615 \n",
      "\n",
      "loss: 0.967387  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.960249 \n",
      "\n",
      "loss: 0.957953  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.959495 \n",
      "\n",
      "loss: 0.964087  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.964097 \n",
      "\n",
      "loss: 0.959042  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.964809 \n",
      "\n",
      "loss: 0.961638  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.962297 \n",
      "\n",
      "loss: 0.964594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.964672 \n",
      "\n",
      "loss: 0.964232  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.960031 \n",
      "\n",
      "loss: 0.965362  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.962724 \n",
      "\n",
      "loss: 0.960069  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.967648 \n",
      "\n",
      "loss: 0.965322  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.964710 \n",
      "\n",
      "loss: 0.966440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.963248 \n",
      "\n",
      "loss: 0.961563  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.965896 \n",
      "\n",
      "loss: 0.963720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.964371 \n",
      "\n",
      "loss: 0.964677  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.964959 \n",
      "\n",
      "loss: 0.958124  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.966240 \n",
      "\n",
      "loss: 0.966634  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.960546 \n",
      "\n",
      "loss: 0.961195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.960401 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 356/500\n",
      "--------------------\n",
      "{'hl': [155, 415, 86], 'alpha': 0.0015743727287882575, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.33854977944175324}\n",
      "loss: 1.062365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.215955 \n",
      "\n",
      "loss: 1.378287  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 1.091221 \n",
      "\n",
      "loss: 1.097017  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.540620 \n",
      "\n",
      "loss: 1.575134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 1.235167 \n",
      "\n",
      "loss: 1.308288  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.186348 \n",
      "\n",
      "loss: 1.175684  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 1.083620 \n",
      "\n",
      "loss: 1.133121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 0.951092 \n",
      "\n",
      "loss: 0.900507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 1.309192 \n",
      "\n",
      "loss: 1.224578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 1.192713 \n",
      "\n",
      "loss: 1.203905  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.339001 \n",
      "\n",
      "loss: 1.502681  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 3.367229 \n",
      "\n",
      "loss: 3.341555  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.267555 \n",
      "\n",
      "loss: 1.284097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 1.251489 \n",
      "\n",
      "loss: 1.185960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 1.361827 \n",
      "\n",
      "loss: 1.600493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 2.171668 \n",
      "\n",
      "loss: 2.157146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.889405 \n",
      "\n",
      "loss: 0.917486  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 1.413352 \n",
      "\n",
      "loss: 1.409028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.165023 \n",
      "\n",
      "loss: 1.208506  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.784300 \n",
      "\n",
      "loss: 0.769881  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.133943 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 357/500\n",
      "--------------------\n",
      "{'hl': [347, 401, 151], 'alpha': 0.14520860088882595, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.02694284633050206}\n",
      "loss: 1.099510  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.667182 \n",
      "\n",
      "loss: 0.661985  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.644529 \n",
      "\n",
      "loss: 0.619802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.639447 \n",
      "\n",
      "loss: 0.633352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.636499 \n",
      "\n",
      "loss: 0.669970  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.632442 \n",
      "\n",
      "loss: 0.605768  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.646712 \n",
      "\n",
      "loss: 0.645929  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.643740 \n",
      "\n",
      "loss: 0.629907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.617763 \n",
      "\n",
      "loss: 0.617603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.634907 \n",
      "\n",
      "loss: 0.612578  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.645408 \n",
      "\n",
      "loss: 0.632153  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.650858 \n",
      "\n",
      "loss: 0.664844  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.634325 \n",
      "\n",
      "loss: 0.671939  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.630568 \n",
      "\n",
      "loss: 0.639383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.632140 \n",
      "\n",
      "loss: 0.611416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.609799 \n",
      "\n",
      "loss: 0.604346  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.619679 \n",
      "\n",
      "loss: 0.618293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.651910 \n",
      "\n",
      "loss: 0.646635  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.625078 \n",
      "\n",
      "loss: 0.640872  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.622334 \n",
      "\n",
      "loss: 0.628680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.626670 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 358/500\n",
      "--------------------\n",
      "{'hl': [245, 85], 'alpha': 0.0023034086101603075, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.01490986690668804}\n",
      "loss: 1.202088  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.502812 \n",
      "\n",
      "loss: 0.510143  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.494442 \n",
      "\n",
      "loss: 0.443907  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.480166 \n",
      "\n",
      "loss: 0.484407  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.456216 \n",
      "\n",
      "loss: 0.508056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.463026 \n",
      "\n",
      "loss: 0.494333  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.461549 \n",
      "\n",
      "loss: 0.462056  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.550129 \n",
      "\n",
      "loss: 0.569214  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.460054 \n",
      "\n",
      "loss: 0.452802  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.470745 \n",
      "\n",
      "loss: 0.442778  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.446172 \n",
      "\n",
      "loss: 0.486574  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.439151 \n",
      "\n",
      "loss: 0.420707  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.446658 \n",
      "\n",
      "loss: 0.449150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.462334 \n",
      "\n",
      "loss: 0.433566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.434374 \n",
      "\n",
      "loss: 0.420719  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.440075 \n",
      "\n",
      "loss: 0.445155  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.413899 \n",
      "\n",
      "loss: 0.417300  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.458544 \n",
      "\n",
      "loss: 0.457301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.454500 \n",
      "\n",
      "loss: 0.430860  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.415097 \n",
      "\n",
      "loss: 0.407989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.413432 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 359/500\n",
      "--------------------\n",
      "{'hl': [469, 510], 'alpha': 0.0008176238652833533, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.09295034916311096}\n",
      "loss: 1.118972  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 2.074512 \n",
      "\n",
      "loss: 1.969168  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.949155 \n",
      "\n",
      "loss: 0.841319  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 1.746204 \n",
      "\n",
      "loss: 1.903437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 2.716206 \n",
      "\n",
      "loss: 2.537083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.887316 \n",
      "\n",
      "loss: 0.842415  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 1.517402 \n",
      "\n",
      "loss: 1.362290  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 1.648866 \n",
      "\n",
      "loss: 1.646912  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 1.662156 \n",
      "\n",
      "loss: 1.367580  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.067706 \n",
      "\n",
      "loss: 1.226307  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.613664 \n",
      "\n",
      "loss: 1.821329  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.900883 \n",
      "\n",
      "loss: 0.950803  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 1.290929 \n",
      "\n",
      "loss: 1.207872  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.584660 \n",
      "\n",
      "loss: 0.563329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 1.227873 \n",
      "\n",
      "loss: 1.248959  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.851445 \n",
      "\n",
      "loss: 0.924411  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.630233 \n",
      "\n",
      "loss: 0.625873  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.575977 \n",
      "\n",
      "loss: 0.524846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.408036 \n",
      "\n",
      "loss: 1.492527  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 1.177387 \n",
      "\n",
      "loss: 1.136047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.619132 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 360/500\n",
      "--------------------\n",
      "{'hl': [684, 397, 95], 'alpha': 0.12265058289885097, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.356582955485925}\n",
      "loss: 1.102088  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.539504 \n",
      "\n",
      "loss: 0.527930  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.538821 \n",
      "\n",
      "loss: 0.531174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.540314 \n",
      "\n",
      "loss: 0.520989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.548119 \n",
      "\n",
      "loss: 0.526266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.541008 \n",
      "\n",
      "loss: 0.535268  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.545295 \n",
      "\n",
      "loss: 0.534437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.542326 \n",
      "\n",
      "loss: 0.558847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.537521 \n",
      "\n",
      "loss: 0.531848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.532208 \n",
      "\n",
      "loss: 0.551031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.539513 \n",
      "\n",
      "loss: 0.536374  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.546289 \n",
      "\n",
      "loss: 0.530268  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.540191 \n",
      "\n",
      "loss: 0.539413  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.543417 \n",
      "\n",
      "loss: 0.512929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.535988 \n",
      "\n",
      "loss: 0.561921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535993 \n",
      "\n",
      "loss: 0.542948  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.537330 \n",
      "\n",
      "loss: 0.529621  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.542708 \n",
      "\n",
      "loss: 0.539283  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.534906 \n",
      "\n",
      "loss: 0.531962  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.536578 \n",
      "\n",
      "loss: 0.554990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535203 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 361/500\n",
      "--------------------\n",
      "{'hl': [282], 'alpha': 0.0004138889725798445, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.15840744651789992}\n",
      "loss: 1.065445  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.789806 \n",
      "\n",
      "loss: 0.720653  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.635188 \n",
      "\n",
      "loss: 0.585236  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.637499 \n",
      "\n",
      "loss: 0.622056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.517415 \n",
      "\n",
      "loss: 0.565407  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.507254 \n",
      "\n",
      "loss: 0.510363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.465027 \n",
      "\n",
      "loss: 0.502674  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.599589 \n",
      "\n",
      "loss: 0.620801  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.621074 \n",
      "\n",
      "loss: 0.627673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.585836 \n",
      "\n",
      "loss: 0.617044  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.517919 \n",
      "\n",
      "loss: 0.507010  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 1.220894 \n",
      "\n",
      "loss: 1.247626  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.533611 \n",
      "\n",
      "loss: 0.529097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.803647 \n",
      "\n",
      "loss: 0.668154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.765423 \n",
      "\n",
      "loss: 0.735592  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.573129 \n",
      "\n",
      "loss: 0.609744  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.580160 \n",
      "\n",
      "loss: 0.616115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.501215 \n",
      "\n",
      "loss: 0.500509  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.938637 \n",
      "\n",
      "loss: 1.040341  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.727659 \n",
      "\n",
      "loss: 0.791172  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.568765 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 362/500\n",
      "--------------------\n",
      "{'hl': [101], 'alpha': 0.00010490130464122246, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.1800227569237136}\n",
      "loss: 1.001988  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 3.720024 \n",
      "\n",
      "loss: 3.309778  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 1.049446 \n",
      "\n",
      "loss: 0.652122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.581743 \n",
      "\n",
      "loss: 0.604661  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.748590 \n",
      "\n",
      "loss: 0.792745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.396372 \n",
      "\n",
      "loss: 0.386689  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.414719 \n",
      "\n",
      "loss: 0.396674  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.347347 \n",
      "\n",
      "loss: 0.327393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.329793 \n",
      "\n",
      "loss: 0.345868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.333904 \n",
      "\n",
      "loss: 0.322622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.337380 \n",
      "\n",
      "loss: 0.299253  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.350202 \n",
      "\n",
      "loss: 0.284285  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.364744 \n",
      "\n",
      "loss: 0.309649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.347857 \n",
      "\n",
      "loss: 0.332364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.338943 \n",
      "\n",
      "loss: 0.349623  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.340372 \n",
      "\n",
      "loss: 0.298478  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.340865 \n",
      "\n",
      "loss: 0.315619  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.352718 \n",
      "\n",
      "loss: 0.321388  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.316919 \n",
      "\n",
      "loss: 0.332659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.374543 \n",
      "\n",
      "loss: 0.355372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.309699 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 363/500\n",
      "--------------------\n",
      "{'hl': [112, 143], 'alpha': 0.00022345440963502435, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2785368176073918}\n",
      "loss: 1.371304  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.909482 \n",
      "\n",
      "loss: 0.853173  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.552297 \n",
      "\n",
      "loss: 0.578950  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 1.434984 \n",
      "\n",
      "loss: 1.372928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.584682 \n",
      "\n",
      "loss: 0.574348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.549258 \n",
      "\n",
      "loss: 0.494036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.679368 \n",
      "\n",
      "loss: 0.723730  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.597172 \n",
      "\n",
      "loss: 0.608812  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.553173 \n",
      "\n",
      "loss: 0.560837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.555148 \n",
      "\n",
      "loss: 0.571392  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.473349 \n",
      "\n",
      "loss: 0.501377  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.745283 \n",
      "\n",
      "loss: 0.769696  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.543473 \n",
      "\n",
      "loss: 0.528202  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.573143 \n",
      "\n",
      "loss: 0.598526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.575195 \n",
      "\n",
      "loss: 0.578780  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.516683 \n",
      "\n",
      "loss: 0.524902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.649666 \n",
      "\n",
      "loss: 0.559565  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.781971 \n",
      "\n",
      "loss: 0.878895  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.649383 \n",
      "\n",
      "loss: 0.692556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.590034 \n",
      "\n",
      "loss: 0.591259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.428277 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 364/500\n",
      "--------------------\n",
      "{'hl': [425, 113, 34], 'alpha': 0.00022828394437395861, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.43187271681636896}\n",
      "loss: 1.056246  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.917364 \n",
      "\n",
      "loss: 0.884029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.833819 \n",
      "\n",
      "loss: 0.828808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.861514 \n",
      "\n",
      "loss: 0.883997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814554 \n",
      "\n",
      "loss: 0.824935  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.817880 \n",
      "\n",
      "loss: 0.824044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.822881 \n",
      "\n",
      "loss: 0.818736  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.828211 \n",
      "\n",
      "loss: 0.825444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.817004 \n",
      "\n",
      "loss: 0.850969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.818081 \n",
      "\n",
      "loss: 0.796329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.819208 \n",
      "\n",
      "loss: 0.849663  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.824393 \n",
      "\n",
      "loss: 0.815409  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.833465 \n",
      "\n",
      "loss: 0.835229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.810253 \n",
      "\n",
      "loss: 0.822316  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.817165 \n",
      "\n",
      "loss: 0.827467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.808883 \n",
      "\n",
      "loss: 0.843439  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820176 \n",
      "\n",
      "loss: 0.810116  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.827257 \n",
      "\n",
      "loss: 0.786794  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.811206 \n",
      "\n",
      "loss: 0.820999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.811084 \n",
      "\n",
      "loss: 0.797720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.815439 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 365/500\n",
      "--------------------\n",
      "{'hl': [306], 'alpha': 0.0045210600872432685, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.28602301933169477}\n",
      "loss: 1.057739  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.467265 \n",
      "\n",
      "loss: 0.422058  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.440418 \n",
      "\n",
      "loss: 0.448007  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.401009 \n",
      "\n",
      "loss: 0.383134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.393226 \n",
      "\n",
      "loss: 0.386368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.371735 \n",
      "\n",
      "loss: 0.362366  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.367663 \n",
      "\n",
      "loss: 0.347940  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.368761 \n",
      "\n",
      "loss: 0.407271  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.357733 \n",
      "\n",
      "loss: 0.351608  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.355034 \n",
      "\n",
      "loss: 0.361759  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.338232 \n",
      "\n",
      "loss: 0.367556  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.348396 \n",
      "\n",
      "loss: 0.332051  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.363826 \n",
      "\n",
      "loss: 0.311641  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.342148 \n",
      "\n",
      "loss: 0.342024  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.352657 \n",
      "\n",
      "loss: 0.328927  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.332875 \n",
      "\n",
      "loss: 0.346720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.335099 \n",
      "\n",
      "loss: 0.314637  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.348524 \n",
      "\n",
      "loss: 0.380940  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.328202 \n",
      "\n",
      "loss: 0.356441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.348126 \n",
      "\n",
      "loss: 0.325408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.322220 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 366/500\n",
      "--------------------\n",
      "{'hl': [709], 'alpha': 0.0033337121199288407, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.15063551956099686}\n",
      "loss: 1.169758  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 2.823699 \n",
      "\n",
      "loss: 2.547417  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 1.177755 \n",
      "\n",
      "loss: 1.131401  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 3.798060 \n",
      "\n",
      "loss: 3.513155  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 4.005357 \n",
      "\n",
      "loss: 3.831736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.3%, Avg loss: 2.128518 \n",
      "\n",
      "loss: 2.066902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 4.347330 \n",
      "\n",
      "loss: 4.397103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.5%, Avg loss: 5.426488 \n",
      "\n",
      "loss: 5.241115  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 3.768803 \n",
      "\n",
      "loss: 4.224391  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 1.687300 \n",
      "\n",
      "loss: 1.580339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.737850 \n",
      "\n",
      "loss: 1.668297  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 2.703206 \n",
      "\n",
      "loss: 2.747357  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 2.498283 \n",
      "\n",
      "loss: 2.840825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 2.124002 \n",
      "\n",
      "loss: 2.009614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 5.674746 \n",
      "\n",
      "loss: 5.844853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 1.110894 \n",
      "\n",
      "loss: 1.123584  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 2.754817 \n",
      "\n",
      "loss: 2.713318  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 3.747555 \n",
      "\n",
      "loss: 3.811693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 1.616964 \n",
      "\n",
      "loss: 1.454808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 2.746645 \n",
      "\n",
      "loss: 3.068549  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 2.381533 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 367/500\n",
      "--------------------\n",
      "{'hl': [157, 72], 'alpha': 0.00046647632078376523, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.14994615173538944}\n",
      "loss: 1.062959  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 5.251122 \n",
      "\n",
      "loss: 4.373950  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.643599 \n",
      "\n",
      "loss: 0.523904  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.431131 \n",
      "\n",
      "loss: 0.414443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.390570 \n",
      "\n",
      "loss: 0.398209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.366212 \n",
      "\n",
      "loss: 0.318092  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.350988 \n",
      "\n",
      "loss: 0.334458  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.356053 \n",
      "\n",
      "loss: 0.340420  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.342000 \n",
      "\n",
      "loss: 0.379491  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.337655 \n",
      "\n",
      "loss: 0.345379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.332093 \n",
      "\n",
      "loss: 0.308284  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.344705 \n",
      "\n",
      "loss: 0.302479  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.350886 \n",
      "\n",
      "loss: 0.322165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.328737 \n",
      "\n",
      "loss: 0.317062  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.339948 \n",
      "\n",
      "loss: 0.323819  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.329917 \n",
      "\n",
      "loss: 0.317156  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.355025 \n",
      "\n",
      "loss: 0.364920  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.332304 \n",
      "\n",
      "loss: 0.292502  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.320755 \n",
      "\n",
      "loss: 0.335267  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.354673 \n",
      "\n",
      "loss: 0.307534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.333811 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 368/500\n",
      "--------------------\n",
      "{'hl': [377], 'alpha': 0.0010157783476349312, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.29694381837973544}\n",
      "loss: 1.040607  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 3.987741 \n",
      "\n",
      "loss: 3.844007  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 2.160587 \n",
      "\n",
      "loss: 1.993718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 2.059249 \n",
      "\n",
      "loss: 1.803156  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 3.696067 \n",
      "\n",
      "loss: 3.437527  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.954452 \n",
      "\n",
      "loss: 2.208158  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 1.191261 \n",
      "\n",
      "loss: 1.245014  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 2.962221 \n",
      "\n",
      "loss: 2.539302  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 5.629699 \n",
      "\n",
      "loss: 5.528431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 2.675289 \n",
      "\n",
      "loss: 2.803944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 1.115655 \n",
      "\n",
      "loss: 1.165045  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 2.452347 \n",
      "\n",
      "loss: 2.282882  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 5.041045 \n",
      "\n",
      "loss: 5.143353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 2.045822 \n",
      "\n",
      "loss: 2.092213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 2.151697 \n",
      "\n",
      "loss: 2.114661  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 1.793574 \n",
      "\n",
      "loss: 1.430418  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 2.479169 \n",
      "\n",
      "loss: 2.391366  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.566460 \n",
      "\n",
      "loss: 1.473389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 1.785059 \n",
      "\n",
      "loss: 1.746203  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 4.048574 \n",
      "\n",
      "loss: 3.789083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 1.447892 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 369/500\n",
      "--------------------\n",
      "{'hl': [476], 'alpha': 0.0002678486552563919, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4744168488510431}\n",
      "loss: 1.171383  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.431502 \n",
      "\n",
      "loss: 0.448487  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.401589 \n",
      "\n",
      "loss: 0.446423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.376048 \n",
      "\n",
      "loss: 0.377653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.366757 \n",
      "\n",
      "loss: 0.380491  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.350891 \n",
      "\n",
      "loss: 0.325570  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.333285 \n",
      "\n",
      "loss: 0.340373  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.352480 \n",
      "\n",
      "loss: 0.316599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.385170 \n",
      "\n",
      "loss: 0.410052  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.378997 \n",
      "\n",
      "loss: 0.394191  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.307066 \n",
      "\n",
      "loss: 0.339825  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.306594 \n",
      "\n",
      "loss: 0.338392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.327676 \n",
      "\n",
      "loss: 0.295067  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.322121 \n",
      "\n",
      "loss: 0.291482  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.321290 \n",
      "\n",
      "loss: 0.303945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.314559 \n",
      "\n",
      "loss: 0.314016  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.432928 \n",
      "\n",
      "loss: 0.390984  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.314912 \n",
      "\n",
      "loss: 0.312605  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.304944 \n",
      "\n",
      "loss: 0.295441  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.411861 \n",
      "\n",
      "loss: 0.410727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.288373 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 370/500\n",
      "--------------------\n",
      "{'hl': [643, 397], 'alpha': 0.1645530164493907, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.1674346382511038}\n",
      "loss: 1.091831  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 230.562436 \n",
      "\n",
      "loss: 208.486465  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 45.632230 \n",
      "\n",
      "loss: 48.528793  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 46.678041 \n",
      "\n",
      "loss: 54.942524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 13.006973 \n",
      "\n",
      "loss: 13.153080  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 3.063398 \n",
      "\n",
      "loss: 2.951348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.577999 \n",
      "\n",
      "loss: 0.575979  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.470979 \n",
      "\n",
      "loss: 0.424701  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.461907 \n",
      "\n",
      "loss: 0.483883  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.483977 \n",
      "\n",
      "loss: 0.496011  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.506791 \n",
      "\n",
      "loss: 0.500206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.468377 \n",
      "\n",
      "loss: 0.460625  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.500708 \n",
      "\n",
      "loss: 0.484317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.502694 \n",
      "\n",
      "loss: 0.500731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.509959 \n",
      "\n",
      "loss: 0.552901  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.502968 \n",
      "\n",
      "loss: 0.491980  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.510952 \n",
      "\n",
      "loss: 0.517278  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.522835 \n",
      "\n",
      "loss: 0.510041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.530887 \n",
      "\n",
      "loss: 0.522096  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.517939 \n",
      "\n",
      "loss: 0.534047  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.536454 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 371/500\n",
      "--------------------\n",
      "{'hl': [616, 147, 315], 'alpha': 0.0019171699867369528, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.15716022226960114}\n",
      "loss: 1.083412  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 2.127545 \n",
      "\n",
      "loss: 2.208352  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 1.315778 \n",
      "\n",
      "loss: 1.147409  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 1.704280 \n",
      "\n",
      "loss: 1.863200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 1.073896 \n",
      "\n",
      "loss: 1.089978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 3.014719 \n",
      "\n",
      "loss: 2.931884  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 2.815790 \n",
      "\n",
      "loss: 2.647124  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 1.290542 \n",
      "\n",
      "loss: 1.228581  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.192699 \n",
      "\n",
      "loss: 1.271497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 2.437671 \n",
      "\n",
      "loss: 2.328377  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.007031 \n",
      "\n",
      "loss: 1.094454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.242060 \n",
      "\n",
      "loss: 1.218361  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 41.8%, Avg loss: 3.869339 \n",
      "\n",
      "loss: 3.725545  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 2.134603 \n",
      "\n",
      "loss: 2.246980  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.232782 \n",
      "\n",
      "loss: 1.284482  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.727550 \n",
      "\n",
      "loss: 0.728686  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 1.924615 \n",
      "\n",
      "loss: 1.887728  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 4.147621 \n",
      "\n",
      "loss: 3.970756  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 3.602273 \n",
      "\n",
      "loss: 3.732018  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.766397 \n",
      "\n",
      "loss: 1.819742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.068469 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 372/500\n",
      "--------------------\n",
      "{'hl': [334, 306], 'alpha': 0.08699563485882172, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.16301053009770844}\n",
      "loss: 1.099263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.073267 \n",
      "\n",
      "loss: 1.049927  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.023630 \n",
      "\n",
      "loss: 1.016209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.167283 \n",
      "\n",
      "loss: 1.177253  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.966691 \n",
      "\n",
      "loss: 0.965020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.996693 \n",
      "\n",
      "loss: 0.960001  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.937688 \n",
      "\n",
      "loss: 0.925203  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.997863 \n",
      "\n",
      "loss: 1.014229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.941915 \n",
      "\n",
      "loss: 0.931201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.011902 \n",
      "\n",
      "loss: 0.994170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.965694 \n",
      "\n",
      "loss: 0.963803  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.108664 \n",
      "\n",
      "loss: 1.073172  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.109190 \n",
      "\n",
      "loss: 1.050267  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.986435 \n",
      "\n",
      "loss: 0.997014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.945116 \n",
      "\n",
      "loss: 0.966906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.038606 \n",
      "\n",
      "loss: 1.064234  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.047272 \n",
      "\n",
      "loss: 1.032419  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.166959 \n",
      "\n",
      "loss: 1.162492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.020986 \n",
      "\n",
      "loss: 1.015644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.069952 \n",
      "\n",
      "loss: 1.115149  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.043049 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 373/500\n",
      "--------------------\n",
      "{'hl': [410, 381], 'alpha': 0.0002854639654884413, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.34088814530173084}\n",
      "loss: 1.090054  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.477104 \n",
      "\n",
      "loss: 0.455847  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.467820 \n",
      "\n",
      "loss: 0.450168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.448053 \n",
      "\n",
      "loss: 0.444667  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.425910 \n",
      "\n",
      "loss: 0.432103  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.432871 \n",
      "\n",
      "loss: 0.451181  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.443075 \n",
      "\n",
      "loss: 0.484390  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.423724 \n",
      "\n",
      "loss: 0.397420  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.411223 \n",
      "\n",
      "loss: 0.427396  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.414403 \n",
      "\n",
      "loss: 0.429148  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.421548 \n",
      "\n",
      "loss: 0.407352  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.378737 \n",
      "\n",
      "loss: 0.364998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.401140 \n",
      "\n",
      "loss: 0.414021  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.391795 \n",
      "\n",
      "loss: 0.437215  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.390892 \n",
      "\n",
      "loss: 0.346078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.373181 \n",
      "\n",
      "loss: 0.363777  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.362423 \n",
      "\n",
      "loss: 0.353294  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.391358 \n",
      "\n",
      "loss: 0.349571  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.356719 \n",
      "\n",
      "loss: 0.369321  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.352712 \n",
      "\n",
      "loss: 0.358929  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.358808 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 374/500\n",
      "--------------------\n",
      "{'hl': [35, 480, 222], 'alpha': 0.005673091878529389, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.40950088744542884}\n",
      "loss: 1.112061  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.444031 \n",
      "\n",
      "loss: 0.443152  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.406019 \n",
      "\n",
      "loss: 0.375754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.387160 \n",
      "\n",
      "loss: 0.353244  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.399837 \n",
      "\n",
      "loss: 0.406324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.358669 \n",
      "\n",
      "loss: 0.388678  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.459831 \n",
      "\n",
      "loss: 0.479447  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.391685 \n",
      "\n",
      "loss: 0.384475  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.368839 \n",
      "\n",
      "loss: 0.352941  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.391529 \n",
      "\n",
      "loss: 0.364038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.361940 \n",
      "\n",
      "loss: 0.365482  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.362513 \n",
      "\n",
      "loss: 0.371890  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.371373 \n",
      "\n",
      "loss: 0.360925  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.365913 \n",
      "\n",
      "loss: 0.309442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.391373 \n",
      "\n",
      "loss: 0.376852  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.331750 \n",
      "\n",
      "loss: 0.343069  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.345269 \n",
      "\n",
      "loss: 0.353655  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.344802 \n",
      "\n",
      "loss: 0.325611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.343521 \n",
      "\n",
      "loss: 0.328251  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.336057 \n",
      "\n",
      "loss: 0.327823  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.342481 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 375/500\n",
      "--------------------\n",
      "{'hl': [697, 519], 'alpha': 0.0003603433326223755, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.12641557429705272}\n",
      "loss: 1.139799  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.482170 \n",
      "\n",
      "loss: 0.485293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.461746 \n",
      "\n",
      "loss: 0.421389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.442269 \n",
      "\n",
      "loss: 0.409486  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.404355 \n",
      "\n",
      "loss: 0.415636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.378070 \n",
      "\n",
      "loss: 0.401098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.391627 \n",
      "\n",
      "loss: 0.391761  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.377242 \n",
      "\n",
      "loss: 0.338754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366661 \n",
      "\n",
      "loss: 0.372575  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.364924 \n",
      "\n",
      "loss: 0.376509  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.339975 \n",
      "\n",
      "loss: 0.336379  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.342815 \n",
      "\n",
      "loss: 0.361206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.343125 \n",
      "\n",
      "loss: 0.364939  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.349547 \n",
      "\n",
      "loss: 0.298656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.332206 \n",
      "\n",
      "loss: 0.321618  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.336509 \n",
      "\n",
      "loss: 0.338825  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.331148 \n",
      "\n",
      "loss: 0.376947  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.329792 \n",
      "\n",
      "loss: 0.303275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.329874 \n",
      "\n",
      "loss: 0.272857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.322548 \n",
      "\n",
      "loss: 0.340720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.320288 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 376/500\n",
      "--------------------\n",
      "{'hl': [441], 'alpha': 0.14332008361910925, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4953512371570403}\n",
      "loss: 1.212130  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 25.724915 \n",
      "\n",
      "loss: 26.470934  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 11.728847 \n",
      "\n",
      "loss: 11.139187  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.120843 \n",
      "\n",
      "loss: 2.037408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 2.888591 \n",
      "\n",
      "loss: 3.185342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 14.948624 \n",
      "\n",
      "loss: 14.739138  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 19.431777 \n",
      "\n",
      "loss: 20.793266  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 60.873403 \n",
      "\n",
      "loss: 56.927277  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 14.599579 \n",
      "\n",
      "loss: 14.758884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 10.363557 \n",
      "\n",
      "loss: 10.085351  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 53.611798 \n",
      "\n",
      "loss: 55.907436  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 56.170851 \n",
      "\n",
      "loss: 48.700848  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 47.219672 \n",
      "\n",
      "loss: 47.126743  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 49.148620 \n",
      "\n",
      "loss: 46.560989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 15.873725 \n",
      "\n",
      "loss: 15.131345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 55.023564 \n",
      "\n",
      "loss: 53.567669  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 24.995932 \n",
      "\n",
      "loss: 23.820415  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 13.996588 \n",
      "\n",
      "loss: 16.703171  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 36.965468 \n",
      "\n",
      "loss: 34.904972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 22.088131 \n",
      "\n",
      "loss: 23.483526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 57.636415 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 377/500\n",
      "--------------------\n",
      "{'hl': [604, 418], 'alpha': 0.013723649092368291, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.39538138643292464}\n",
      "loss: 1.304406  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 0.816938 \n",
      "\n",
      "loss: 0.806139  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.816330 \n",
      "\n",
      "loss: 0.800850  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.711291 \n",
      "\n",
      "loss: 0.755147  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.620411 \n",
      "\n",
      "loss: 0.632512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.591592 \n",
      "\n",
      "loss: 0.593227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.578325 \n",
      "\n",
      "loss: 0.597222  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.672348 \n",
      "\n",
      "loss: 0.683484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.631056 \n",
      "\n",
      "loss: 0.603358  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.604302 \n",
      "\n",
      "loss: 0.589141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.530581 \n",
      "\n",
      "loss: 0.544081  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.625987 \n",
      "\n",
      "loss: 0.597183  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.533070 \n",
      "\n",
      "loss: 0.531314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.588774 \n",
      "\n",
      "loss: 0.599301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.610251 \n",
      "\n",
      "loss: 0.643019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.573943 \n",
      "\n",
      "loss: 0.575731  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.570657 \n",
      "\n",
      "loss: 0.558566  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.716222 \n",
      "\n",
      "loss: 0.739646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.570220 \n",
      "\n",
      "loss: 0.562312  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.627720 \n",
      "\n",
      "loss: 0.638416  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 0.630034 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 378/500\n",
      "--------------------\n",
      "{'hl': [557, 616], 'alpha': 0.035704377698958005, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.38450012855522825}\n",
      "loss: 1.063091  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.455657 \n",
      "\n",
      "loss: 0.467801  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.447799 \n",
      "\n",
      "loss: 0.454127  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.421945 \n",
      "\n",
      "loss: 0.395713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.418069 \n",
      "\n",
      "loss: 0.400755  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.409257 \n",
      "\n",
      "loss: 0.420237  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.412089 \n",
      "\n",
      "loss: 0.385357  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.425758 \n",
      "\n",
      "loss: 0.393896  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.407404 \n",
      "\n",
      "loss: 0.401556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.408245 \n",
      "\n",
      "loss: 0.426664  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.429048 \n",
      "\n",
      "loss: 0.423003  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.411968 \n",
      "\n",
      "loss: 0.426253  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.432759 \n",
      "\n",
      "loss: 0.428272  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.416704 \n",
      "\n",
      "loss: 0.433687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.406296 \n",
      "\n",
      "loss: 0.406108  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.410326 \n",
      "\n",
      "loss: 0.426725  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.409331 \n",
      "\n",
      "loss: 0.411749  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.414945 \n",
      "\n",
      "loss: 0.405708  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.416968 \n",
      "\n",
      "loss: 0.405461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.404905 \n",
      "\n",
      "loss: 0.426258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.404589 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 379/500\n",
      "--------------------\n",
      "{'hl': [688, 371, 178], 'alpha': 0.038725710271304586, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4834088856709459}\n",
      "loss: 1.131638  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 5609.306641 \n",
      "\n",
      "loss: 5866.573730  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.855640 \n",
      "\n",
      "loss: 0.848536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.835583 \n",
      "\n",
      "loss: 0.834759  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.839281 \n",
      "\n",
      "loss: 0.836763  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.828952 \n",
      "\n",
      "loss: 0.837491  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.845064 \n",
      "\n",
      "loss: 0.833293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.764324 \n",
      "\n",
      "loss: 1.861296  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.831202 \n",
      "\n",
      "loss: 0.834720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.855184 \n",
      "\n",
      "loss: 0.839175  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.832935 \n",
      "\n",
      "loss: 0.824350  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.839269 \n",
      "\n",
      "loss: 0.827732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 0.945415 \n",
      "\n",
      "loss: 0.837859  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 0.893297 \n",
      "\n",
      "loss: 0.862703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.839541 \n",
      "\n",
      "loss: 0.834749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.839341 \n",
      "\n",
      "loss: 0.838918  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.838393 \n",
      "\n",
      "loss: 0.830732  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 0.842342 \n",
      "\n",
      "loss: 0.845568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.805317 \n",
      "\n",
      "loss: 0.800951  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 0.807891 \n",
      "\n",
      "loss: 0.828944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.849850 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 380/500\n",
      "--------------------\n",
      "{'hl': [448, 116], 'alpha': 0.00011020240974567073, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.25538705263846984}\n",
      "loss: 1.135147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.465976 \n",
      "\n",
      "loss: 0.468916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.432679 \n",
      "\n",
      "loss: 0.398223  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.390958 \n",
      "\n",
      "loss: 0.416936  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.372034 \n",
      "\n",
      "loss: 0.364146  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.365274 \n",
      "\n",
      "loss: 0.391174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.374171 \n",
      "\n",
      "loss: 0.371193  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.359361 \n",
      "\n",
      "loss: 0.320909  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.343642 \n",
      "\n",
      "loss: 0.301712  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.347613 \n",
      "\n",
      "loss: 0.321583  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.313090 \n",
      "\n",
      "loss: 0.352630  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.313993 \n",
      "\n",
      "loss: 0.326329  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.334301 \n",
      "\n",
      "loss: 0.334637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.330762 \n",
      "\n",
      "loss: 0.317872  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.362208 \n",
      "\n",
      "loss: 0.380680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.313167 \n",
      "\n",
      "loss: 0.336616  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.318800 \n",
      "\n",
      "loss: 0.336369  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.309962 \n",
      "\n",
      "loss: 0.294611  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.324850 \n",
      "\n",
      "loss: 0.293141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.312130 \n",
      "\n",
      "loss: 0.331462  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.289840 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 381/500\n",
      "--------------------\n",
      "{'hl': [579, 602, 712], 'alpha': 0.019995929324953456, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.19562797092188366}\n",
      "loss: 1.275445  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 16.716914 \n",
      "\n",
      "loss: 16.539268  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 4.987359 \n",
      "\n",
      "loss: 4.690987  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 8.895787 \n",
      "\n",
      "loss: 9.236970  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 7.643067 \n",
      "\n",
      "loss: 7.505124  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 13.464697 \n",
      "\n",
      "loss: 14.576880  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 6.018745 \n",
      "\n",
      "loss: 5.184468  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 14.516717 \n",
      "\n",
      "loss: 14.610528  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 10.107842 \n",
      "\n",
      "loss: 10.014395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.712863 \n",
      "\n",
      "loss: 4.806003  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 10.637029 \n",
      "\n",
      "loss: 10.958958  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.985362 \n",
      "\n",
      "loss: 1.895920  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 13.206169 \n",
      "\n",
      "loss: 12.535718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.323576 \n",
      "\n",
      "loss: 3.191054  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.729155 \n",
      "\n",
      "loss: 3.642087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 7.221390 \n",
      "\n",
      "loss: 6.715706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 10.510502 \n",
      "\n",
      "loss: 10.304221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 9.940722 \n",
      "\n",
      "loss: 9.903671  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 6.215873 \n",
      "\n",
      "loss: 6.243635  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 3.564651 \n",
      "\n",
      "loss: 3.568156  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 10.477132 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 382/500\n",
      "--------------------\n",
      "{'hl': [610, 715, 520], 'alpha': 0.00040084800817717024, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.05236422406723024}\n",
      "loss: 1.105580  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 46.527525 \n",
      "\n",
      "loss: 27.988626  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 16.195303 \n",
      "\n",
      "loss: 16.613190  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.735006 \n",
      "\n",
      "loss: 0.850969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.676955 \n",
      "\n",
      "loss: 0.685342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.635852 \n",
      "\n",
      "loss: 0.650675  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.676707 \n",
      "\n",
      "loss: 0.560261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535358 \n",
      "\n",
      "loss: 0.528834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.552039 \n",
      "\n",
      "loss: 0.563830  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.487714 \n",
      "\n",
      "loss: 0.467167  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.461767 \n",
      "\n",
      "loss: 0.464953  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.450414 \n",
      "\n",
      "loss: 0.470355  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.967679 \n",
      "\n",
      "loss: 0.647933  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.540178 \n",
      "\n",
      "loss: 0.562790  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.529889 \n",
      "\n",
      "loss: 0.511886  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.477245 \n",
      "\n",
      "loss: 0.430835  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.473534 \n",
      "\n",
      "loss: 0.440871  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.465712 \n",
      "\n",
      "loss: 0.421693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.458542 \n",
      "\n",
      "loss: 0.454737  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.433932 \n",
      "\n",
      "loss: 0.384156  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.699290 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 383/500\n",
      "--------------------\n",
      "{'hl': [95, 126], 'alpha': 0.21148081666438723, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.15601398291438096}\n",
      "loss: 1.143194  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.674005 \n",
      "\n",
      "loss: 0.693727  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.664134 \n",
      "\n",
      "loss: 0.674847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.605636 \n",
      "\n",
      "loss: 0.618705  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.616325 \n",
      "\n",
      "loss: 0.615394  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.609257 \n",
      "\n",
      "loss: 0.619749  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.626375 \n",
      "\n",
      "loss: 0.632180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 2.759338 \n",
      "\n",
      "loss: 2.817433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 1.059870 \n",
      "\n",
      "loss: 1.104915  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 1.053591 \n",
      "\n",
      "loss: 1.046678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.893091 \n",
      "\n",
      "loss: 0.927796  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.822679 \n",
      "\n",
      "loss: 0.829461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.632414 \n",
      "\n",
      "loss: 0.645353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.601105 \n",
      "\n",
      "loss: 0.602626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.647603 \n",
      "\n",
      "loss: 0.653096  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.626831 \n",
      "\n",
      "loss: 0.625339  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.612285 \n",
      "\n",
      "loss: 0.605397  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.641336 \n",
      "\n",
      "loss: 0.669998  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.667424 \n",
      "\n",
      "loss: 0.662126  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.585131 \n",
      "\n",
      "loss: 0.576979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.669710 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 384/500\n",
      "--------------------\n",
      "{'hl': [219, 541], 'alpha': 0.008544841181312764, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.21913915254268623}\n",
      "loss: 1.055017  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.523680 \n",
      "\n",
      "loss: 1.526106  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.855237 \n",
      "\n",
      "loss: 0.862068  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.774174 \n",
      "\n",
      "loss: 0.806845  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.574841 \n",
      "\n",
      "loss: 0.575195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.544026 \n",
      "\n",
      "loss: 0.551989  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.664434 \n",
      "\n",
      "loss: 0.657023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.593631 \n",
      "\n",
      "loss: 0.581221  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.534736 \n",
      "\n",
      "loss: 0.541187  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.543285 \n",
      "\n",
      "loss: 0.522538  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.571822 \n",
      "\n",
      "loss: 0.518818  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.610747 \n",
      "\n",
      "loss: 0.620781  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.686338 \n",
      "\n",
      "loss: 0.715279  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.540304 \n",
      "\n",
      "loss: 0.562125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.498343 \n",
      "\n",
      "loss: 0.559353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.503974 \n",
      "\n",
      "loss: 0.493705  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.735471 \n",
      "\n",
      "loss: 0.770944  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.710148 \n",
      "\n",
      "loss: 0.690636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.517357 \n",
      "\n",
      "loss: 0.495315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.505267 \n",
      "\n",
      "loss: 0.522659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.514089 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 385/500\n",
      "--------------------\n",
      "{'hl': [471, 334, 76], 'alpha': 0.0015887528137891076, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.4246050860226502}\n",
      "loss: 1.090210  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.455211 \n",
      "\n",
      "loss: 0.424824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.427378 \n",
      "\n",
      "loss: 0.425196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.422419 \n",
      "\n",
      "loss: 0.400505  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.428829 \n",
      "\n",
      "loss: 0.441323  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.359161 \n",
      "\n",
      "loss: 0.379770  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.327315 \n",
      "\n",
      "loss: 0.385975  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.403694 \n",
      "\n",
      "loss: 0.408402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.340947 \n",
      "\n",
      "loss: 0.333891  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.350127 \n",
      "\n",
      "loss: 0.360618  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.388383 \n",
      "\n",
      "loss: 0.407900  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.380622 \n",
      "\n",
      "loss: 0.391660  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.334650 \n",
      "\n",
      "loss: 0.340693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.304675 \n",
      "\n",
      "loss: 0.290442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.315120 \n",
      "\n",
      "loss: 0.311801  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.300434 \n",
      "\n",
      "loss: 0.323104  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.310017 \n",
      "\n",
      "loss: 0.308385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.319271 \n",
      "\n",
      "loss: 0.301058  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.302748 \n",
      "\n",
      "loss: 0.299213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.285397 \n",
      "\n",
      "loss: 0.293134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.263086 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 386/500\n",
      "--------------------\n",
      "{'hl': [119, 701, 176], 'alpha': 0.5244327271561038, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.2759999538835275}\n",
      "loss: 1.108408  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.963223 \n",
      "\n",
      "loss: 0.962289  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.966530 \n",
      "\n",
      "loss: 0.964088  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.962093 \n",
      "\n",
      "loss: 0.964937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.964770 \n",
      "\n",
      "loss: 0.962096  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962638 \n",
      "\n",
      "loss: 0.963518  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.964888 \n",
      "\n",
      "loss: 0.966573  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.964771 \n",
      "\n",
      "loss: 0.964999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.961926 \n",
      "\n",
      "loss: 0.966955  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.965728 \n",
      "\n",
      "loss: 0.964608  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.964130 \n",
      "\n",
      "loss: 0.967277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.965903 \n",
      "\n",
      "loss: 0.966178  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.965365 \n",
      "\n",
      "loss: 0.966243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.961334 \n",
      "\n",
      "loss: 0.965964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.963660 \n",
      "\n",
      "loss: 0.963591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962113 \n",
      "\n",
      "loss: 0.968027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.964499 \n",
      "\n",
      "loss: 0.961238  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.965482 \n",
      "\n",
      "loss: 0.959301  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.961094 \n",
      "\n",
      "loss: 0.967499  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.964679 \n",
      "\n",
      "loss: 0.966785  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.964258 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 387/500\n",
      "--------------------\n",
      "{'hl': [581, 444], 'alpha': 0.6821038281821366, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3149171834074515}\n",
      "loss: 1.133928  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 4.627170 \n",
      "\n",
      "loss: 4.719037  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 3.087370 \n",
      "\n",
      "loss: 2.973151  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 33.4%, Avg loss: 35.548281 \n",
      "\n",
      "loss: 35.312729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 5.053441 \n",
      "\n",
      "loss: 5.437075  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 11.615653 \n",
      "\n",
      "loss: 12.281420  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 5.849932 \n",
      "\n",
      "loss: 6.007795  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 36.8%, Avg loss: 14.477581 \n",
      "\n",
      "loss: 14.980884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 32.4%, Avg loss: 33.465165 \n",
      "\n",
      "loss: 32.622684  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 9.118920 \n",
      "\n",
      "loss: 8.684332  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 36.4%, Avg loss: 19.266925 \n",
      "\n",
      "loss: 18.127558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 15.810716 \n",
      "\n",
      "loss: 15.831262  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 6.029792 \n",
      "\n",
      "loss: 5.738475  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 3.952880 \n",
      "\n",
      "loss: 3.898451  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 15.081563 \n",
      "\n",
      "loss: 15.215616  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 7.999430 \n",
      "\n",
      "loss: 7.801211  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 33.588492 \n",
      "\n",
      "loss: 33.599606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 30.7%, Avg loss: 18.654213 \n",
      "\n",
      "loss: 18.705185  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 15.2%, Avg loss: 15.773133 \n",
      "\n",
      "loss: 15.576099  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 30.9%, Avg loss: 25.247681 \n",
      "\n",
      "loss: 24.611727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 6.582979 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 388/500\n",
      "--------------------\n",
      "{'hl': [663], 'alpha': 0.04258254799973799, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.36872044593611397}\n",
      "loss: 1.090055  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 6.684527 \n",
      "\n",
      "loss: 6.216729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 2.555236 \n",
      "\n",
      "loss: 2.734348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.989421 \n",
      "\n",
      "loss: 1.933627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 1.023802 \n",
      "\n",
      "loss: 1.065170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 1.963139 \n",
      "\n",
      "loss: 2.220191  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 2.765522 \n",
      "\n",
      "loss: 3.167587  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 4.076993 \n",
      "\n",
      "loss: 4.039781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 5.009752 \n",
      "\n",
      "loss: 5.363228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 13.598127 \n",
      "\n",
      "loss: 14.252363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 1.866288 \n",
      "\n",
      "loss: 1.905287  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 3.858979 \n",
      "\n",
      "loss: 4.129145  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 2.149684 \n",
      "\n",
      "loss: 2.350595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 6.676654 \n",
      "\n",
      "loss: 7.130563  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 1.127162 \n",
      "\n",
      "loss: 1.361443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 1.230599 \n",
      "\n",
      "loss: 1.190901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 2.056876 \n",
      "\n",
      "loss: 1.906419  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 1.561013 \n",
      "\n",
      "loss: 1.480266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 7.933935 \n",
      "\n",
      "loss: 8.576492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 13.441024 \n",
      "\n",
      "loss: 12.824269  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 1.732816 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 389/500\n",
      "--------------------\n",
      "{'hl': [468], 'alpha': 0.023378284177183375, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.35239733441827126}\n",
      "loss: 1.273557  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 2.318377 \n",
      "\n",
      "loss: 2.119922  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.560202 \n",
      "\n",
      "loss: 1.479840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 1.504113 \n",
      "\n",
      "loss: 1.460539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 4.330111 \n",
      "\n",
      "loss: 4.070555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.887765 \n",
      "\n",
      "loss: 0.871994  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.990813 \n",
      "\n",
      "loss: 1.038362  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.844654 \n",
      "\n",
      "loss: 0.865246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 3.153846 \n",
      "\n",
      "loss: 2.958438  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.058420 \n",
      "\n",
      "loss: 1.205798  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 1.617727 \n",
      "\n",
      "loss: 1.468552  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 7.000464 \n",
      "\n",
      "loss: 6.817430  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.852747 \n",
      "\n",
      "loss: 0.889363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 1.209312 \n",
      "\n",
      "loss: 1.198612  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.658470 \n",
      "\n",
      "loss: 0.694097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.390464 \n",
      "\n",
      "loss: 1.503573  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 1.185474 \n",
      "\n",
      "loss: 1.055365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.626506 \n",
      "\n",
      "loss: 1.640674  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 2.690520 \n",
      "\n",
      "loss: 2.491158  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2.299174 \n",
      "\n",
      "loss: 2.217318  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 1.842218 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 390/500\n",
      "--------------------\n",
      "{'hl': [293], 'alpha': 0.10216496285590626, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.39977122820766614}\n",
      "loss: 1.133932  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.493964 \n",
      "\n",
      "loss: 0.468803  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.503920 \n",
      "\n",
      "loss: 0.497357  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.502899 \n",
      "\n",
      "loss: 0.504966  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.481316 \n",
      "\n",
      "loss: 0.489292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.487131 \n",
      "\n",
      "loss: 0.491165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.498365 \n",
      "\n",
      "loss: 0.460691  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.502022 \n",
      "\n",
      "loss: 0.488386  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.499801 \n",
      "\n",
      "loss: 0.461038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.484276 \n",
      "\n",
      "loss: 0.526209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.499501 \n",
      "\n",
      "loss: 0.503995  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.497536 \n",
      "\n",
      "loss: 0.479910  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.517703 \n",
      "\n",
      "loss: 0.468406  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.496711 \n",
      "\n",
      "loss: 0.509831  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.492208 \n",
      "\n",
      "loss: 0.514919  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.499089 \n",
      "\n",
      "loss: 0.483059  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.492063 \n",
      "\n",
      "loss: 0.494321  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.503178 \n",
      "\n",
      "loss: 0.506104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.501910 \n",
      "\n",
      "loss: 0.506820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.495688 \n",
      "\n",
      "loss: 0.509086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.504413 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 391/500\n",
      "--------------------\n",
      "{'hl': [199, 382, 341], 'alpha': 0.0006141820230287792, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.33538364396938686}\n",
      "loss: 1.102931  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 3270.941705 \n",
      "\n",
      "loss: 3117.078125  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 2.661575 \n",
      "\n",
      "loss: 0.857848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 1.034202 \n",
      "\n",
      "loss: 0.833721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.051488 \n",
      "\n",
      "loss: 1.055424  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.812220 \n",
      "\n",
      "loss: 0.821277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.821813 \n",
      "\n",
      "loss: 0.849098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.828775 \n",
      "\n",
      "loss: 0.861781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 0.848702 \n",
      "\n",
      "loss: 0.858016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 61.603413 \n",
      "\n",
      "loss: 65.752167  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.089109 \n",
      "\n",
      "loss: 1.137851  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.818357 \n",
      "\n",
      "loss: 0.834720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 1.373189 \n",
      "\n",
      "loss: 1.211082  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.004087 \n",
      "\n",
      "loss: 0.944889  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 36.5%, Avg loss: 164.174115 \n",
      "\n",
      "loss: 161.723923  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.950944 \n",
      "\n",
      "loss: 0.953292  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.818570 \n",
      "\n",
      "loss: 0.824716  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.207532 \n",
      "\n",
      "loss: 1.233050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 0.814235 \n",
      "\n",
      "loss: 0.819825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.032868 \n",
      "\n",
      "loss: 1.084031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 0.911681 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 392/500\n",
      "--------------------\n",
      "{'hl': [548, 662], 'alpha': 0.0017931492554123577, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.29354365681115246}\n",
      "loss: 1.127729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 5.258951 \n",
      "\n",
      "loss: 4.828506  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 10.896013 \n",
      "\n",
      "loss: 10.742619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 4.076067 \n",
      "\n",
      "loss: 3.404591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 9.172940 \n",
      "\n",
      "loss: 9.071975  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 6.482166 \n",
      "\n",
      "loss: 6.683975  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 9.416032 \n",
      "\n",
      "loss: 9.652525  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 6.168552 \n",
      "\n",
      "loss: 5.900363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 11.681198 \n",
      "\n",
      "loss: 11.799870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 6.183965 \n",
      "\n",
      "loss: 7.509634  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 9.022435 \n",
      "\n",
      "loss: 9.169119  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 5.050553 \n",
      "\n",
      "loss: 5.089193  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 13.725925 \n",
      "\n",
      "loss: 14.348789  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 11.897738 \n",
      "\n",
      "loss: 10.993116  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 26.4%, Avg loss: 3.807767 \n",
      "\n",
      "loss: 3.671057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 8.072788 \n",
      "\n",
      "loss: 10.348731  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 6.259494 \n",
      "\n",
      "loss: 6.497258  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 9.002540 \n",
      "\n",
      "loss: 8.769949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 8.684688 \n",
      "\n",
      "loss: 8.239114  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 13.339046 \n",
      "\n",
      "loss: 14.286436  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 3.023762 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 393/500\n",
      "--------------------\n",
      "{'hl': [368, 476], 'alpha': 0.02947478985066584, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.33608782985031965}\n",
      "loss: 1.119661  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.471189 \n",
      "\n",
      "loss: 0.467723  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.444959 \n",
      "\n",
      "loss: 0.443843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.419948 \n",
      "\n",
      "loss: 0.414868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.401314 \n",
      "\n",
      "loss: 0.380440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.395350 \n",
      "\n",
      "loss: 0.394891  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.399918 \n",
      "\n",
      "loss: 0.412094  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.412239 \n",
      "\n",
      "loss: 0.396390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.403982 \n",
      "\n",
      "loss: 0.418902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.395620 \n",
      "\n",
      "loss: 0.388015  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.401591 \n",
      "\n",
      "loss: 0.385030  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.400767 \n",
      "\n",
      "loss: 0.390909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.397580 \n",
      "\n",
      "loss: 0.392654  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.398660 \n",
      "\n",
      "loss: 0.395835  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.395366 \n",
      "\n",
      "loss: 0.394051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.380760 \n",
      "\n",
      "loss: 0.429542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.394178 \n",
      "\n",
      "loss: 0.375787  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.405617 \n",
      "\n",
      "loss: 0.392763  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.396061 \n",
      "\n",
      "loss: 0.381586  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.403312 \n",
      "\n",
      "loss: 0.426211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.398926 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 394/500\n",
      "--------------------\n",
      "{'hl': [128, 252], 'alpha': 0.001665405559669503, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3467489272040511}\n",
      "loss: 1.106805  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 3.650432 \n",
      "\n",
      "loss: 3.460310  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 2.158757 \n",
      "\n",
      "loss: 2.050220  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 4.068281 \n",
      "\n",
      "loss: 3.758037  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 4.339410 \n",
      "\n",
      "loss: 4.801746  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 1.918711 \n",
      "\n",
      "loss: 1.823027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 2.944055 \n",
      "\n",
      "loss: 2.635067  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 3.511525 \n",
      "\n",
      "loss: 3.647250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 2.313821 \n",
      "\n",
      "loss: 2.145943  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 2.117416 \n",
      "\n",
      "loss: 2.255765  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 3.037317 \n",
      "\n",
      "loss: 3.088817  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 2.099394 \n",
      "\n",
      "loss: 2.064324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.734559 \n",
      "\n",
      "loss: 1.692448  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 2.367508 \n",
      "\n",
      "loss: 2.244653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.761271 \n",
      "\n",
      "loss: 1.773329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 2.272057 \n",
      "\n",
      "loss: 2.227480  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 1.674180 \n",
      "\n",
      "loss: 1.509175  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 2.485839 \n",
      "\n",
      "loss: 2.745050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 1.356142 \n",
      "\n",
      "loss: 1.251621  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 7.130131 \n",
      "\n",
      "loss: 7.324660  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 3.645703 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 395/500\n",
      "--------------------\n",
      "{'hl': [405, 436, 618], 'alpha': 0.0003560157358340568, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.09295827427645355}\n",
      "loss: 1.285423  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.542775 \n",
      "\n",
      "loss: 1.688261  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 1.055987 \n",
      "\n",
      "loss: 0.985343  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.605069 \n",
      "\n",
      "loss: 1.529715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.090746 \n",
      "\n",
      "loss: 4.004632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.712215 \n",
      "\n",
      "loss: 2.089109  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.879240 \n",
      "\n",
      "loss: 0.864876  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.887002 \n",
      "\n",
      "loss: 1.840723  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.982912 \n",
      "\n",
      "loss: 0.978543  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 3.863325 \n",
      "\n",
      "loss: 3.504464  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 2.077358 \n",
      "\n",
      "loss: 2.074357  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 6.524707 \n",
      "\n",
      "loss: 6.473917  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.076202 \n",
      "\n",
      "loss: 1.032541  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.980276 \n",
      "\n",
      "loss: 0.963564  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.912951 \n",
      "\n",
      "loss: 0.916983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.654230 \n",
      "\n",
      "loss: 2.431322  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.261154 \n",
      "\n",
      "loss: 2.302211  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.126724 \n",
      "\n",
      "loss: 1.123799  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.873967 \n",
      "\n",
      "loss: 0.869125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.145826 \n",
      "\n",
      "loss: 1.129759  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.867821 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 396/500\n",
      "--------------------\n",
      "{'hl': [558, 718, 668], 'alpha': 0.5281773226864312, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.2448720488934852}\n",
      "loss: 1.106342  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.963218 \n",
      "\n",
      "loss: 0.954241  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.966602 \n",
      "\n",
      "loss: 0.965782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.965663 \n",
      "\n",
      "loss: 0.962681  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.965366 \n",
      "\n",
      "loss: 0.963693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.963716 \n",
      "\n",
      "loss: 0.961731  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.966059 \n",
      "\n",
      "loss: 0.963636  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.965983 \n",
      "\n",
      "loss: 0.967436  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.964332 \n",
      "\n",
      "loss: 0.968059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.964670 \n",
      "\n",
      "loss: 0.973312  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962339 \n",
      "\n",
      "loss: 0.961110  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.967698 \n",
      "\n",
      "loss: 0.967112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.966384 \n",
      "\n",
      "loss: 0.964130  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.962216 \n",
      "\n",
      "loss: 0.958361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.963920 \n",
      "\n",
      "loss: 0.961849  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.965553 \n",
      "\n",
      "loss: 0.966021  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.964694 \n",
      "\n",
      "loss: 0.958884  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.966908 \n",
      "\n",
      "loss: 0.964626  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.961828 \n",
      "\n",
      "loss: 0.961189  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.964322 \n",
      "\n",
      "loss: 0.967953  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.962588 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 397/500\n",
      "--------------------\n",
      "{'hl': [199], 'alpha': 0.001812675473912294, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.43277456320512053}\n",
      "loss: 1.126247  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 1.187959 \n",
      "\n",
      "loss: 1.176317  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.132235 \n",
      "\n",
      "loss: 1.067906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.681821 \n",
      "\n",
      "loss: 0.704799  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.543302 \n",
      "\n",
      "loss: 0.534070  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.825518 \n",
      "\n",
      "loss: 0.708719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.310949 \n",
      "\n",
      "loss: 1.389379  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.492859 \n",
      "\n",
      "loss: 0.457517  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 1.767306 \n",
      "\n",
      "loss: 1.799622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.873347 \n",
      "\n",
      "loss: 0.891568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510884 \n",
      "\n",
      "loss: 0.537484  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.756118 \n",
      "\n",
      "loss: 0.745236  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.671619 \n",
      "\n",
      "loss: 0.646193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.645178 \n",
      "\n",
      "loss: 0.606714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.508219 \n",
      "\n",
      "loss: 0.523640  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.483988 \n",
      "\n",
      "loss: 0.440114  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.731117 \n",
      "\n",
      "loss: 0.737851  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.518690 \n",
      "\n",
      "loss: 0.463833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.441920 \n",
      "\n",
      "loss: 0.452935  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.485880 \n",
      "\n",
      "loss: 0.505049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.466842 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 398/500\n",
      "--------------------\n",
      "{'hl': [504], 'alpha': 0.000351672864275969, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2046262607491006}\n",
      "loss: 1.182244  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 2.058668 \n",
      "\n",
      "loss: 1.972147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 2.097191 \n",
      "\n",
      "loss: 2.087209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 1.100546 \n",
      "\n",
      "loss: 0.971650  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 1.377658 \n",
      "\n",
      "loss: 1.237862  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 1.231338 \n",
      "\n",
      "loss: 1.072726  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.754012 \n",
      "\n",
      "loss: 1.689899  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 1.113100 \n",
      "\n",
      "loss: 1.005723  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 1.001211 \n",
      "\n",
      "loss: 1.041722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.865288 \n",
      "\n",
      "loss: 0.998207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 1.503459 \n",
      "\n",
      "loss: 1.335570  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.912901 \n",
      "\n",
      "loss: 0.908163  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 1.617368 \n",
      "\n",
      "loss: 1.279090  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.848808 \n",
      "\n",
      "loss: 0.779782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 1.679529 \n",
      "\n",
      "loss: 1.748490  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 1.637464 \n",
      "\n",
      "loss: 1.510532  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 2.122366 \n",
      "\n",
      "loss: 1.578132  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 1.066374 \n",
      "\n",
      "loss: 1.115501  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 1.531243 \n",
      "\n",
      "loss: 1.572914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 1.105910 \n",
      "\n",
      "loss: 1.058244  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 1.127430 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 399/500\n",
      "--------------------\n",
      "{'hl': [433, 462], 'alpha': 0.009011519934707012, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3979608567122534}\n",
      "loss: 1.110337  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.456502 \n",
      "\n",
      "loss: 0.422148  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.408654 \n",
      "\n",
      "loss: 0.401199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.381561 \n",
      "\n",
      "loss: 0.387339  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.395438 \n",
      "\n",
      "loss: 0.381972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.368762 \n",
      "\n",
      "loss: 0.412385  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.402294 \n",
      "\n",
      "loss: 0.369020  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.371277 \n",
      "\n",
      "loss: 0.373527  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.350439 \n",
      "\n",
      "loss: 0.300834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.364537 \n",
      "\n",
      "loss: 0.356714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.361714 \n",
      "\n",
      "loss: 0.365755  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.371453 \n",
      "\n",
      "loss: 0.425438  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.366646 \n",
      "\n",
      "loss: 0.367078  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.360657 \n",
      "\n",
      "loss: 0.341903  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.367182 \n",
      "\n",
      "loss: 0.352771  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.340502 \n",
      "\n",
      "loss: 0.357211  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.353535 \n",
      "\n",
      "loss: 0.298324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.363928 \n",
      "\n",
      "loss: 0.367579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.350245 \n",
      "\n",
      "loss: 0.337680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.383730 \n",
      "\n",
      "loss: 0.357560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.341896 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 400/500\n",
      "--------------------\n",
      "{'hl': [307], 'alpha': 0.0001351388900076028, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.0841876678205432}\n",
      "loss: 1.111818  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.687539 \n",
      "\n",
      "loss: 0.617344  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.421717 \n",
      "\n",
      "loss: 0.380118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.371015 \n",
      "\n",
      "loss: 0.335990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.479478 \n",
      "\n",
      "loss: 0.438239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.359821 \n",
      "\n",
      "loss: 0.340260  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.362656 \n",
      "\n",
      "loss: 0.322901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360276 \n",
      "\n",
      "loss: 0.340632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.362248 \n",
      "\n",
      "loss: 0.369496  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.346075 \n",
      "\n",
      "loss: 0.302951  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.379041 \n",
      "\n",
      "loss: 0.470599  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.421172 \n",
      "\n",
      "loss: 0.380629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.374237 \n",
      "\n",
      "loss: 0.381312  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.405252 \n",
      "\n",
      "loss: 0.401317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.388942 \n",
      "\n",
      "loss: 0.362287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.376324 \n",
      "\n",
      "loss: 0.361272  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.392454 \n",
      "\n",
      "loss: 0.349544  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.444380 \n",
      "\n",
      "loss: 0.405461  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.519831 \n",
      "\n",
      "loss: 0.488596  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.447627 \n",
      "\n",
      "loss: 0.476526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.365225 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 401/500\n",
      "--------------------\n",
      "{'hl': [587, 515], 'alpha': 0.015809012329051006, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.13401766580551114}\n",
      "loss: 1.097870  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.490468 \n",
      "\n",
      "loss: 0.496605  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.466224 \n",
      "\n",
      "loss: 0.509170  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.438709 \n",
      "\n",
      "loss: 0.462523  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.431267 \n",
      "\n",
      "loss: 0.410122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.405568 \n",
      "\n",
      "loss: 0.430777  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.401090 \n",
      "\n",
      "loss: 0.380307  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.405271 \n",
      "\n",
      "loss: 0.395159  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.388146 \n",
      "\n",
      "loss: 0.427000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.382382 \n",
      "\n",
      "loss: 0.346300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.366814 \n",
      "\n",
      "loss: 0.379706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.378516 \n",
      "\n",
      "loss: 0.399916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.382947 \n",
      "\n",
      "loss: 0.380180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.379457 \n",
      "\n",
      "loss: 0.399989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.366398 \n",
      "\n",
      "loss: 0.349809  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.361593 \n",
      "\n",
      "loss: 0.377976  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.364808 \n",
      "\n",
      "loss: 0.372857  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.368107 \n",
      "\n",
      "loss: 0.404406  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.366298 \n",
      "\n",
      "loss: 0.416265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.364029 \n",
      "\n",
      "loss: 0.340248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.358341 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 402/500\n",
      "--------------------\n",
      "{'hl': [383, 563, 50], 'alpha': 0.10965199145596241, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.49488888636555395}\n",
      "loss: 1.148262  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.824603 \n",
      "\n",
      "loss: 0.824872  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.874014 \n",
      "\n",
      "loss: 0.864846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.993904 \n",
      "\n",
      "loss: 0.981443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.829985 \n",
      "\n",
      "loss: 0.819275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.125282 \n",
      "\n",
      "loss: 1.106785  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.946344 \n",
      "\n",
      "loss: 0.964454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.845171 \n",
      "\n",
      "loss: 0.837965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.843359 \n",
      "\n",
      "loss: 0.844499  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.890730 \n",
      "\n",
      "loss: 0.894152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.838151 \n",
      "\n",
      "loss: 0.833808  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.873632 \n",
      "\n",
      "loss: 0.857054  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.883632 \n",
      "\n",
      "loss: 0.890764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.832535 \n",
      "\n",
      "loss: 0.828718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.896975 \n",
      "\n",
      "loss: 0.893743  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.846264 \n",
      "\n",
      "loss: 0.835425  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.858913 \n",
      "\n",
      "loss: 0.863180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.112305 \n",
      "\n",
      "loss: 1.090599  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.853471 \n",
      "\n",
      "loss: 0.854314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.948044 \n",
      "\n",
      "loss: 0.970511  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.825968 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 403/500\n",
      "--------------------\n",
      "{'hl': [677], 'alpha': 0.10124695693236666, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.22492119818092382}\n",
      "loss: 1.060368  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.512283 \n",
      "\n",
      "loss: 0.491437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.506627 \n",
      "\n",
      "loss: 0.532897  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.503678 \n",
      "\n",
      "loss: 0.471718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.494229 \n",
      "\n",
      "loss: 0.524970  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.495648 \n",
      "\n",
      "loss: 0.512245  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.497345 \n",
      "\n",
      "loss: 0.473807  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.500381 \n",
      "\n",
      "loss: 0.484576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.492860 \n",
      "\n",
      "loss: 0.456370  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.487562 \n",
      "\n",
      "loss: 0.505955  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.494027 \n",
      "\n",
      "loss: 0.487856  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.501229 \n",
      "\n",
      "loss: 0.492125  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.496496 \n",
      "\n",
      "loss: 0.487246  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.492871 \n",
      "\n",
      "loss: 0.494216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.487761 \n",
      "\n",
      "loss: 0.490993  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.501072 \n",
      "\n",
      "loss: 0.494461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.490211 \n",
      "\n",
      "loss: 0.482071  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.494086 \n",
      "\n",
      "loss: 0.493959  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.495792 \n",
      "\n",
      "loss: 0.508169  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.486112 \n",
      "\n",
      "loss: 0.494755  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.483816 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 404/500\n",
      "--------------------\n",
      "{'hl': [97, 457], 'alpha': 0.2891757572397199, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.10501809597812806}\n",
      "loss: 1.075823  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.727352 \n",
      "\n",
      "loss: 0.726353  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.700253 \n",
      "\n",
      "loss: 0.700816  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.695756 \n",
      "\n",
      "loss: 0.686567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.689107 \n",
      "\n",
      "loss: 0.687304  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.695060 \n",
      "\n",
      "loss: 0.698725  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.686929 \n",
      "\n",
      "loss: 0.676802  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.695654 \n",
      "\n",
      "loss: 0.697019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.696178 \n",
      "\n",
      "loss: 0.688177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.686884 \n",
      "\n",
      "loss: 0.684317  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.693745 \n",
      "\n",
      "loss: 0.693486  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.690048 \n",
      "\n",
      "loss: 0.678323  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.696576 \n",
      "\n",
      "loss: 0.690071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.688437 \n",
      "\n",
      "loss: 0.687935  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.695889 \n",
      "\n",
      "loss: 0.698678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.689112 \n",
      "\n",
      "loss: 0.692571  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.690203 \n",
      "\n",
      "loss: 0.673523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.695797 \n",
      "\n",
      "loss: 0.689420  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.693391 \n",
      "\n",
      "loss: 0.688405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.689661 \n",
      "\n",
      "loss: 0.702924  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.694024 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 405/500\n",
      "--------------------\n",
      "{'hl': [610, 713, 367], 'alpha': 0.27809602744254175, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.30811398477109936}\n",
      "loss: 1.100451  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.333665 \n",
      "\n",
      "loss: 1.297791  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.256388 \n",
      "\n",
      "loss: 1.283603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.382043 \n",
      "\n",
      "loss: 1.399857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.215833 \n",
      "\n",
      "loss: 1.206557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.225112 \n",
      "\n",
      "loss: 1.310692  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.765765 \n",
      "\n",
      "loss: 1.766361  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.419927 \n",
      "\n",
      "loss: 1.378664  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.316312 \n",
      "\n",
      "loss: 1.360534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.403326 \n",
      "\n",
      "loss: 1.459644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.254469 \n",
      "\n",
      "loss: 1.209127  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.296321 \n",
      "\n",
      "loss: 1.262658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.371066 \n",
      "\n",
      "loss: 1.433050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.409685 \n",
      "\n",
      "loss: 1.376082  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.320104 \n",
      "\n",
      "loss: 1.391437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.486996 \n",
      "\n",
      "loss: 1.448567  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.338173 \n",
      "\n",
      "loss: 1.335637  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.363750 \n",
      "\n",
      "loss: 1.349057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.383119 \n",
      "\n",
      "loss: 1.391699  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.316368 \n",
      "\n",
      "loss: 1.255125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.180026 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 406/500\n",
      "--------------------\n",
      "{'hl': [219], 'alpha': 0.16663336842085627, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.29846915717371103}\n",
      "loss: 1.077671  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 5.280419 \n",
      "\n",
      "loss: 5.041819  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.737836 \n",
      "\n",
      "loss: 0.711836  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.552727 \n",
      "\n",
      "loss: 0.542380  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.545525 \n",
      "\n",
      "loss: 0.553846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.545544 \n",
      "\n",
      "loss: 0.544713  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.548920 \n",
      "\n",
      "loss: 0.540539  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.563492 \n",
      "\n",
      "loss: 0.556500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.564859 \n",
      "\n",
      "loss: 0.545568  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.540424 \n",
      "\n",
      "loss: 0.532007  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.542093 \n",
      "\n",
      "loss: 0.550983  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.547302 \n",
      "\n",
      "loss: 0.534436  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.593570 \n",
      "\n",
      "loss: 0.611559  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.562283 \n",
      "\n",
      "loss: 0.559364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.567863 \n",
      "\n",
      "loss: 0.568092  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.553486 \n",
      "\n",
      "loss: 0.568365  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.584286 \n",
      "\n",
      "loss: 0.577536  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.578684 \n",
      "\n",
      "loss: 0.537791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.574210 \n",
      "\n",
      "loss: 0.573449  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.543511 \n",
      "\n",
      "loss: 0.560583  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.533062 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 407/500\n",
      "--------------------\n",
      "{'hl': [339], 'alpha': 0.8241393022052166, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.2864105163488149}\n",
      "loss: 1.174862  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.666937 \n",
      "\n",
      "loss: 0.641708  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.868745 \n",
      "\n",
      "loss: 0.870199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.842321 \n",
      "\n",
      "loss: 0.843981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 0.848352 \n",
      "\n",
      "loss: 0.855755  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 0.870189 \n",
      "\n",
      "loss: 0.880049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.848868 \n",
      "\n",
      "loss: 0.848227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.873431 \n",
      "\n",
      "loss: 0.872195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.877467 \n",
      "\n",
      "loss: 0.887950  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.817967 \n",
      "\n",
      "loss: 0.805409  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.868187 \n",
      "\n",
      "loss: 0.870158  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.824672 \n",
      "\n",
      "loss: 0.820476  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 0.854830 \n",
      "\n",
      "loss: 0.838537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.872057 \n",
      "\n",
      "loss: 0.855765  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.852907 \n",
      "\n",
      "loss: 0.856280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.853641 \n",
      "\n",
      "loss: 0.856041  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.847822 \n",
      "\n",
      "loss: 0.844380  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.860329 \n",
      "\n",
      "loss: 0.851577  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.869441 \n",
      "\n",
      "loss: 0.881483  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.802895 \n",
      "\n",
      "loss: 0.810646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.847809 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 408/500\n",
      "--------------------\n",
      "{'hl': [703, 105, 146], 'alpha': 0.7097215297675865, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.49624386419977273}\n",
      "loss: 1.191542  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.856453 \n",
      "\n",
      "loss: 2.871564  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.870767 \n",
      "\n",
      "loss: 1.878945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.626400 \n",
      "\n",
      "loss: 2.708401  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.165321 \n",
      "\n",
      "loss: 2.048559  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.491688 \n",
      "\n",
      "loss: 2.572899  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.406440 \n",
      "\n",
      "loss: 2.390508  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.924656 \n",
      "\n",
      "loss: 2.973168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.251813 \n",
      "\n",
      "loss: 2.256756  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.422375 \n",
      "\n",
      "loss: 2.427265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.429078 \n",
      "\n",
      "loss: 2.424477  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.969906 \n",
      "\n",
      "loss: 2.979004  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.296822 \n",
      "\n",
      "loss: 2.235390  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 3.032589 \n",
      "\n",
      "loss: 3.078334  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 2.164982 \n",
      "\n",
      "loss: 2.212968  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.638984 \n",
      "\n",
      "loss: 2.733245  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.225962 \n",
      "\n",
      "loss: 2.169103  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.939273 \n",
      "\n",
      "loss: 2.830821  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.286028 \n",
      "\n",
      "loss: 2.311790  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.739989 \n",
      "\n",
      "loss: 2.682120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 2.034888 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 409/500\n",
      "--------------------\n",
      "{'hl': [137, 143, 263], 'alpha': 0.0003845685579073813, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.38076064638118046}\n",
      "loss: 1.090971  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.463428 \n",
      "\n",
      "loss: 0.468741  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.419421 \n",
      "\n",
      "loss: 0.419921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.384589 \n",
      "\n",
      "loss: 0.390347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.395709 \n",
      "\n",
      "loss: 0.399842  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.358304 \n",
      "\n",
      "loss: 0.371862  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.352633 \n",
      "\n",
      "loss: 0.347775  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.369180 \n",
      "\n",
      "loss: 0.350937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.347229 \n",
      "\n",
      "loss: 0.358402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.344793 \n",
      "\n",
      "loss: 0.336016  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.374597 \n",
      "\n",
      "loss: 0.383469  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.320545 \n",
      "\n",
      "loss: 0.359079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.336778 \n",
      "\n",
      "loss: 0.292512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.324150 \n",
      "\n",
      "loss: 0.296871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.306277 \n",
      "\n",
      "loss: 0.326973  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.290806 \n",
      "\n",
      "loss: 0.297421  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.298956 \n",
      "\n",
      "loss: 0.281328  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.353323 \n",
      "\n",
      "loss: 0.317807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.290019 \n",
      "\n",
      "loss: 0.327837  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.321947 \n",
      "\n",
      "loss: 0.351293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.276508 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 410/500\n",
      "--------------------\n",
      "{'hl': [410, 509, 153], 'alpha': 0.020403379958490616, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.18764864669032888}\n",
      "loss: 1.107674  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.1%, Avg loss: 361.944890 \n",
      "\n",
      "loss: 177.101654  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 28.448280 \n",
      "\n",
      "loss: 29.531868  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 55.955246 \n",
      "\n",
      "loss: 40.813293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 18.862232 \n",
      "\n",
      "loss: 18.067820  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 5.623518 \n",
      "\n",
      "loss: 5.827761  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 1.300313 \n",
      "\n",
      "loss: 1.187146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.861780 \n",
      "\n",
      "loss: 0.913342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.455595 \n",
      "\n",
      "loss: 0.449444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.488542 \n",
      "\n",
      "loss: 0.492851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.431912 \n",
      "\n",
      "loss: 0.432210  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.416838 \n",
      "\n",
      "loss: 0.413906  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.415112 \n",
      "\n",
      "loss: 0.420026  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.394603 \n",
      "\n",
      "loss: 0.380397  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.391184 \n",
      "\n",
      "loss: 0.367334  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.391392 \n",
      "\n",
      "loss: 0.423553  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.390764 \n",
      "\n",
      "loss: 0.380326  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.420538 \n",
      "\n",
      "loss: 0.429470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.394143 \n",
      "\n",
      "loss: 0.389697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.394044 \n",
      "\n",
      "loss: 0.375293  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.377494 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 411/500\n",
      "--------------------\n",
      "{'hl': [656], 'alpha': 0.15079763230590004, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.25785517469664077}\n",
      "loss: 1.093423  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.9%, Avg loss: 5.489650 \n",
      "\n",
      "loss: 4.697721  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.854801 \n",
      "\n",
      "loss: 1.817720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 8.761391 \n",
      "\n",
      "loss: 7.496677  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 13.919686 \n",
      "\n",
      "loss: 12.359405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 10.256784 \n",
      "\n",
      "loss: 8.856551  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 7.793269 \n",
      "\n",
      "loss: 7.839564  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 1.194949 \n",
      "\n",
      "loss: 1.127679  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.557295 \n",
      "\n",
      "loss: 0.537550  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.529133 \n",
      "\n",
      "loss: 0.502603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.560614 \n",
      "\n",
      "loss: 0.578267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.551423 \n",
      "\n",
      "loss: 0.574778  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.578390 \n",
      "\n",
      "loss: 0.557044  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.560435 \n",
      "\n",
      "loss: 0.550054  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.542856 \n",
      "\n",
      "loss: 0.563779  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.558092 \n",
      "\n",
      "loss: 0.585864  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.563381 \n",
      "\n",
      "loss: 0.567711  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.558426 \n",
      "\n",
      "loss: 0.563201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.540540 \n",
      "\n",
      "loss: 0.552967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.544286 \n",
      "\n",
      "loss: 0.535702  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.539445 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 412/500\n",
      "--------------------\n",
      "{'hl': [719, 385], 'alpha': 0.006588440016163185, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.2910195767800233}\n",
      "loss: 1.119126  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 4.754355 \n",
      "\n",
      "loss: 5.411133  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 4.207512 \n",
      "\n",
      "loss: 3.762115  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 2.923131 \n",
      "\n",
      "loss: 2.388846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 4.531354 \n",
      "\n",
      "loss: 4.462628  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 8.706430 \n",
      "\n",
      "loss: 8.655118  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 6.770376 \n",
      "\n",
      "loss: 7.153388  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 5.964613 \n",
      "\n",
      "loss: 6.459833  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 22.7%, Avg loss: 2.083746 \n",
      "\n",
      "loss: 2.096139  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 8.186417 \n",
      "\n",
      "loss: 8.130311  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 7.853008 \n",
      "\n",
      "loss: 7.777924  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.568012 \n",
      "\n",
      "loss: 4.278245  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 5.281696 \n",
      "\n",
      "loss: 4.099257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 3.252388 \n",
      "\n",
      "loss: 2.185190  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 3.893764 \n",
      "\n",
      "loss: 3.891708  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.374032 \n",
      "\n",
      "loss: 3.822639  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 9.233047 \n",
      "\n",
      "loss: 9.508623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 3.415459 \n",
      "\n",
      "loss: 3.405553  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 11.622737 \n",
      "\n",
      "loss: 11.814375  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 6.174990 \n",
      "\n",
      "loss: 6.123161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 5.376728 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 413/500\n",
      "--------------------\n",
      "{'hl': [103, 477, 658], 'alpha': 0.04534979031346057, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.3978593955312579}\n",
      "loss: 1.095524  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.482611 \n",
      "\n",
      "loss: 0.479817  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.461842 \n",
      "\n",
      "loss: 0.411526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.444998 \n",
      "\n",
      "loss: 0.454857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.433371 \n",
      "\n",
      "loss: 0.423423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.427614 \n",
      "\n",
      "loss: 0.440997  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.435910 \n",
      "\n",
      "loss: 0.428847  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.433282 \n",
      "\n",
      "loss: 0.430595  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.422128 \n",
      "\n",
      "loss: 0.428552  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.435676 \n",
      "\n",
      "loss: 0.422091  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.419954 \n",
      "\n",
      "loss: 0.421313  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.431454 \n",
      "\n",
      "loss: 0.457606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.425309 \n",
      "\n",
      "loss: 0.436961  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.432941 \n",
      "\n",
      "loss: 0.401320  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.423830 \n",
      "\n",
      "loss: 0.448682  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.418580 \n",
      "\n",
      "loss: 0.427266  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.421516 \n",
      "\n",
      "loss: 0.437384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.430050 \n",
      "\n",
      "loss: 0.440985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.431023 \n",
      "\n",
      "loss: 0.404524  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.413202 \n",
      "\n",
      "loss: 0.415348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.419873 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 414/500\n",
      "--------------------\n",
      "{'hl': [231, 447], 'alpha': 0.19924644921477763, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.16150028828001747}\n",
      "loss: 1.044632  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 4.491114 \n",
      "\n",
      "loss: 4.528072  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.293456 \n",
      "\n",
      "loss: 1.398750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.958362 \n",
      "\n",
      "loss: 3.125279  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 2.298358 \n",
      "\n",
      "loss: 2.404365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 7.742046 \n",
      "\n",
      "loss: 7.799363  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 3.295062 \n",
      "\n",
      "loss: 3.137085  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.218563 \n",
      "\n",
      "loss: 2.072263  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 3.507572 \n",
      "\n",
      "loss: 3.399848  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 4.206891 \n",
      "\n",
      "loss: 4.092010  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.904492 \n",
      "\n",
      "loss: 1.847746  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.025884 \n",
      "\n",
      "loss: 1.017642  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.895754 \n",
      "\n",
      "loss: 0.866207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.410183 \n",
      "\n",
      "loss: 1.439547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.481087 \n",
      "\n",
      "loss: 1.449988  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.878605 \n",
      "\n",
      "loss: 0.885671  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.912647 \n",
      "\n",
      "loss: 0.933096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.274824 \n",
      "\n",
      "loss: 1.340676  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.785485 \n",
      "\n",
      "loss: 1.768665  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 5.912520 \n",
      "\n",
      "loss: 5.599714  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.910718 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 415/500\n",
      "--------------------\n",
      "{'hl': [353, 568], 'alpha': 0.020499089001886454, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.44708791355347416}\n",
      "loss: 1.284833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 13.567938 \n",
      "\n",
      "loss: 14.024351  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 12.198345 \n",
      "\n",
      "loss: 11.875268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 38.8%, Avg loss: 9.503407 \n",
      "\n",
      "loss: 9.133677  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 16.257537 \n",
      "\n",
      "loss: 15.953604  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 25.940360 \n",
      "\n",
      "loss: 25.444742  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.458133 \n",
      "\n",
      "loss: 12.553187  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 22.504005 \n",
      "\n",
      "loss: 21.470154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 16.948968 \n",
      "\n",
      "loss: 18.055136  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 11.660238 \n",
      "\n",
      "loss: 11.333200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 28.964415 \n",
      "\n",
      "loss: 30.323257  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 18.730335 \n",
      "\n",
      "loss: 18.823212  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 4.629676 \n",
      "\n",
      "loss: 3.584540  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 8.404690 \n",
      "\n",
      "loss: 7.304646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 23.130578 \n",
      "\n",
      "loss: 22.350178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 22.063629 \n",
      "\n",
      "loss: 21.328747  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 30.148818 \n",
      "\n",
      "loss: 32.258762  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 10.202079 \n",
      "\n",
      "loss: 9.845400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 16.738891 \n",
      "\n",
      "loss: 16.903969  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 8.320349 \n",
      "\n",
      "loss: 8.214259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 12.358086 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 416/500\n",
      "--------------------\n",
      "{'hl': [55], 'alpha': 0.0002502067188247076, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.06220616589727619}\n",
      "loss: 0.985554  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.678710 \n",
      "\n",
      "loss: 0.680973  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.606737 \n",
      "\n",
      "loss: 0.570843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.573545 \n",
      "\n",
      "loss: 0.545937  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.532663 \n",
      "\n",
      "loss: 0.578066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.525178 \n",
      "\n",
      "loss: 0.533471  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.513879 \n",
      "\n",
      "loss: 0.528004  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.517404 \n",
      "\n",
      "loss: 0.493332  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.514666 \n",
      "\n",
      "loss: 0.505768  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.500640 \n",
      "\n",
      "loss: 0.483653  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.509089 \n",
      "\n",
      "loss: 0.489378  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.504514 \n",
      "\n",
      "loss: 0.561777  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.513806 \n",
      "\n",
      "loss: 0.481700  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.503920 \n",
      "\n",
      "loss: 0.496493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.496231 \n",
      "\n",
      "loss: 0.496600  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.493073 \n",
      "\n",
      "loss: 0.546236  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.485152 \n",
      "\n",
      "loss: 0.530845  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.507469 \n",
      "\n",
      "loss: 0.497681  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.487566 \n",
      "\n",
      "loss: 0.483816  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.488950 \n",
      "\n",
      "loss: 0.535629  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.488410 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 417/500\n",
      "--------------------\n",
      "{'hl': [459], 'alpha': 0.006699965152532858, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.49784746496027016}\n",
      "loss: 1.229485  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 1.599250 \n",
      "\n",
      "loss: 1.789716  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 1.157403 \n",
      "\n",
      "loss: 1.068692  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 1.345764 \n",
      "\n",
      "loss: 1.152360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 2.175781 \n",
      "\n",
      "loss: 2.219774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 1.368735 \n",
      "\n",
      "loss: 1.244157  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 1.106297 \n",
      "\n",
      "loss: 1.249622  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.924801 \n",
      "\n",
      "loss: 0.849403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.765479 \n",
      "\n",
      "loss: 1.747536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.755941 \n",
      "\n",
      "loss: 0.846328  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.847304 \n",
      "\n",
      "loss: 0.860321  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.778364 \n",
      "\n",
      "loss: 0.795338  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.956006 \n",
      "\n",
      "loss: 0.972069  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 44.7%, Avg loss: 3.113479 \n",
      "\n",
      "loss: 2.996808  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.730667 \n",
      "\n",
      "loss: 0.708509  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.649182 \n",
      "\n",
      "loss: 0.687901  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.950166 \n",
      "\n",
      "loss: 1.166181  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 1.136619 \n",
      "\n",
      "loss: 1.174932  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.839838 \n",
      "\n",
      "loss: 0.874240  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.681102 \n",
      "\n",
      "loss: 0.623367  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.963678 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 418/500\n",
      "--------------------\n",
      "{'hl': [673], 'alpha': 0.0016123600075102558, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.32732852341295515}\n",
      "loss: 1.213824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.440689 \n",
      "\n",
      "loss: 0.424634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.419077 \n",
      "\n",
      "loss: 0.410209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.393462 \n",
      "\n",
      "loss: 0.365248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.385807 \n",
      "\n",
      "loss: 0.374573  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.342753 \n",
      "\n",
      "loss: 0.351771  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.345698 \n",
      "\n",
      "loss: 0.387002  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.388187 \n",
      "\n",
      "loss: 0.392579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.343131 \n",
      "\n",
      "loss: 0.336992  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360395 \n",
      "\n",
      "loss: 0.351500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.333425 \n",
      "\n",
      "loss: 0.363437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.325016 \n",
      "\n",
      "loss: 0.338576  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.339348 \n",
      "\n",
      "loss: 0.287095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.326397 \n",
      "\n",
      "loss: 0.334168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.331918 \n",
      "\n",
      "loss: 0.311490  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.301426 \n",
      "\n",
      "loss: 0.313530  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.314861 \n",
      "\n",
      "loss: 0.316706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.318329 \n",
      "\n",
      "loss: 0.318106  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.310827 \n",
      "\n",
      "loss: 0.299792  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.321618 \n",
      "\n",
      "loss: 0.322482  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.303881 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 419/500\n",
      "--------------------\n",
      "{'hl': [92, 388], 'alpha': 0.045502498670977616, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.19823114930942337}\n",
      "loss: 1.079152  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.506419 \n",
      "\n",
      "loss: 0.499718  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.501728 \n",
      "\n",
      "loss: 0.524601  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.499454 \n",
      "\n",
      "loss: 0.514033  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.491836 \n",
      "\n",
      "loss: 0.519231  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.495548 \n",
      "\n",
      "loss: 0.519288  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.500649 \n",
      "\n",
      "loss: 0.498096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.488806 \n",
      "\n",
      "loss: 0.476286  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.490363 \n",
      "\n",
      "loss: 0.486282  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.479712 \n",
      "\n",
      "loss: 0.479795  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.483792 \n",
      "\n",
      "loss: 0.497848  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.478780 \n",
      "\n",
      "loss: 0.456902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.486219 \n",
      "\n",
      "loss: 0.503552  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.489194 \n",
      "\n",
      "loss: 0.478672  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.475356 \n",
      "\n",
      "loss: 0.466438  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.484427 \n",
      "\n",
      "loss: 0.496887  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.486199 \n",
      "\n",
      "loss: 0.487243  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.481136 \n",
      "\n",
      "loss: 0.472764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.475676 \n",
      "\n",
      "loss: 0.482992  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.479219 \n",
      "\n",
      "loss: 0.505874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.486614 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 420/500\n",
      "--------------------\n",
      "{'hl': [247, 447], 'alpha': 0.04187365914525958, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.10678924635541193}\n",
      "loss: 1.082747  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.526581 \n",
      "\n",
      "loss: 0.491526  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.483625 \n",
      "\n",
      "loss: 0.495306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.465221 \n",
      "\n",
      "loss: 0.477601  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.467137 \n",
      "\n",
      "loss: 0.480400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.447874 \n",
      "\n",
      "loss: 0.436751  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.450084 \n",
      "\n",
      "loss: 0.424996  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.443645 \n",
      "\n",
      "loss: 0.483483  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.446062 \n",
      "\n",
      "loss: 0.438953  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.429104 \n",
      "\n",
      "loss: 0.435679  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.428319 \n",
      "\n",
      "loss: 0.436697  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.423119 \n",
      "\n",
      "loss: 0.460391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.442877 \n",
      "\n",
      "loss: 0.449532  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.429816 \n",
      "\n",
      "loss: 0.439509  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.418168 \n",
      "\n",
      "loss: 0.451184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.412297 \n",
      "\n",
      "loss: 0.422902  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.414675 \n",
      "\n",
      "loss: 0.429750  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.433230 \n",
      "\n",
      "loss: 0.438358  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.424227 \n",
      "\n",
      "loss: 0.456778  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.414607 \n",
      "\n",
      "loss: 0.430124  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.426093 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 421/500\n",
      "--------------------\n",
      "{'hl': [143], 'alpha': 0.02369834334814421, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.0041304782526864784}\n",
      "loss: 1.082566  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 0.843937 \n",
      "\n",
      "loss: 0.844391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 0.797743 \n",
      "\n",
      "loss: 0.786475  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.768485 \n",
      "\n",
      "loss: 0.754716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.747954 \n",
      "\n",
      "loss: 0.777992  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.731703 \n",
      "\n",
      "loss: 0.724401  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.725854 \n",
      "\n",
      "loss: 0.754149  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.716746 \n",
      "\n",
      "loss: 0.723199  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.701124 \n",
      "\n",
      "loss: 0.691560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.695714 \n",
      "\n",
      "loss: 0.717307  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.673084 \n",
      "\n",
      "loss: 0.677391  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.679160 \n",
      "\n",
      "loss: 0.677591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.665347 \n",
      "\n",
      "loss: 0.664353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.659072 \n",
      "\n",
      "loss: 0.667206  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.656551 \n",
      "\n",
      "loss: 0.625783  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.641374 \n",
      "\n",
      "loss: 0.645942  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.642399 \n",
      "\n",
      "loss: 0.650595  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.643395 \n",
      "\n",
      "loss: 0.683644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.647627 \n",
      "\n",
      "loss: 0.654209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.625004 \n",
      "\n",
      "loss: 0.631512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.613322 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 422/500\n",
      "--------------------\n",
      "{'hl': [131, 440], 'alpha': 0.059720578293834765, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.11455053904277572}\n",
      "loss: 1.040976  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.600861 \n",
      "\n",
      "loss: 2.555628  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.454625 \n",
      "\n",
      "loss: 1.460779  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.726921 \n",
      "\n",
      "loss: 1.721888  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.306606 \n",
      "\n",
      "loss: 1.327658  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.562136 \n",
      "\n",
      "loss: 1.534950  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.218204 \n",
      "\n",
      "loss: 1.191333  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.519332 \n",
      "\n",
      "loss: 1.432297  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.153999 \n",
      "\n",
      "loss: 1.149678  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.276079 \n",
      "\n",
      "loss: 1.243921  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.133406 \n",
      "\n",
      "loss: 1.098256  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.368602 \n",
      "\n",
      "loss: 1.331492  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.109079 \n",
      "\n",
      "loss: 1.090279  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.507099 \n",
      "\n",
      "loss: 1.601716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.982848 \n",
      "\n",
      "loss: 0.959555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.171699 \n",
      "\n",
      "loss: 1.185812  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.208635 \n",
      "\n",
      "loss: 1.197011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.341864 \n",
      "\n",
      "loss: 1.244916  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.137771 \n",
      "\n",
      "loss: 1.093012  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.549702 \n",
      "\n",
      "loss: 1.495050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.179748 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 423/500\n",
      "--------------------\n",
      "{'hl': [112], 'alpha': 0.0002587057806010935, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.06865093444229846}\n",
      "loss: 1.154788  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.876486 \n",
      "\n",
      "loss: 0.755644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.494977 \n",
      "\n",
      "loss: 0.438229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.371441 \n",
      "\n",
      "loss: 0.320728  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.353522 \n",
      "\n",
      "loss: 0.343940  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.340907 \n",
      "\n",
      "loss: 0.364427  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.351286 \n",
      "\n",
      "loss: 0.360489  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.330790 \n",
      "\n",
      "loss: 0.347426  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.343877 \n",
      "\n",
      "loss: 0.338644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.375363 \n",
      "\n",
      "loss: 0.369686  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.333864 \n",
      "\n",
      "loss: 0.354166  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.363601 \n",
      "\n",
      "loss: 0.322577  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.350448 \n",
      "\n",
      "loss: 0.312984  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.351095 \n",
      "\n",
      "loss: 0.310990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.355016 \n",
      "\n",
      "loss: 0.321584  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.323899 \n",
      "\n",
      "loss: 0.369145  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.313373 \n",
      "\n",
      "loss: 0.297419  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.355944 \n",
      "\n",
      "loss: 0.344749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.363509 \n",
      "\n",
      "loss: 0.391594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.385482 \n",
      "\n",
      "loss: 0.375711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.332036 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 424/500\n",
      "--------------------\n",
      "{'hl': [664], 'alpha': 0.9370453740020422, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.2653010874456858}\n",
      "loss: 1.075249  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.788353 \n",
      "\n",
      "loss: 0.776374  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.796978 \n",
      "\n",
      "loss: 0.795455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.780628 \n",
      "\n",
      "loss: 0.774736  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.786722 \n",
      "\n",
      "loss: 0.797014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.781844 \n",
      "\n",
      "loss: 0.780582  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.807531 \n",
      "\n",
      "loss: 0.813333  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.781883 \n",
      "\n",
      "loss: 0.785703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.787874 \n",
      "\n",
      "loss: 0.784483  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.789812 \n",
      "\n",
      "loss: 0.789200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.791792 \n",
      "\n",
      "loss: 0.789218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.784110 \n",
      "\n",
      "loss: 0.770894  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.798829 \n",
      "\n",
      "loss: 0.782216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.790876 \n",
      "\n",
      "loss: 0.798555  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.783410 \n",
      "\n",
      "loss: 0.795306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.792078 \n",
      "\n",
      "loss: 0.805463  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.792168 \n",
      "\n",
      "loss: 0.785579  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.784269 \n",
      "\n",
      "loss: 0.794083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.795350 \n",
      "\n",
      "loss: 0.795286  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.786922 \n",
      "\n",
      "loss: 0.792073  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.791891 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 425/500\n",
      "--------------------\n",
      "{'hl': [632], 'alpha': 0.03981812930901614, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.36124376997952473}\n",
      "loss: 1.021880  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 2.969251 \n",
      "\n",
      "loss: 3.406232  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 4.004011 \n",
      "\n",
      "loss: 3.572511  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 6.927540 \n",
      "\n",
      "loss: 6.950192  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 9.250222 \n",
      "\n",
      "loss: 10.810059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 8.194017 \n",
      "\n",
      "loss: 7.625023  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 4.188983 \n",
      "\n",
      "loss: 4.300505  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 4.551902 \n",
      "\n",
      "loss: 4.547302  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 9.185003 \n",
      "\n",
      "loss: 9.366098  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 7.179527 \n",
      "\n",
      "loss: 6.761533  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 9.237427 \n",
      "\n",
      "loss: 11.174217  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 3.003328 \n",
      "\n",
      "loss: 2.837264  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 2.953983 \n",
      "\n",
      "loss: 3.031368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 7.997747 \n",
      "\n",
      "loss: 7.308858  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 9.044656 \n",
      "\n",
      "loss: 9.354048  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 11.023088 \n",
      "\n",
      "loss: 11.055918  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 6.613339 \n",
      "\n",
      "loss: 6.801288  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 4.329665 \n",
      "\n",
      "loss: 3.869579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 4.932360 \n",
      "\n",
      "loss: 5.432551  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 7.722088 \n",
      "\n",
      "loss: 6.885762  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 8.925476 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 426/500\n",
      "--------------------\n",
      "{'hl': [163, 429, 638], 'alpha': 0.05575254276560732, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.44830681350992996}\n",
      "loss: 1.105071  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.498804 \n",
      "\n",
      "loss: 0.515017  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.523243 \n",
      "\n",
      "loss: 0.504155  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.518632 \n",
      "\n",
      "loss: 0.515884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.497202 \n",
      "\n",
      "loss: 0.482827  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.515898 \n",
      "\n",
      "loss: 0.498938  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.499575 \n",
      "\n",
      "loss: 0.524537  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.520931 \n",
      "\n",
      "loss: 0.514400  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.510099 \n",
      "\n",
      "loss: 0.532376  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.510029 \n",
      "\n",
      "loss: 0.504200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.499319 \n",
      "\n",
      "loss: 0.522444  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.498971 \n",
      "\n",
      "loss: 0.504271  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.508175 \n",
      "\n",
      "loss: 0.535668  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.499262 \n",
      "\n",
      "loss: 0.510411  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.493932 \n",
      "\n",
      "loss: 0.492893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.506441 \n",
      "\n",
      "loss: 0.470756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.511343 \n",
      "\n",
      "loss: 0.531571  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.511431 \n",
      "\n",
      "loss: 0.445458  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.500944 \n",
      "\n",
      "loss: 0.523560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.497856 \n",
      "\n",
      "loss: 0.490403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.499919 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 427/500\n",
      "--------------------\n",
      "{'hl': [134], 'alpha': 0.02281895075128178, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.4816280304055767}\n",
      "loss: 1.232500  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.967051 \n",
      "\n",
      "loss: 0.937041  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 1.241746 \n",
      "\n",
      "loss: 1.255572  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 1.237305 \n",
      "\n",
      "loss: 1.339176  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.943333 \n",
      "\n",
      "loss: 0.926082  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.416186 \n",
      "\n",
      "loss: 1.498000  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.974170 \n",
      "\n",
      "loss: 0.900518  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.948519 \n",
      "\n",
      "loss: 0.979000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 1.531887 \n",
      "\n",
      "loss: 1.505402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 2.465046 \n",
      "\n",
      "loss: 2.778366  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 1.516579 \n",
      "\n",
      "loss: 1.787679  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 1.956348 \n",
      "\n",
      "loss: 1.981707  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.992647 \n",
      "\n",
      "loss: 1.002430  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 1.357638 \n",
      "\n",
      "loss: 1.312989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.9%, Avg loss: 2.140398 \n",
      "\n",
      "loss: 2.141870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.618369 \n",
      "\n",
      "loss: 1.777104  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 1.056251 \n",
      "\n",
      "loss: 1.144234  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 1.384269 \n",
      "\n",
      "loss: 1.450272  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.963121 \n",
      "\n",
      "loss: 1.899255  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.213897 \n",
      "\n",
      "loss: 1.337775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 2.249110 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 428/500\n",
      "--------------------\n",
      "{'hl': [151, 261], 'alpha': 0.0012819486453883513, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2767429762291866}\n",
      "loss: 1.088047  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.478687 \n",
      "\n",
      "loss: 0.533270  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.443064 \n",
      "\n",
      "loss: 0.399497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.408045 \n",
      "\n",
      "loss: 0.385499  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.392089 \n",
      "\n",
      "loss: 0.363552  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.367226 \n",
      "\n",
      "loss: 0.354244  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.356880 \n",
      "\n",
      "loss: 0.361167  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.350927 \n",
      "\n",
      "loss: 0.328178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.351394 \n",
      "\n",
      "loss: 0.350887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.350933 \n",
      "\n",
      "loss: 0.347284  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.331869 \n",
      "\n",
      "loss: 0.295606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.329571 \n",
      "\n",
      "loss: 0.367916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.342869 \n",
      "\n",
      "loss: 0.298556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.345049 \n",
      "\n",
      "loss: 0.303976  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.337711 \n",
      "\n",
      "loss: 0.341463  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.314100 \n",
      "\n",
      "loss: 0.380818  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.324142 \n",
      "\n",
      "loss: 0.307595  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.326807 \n",
      "\n",
      "loss: 0.328642  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.419154 \n",
      "\n",
      "loss: 0.433049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.320010 \n",
      "\n",
      "loss: 0.314041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.291810 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 429/500\n",
      "--------------------\n",
      "{'hl': [630, 299, 715], 'alpha': 0.0001280258372250546, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.258922788985839}\n",
      "loss: 1.118411  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.456075 \n",
      "\n",
      "loss: 0.467746  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.479100 \n",
      "\n",
      "loss: 0.472083  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.390742 \n",
      "\n",
      "loss: 0.405979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.378460 \n",
      "\n",
      "loss: 0.398660  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.394898 \n",
      "\n",
      "loss: 0.389729  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.348919 \n",
      "\n",
      "loss: 0.342796  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.344185 \n",
      "\n",
      "loss: 0.315781  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.333708 \n",
      "\n",
      "loss: 0.329560  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.341231 \n",
      "\n",
      "loss: 0.368147  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.339459 \n",
      "\n",
      "loss: 0.364111  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.345192 \n",
      "\n",
      "loss: 0.354481  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.320699 \n",
      "\n",
      "loss: 0.309350  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.319288 \n",
      "\n",
      "loss: 0.280525  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.308878 \n",
      "\n",
      "loss: 0.270556  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.297960 \n",
      "\n",
      "loss: 0.262400  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.301442 \n",
      "\n",
      "loss: 0.332317  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.320098 \n",
      "\n",
      "loss: 0.324347  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.313197 \n",
      "\n",
      "loss: 0.274137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.298968 \n",
      "\n",
      "loss: 0.309403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.284396 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 430/500\n",
      "--------------------\n",
      "{'hl': [201, 409, 310], 'alpha': 0.03843077110394621, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.1930041988243204}\n",
      "loss: 1.108523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 3.530117 \n",
      "\n",
      "loss: 3.898641  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 25.0%, Avg loss: 5.299498 \n",
      "\n",
      "loss: 5.262862  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 3.884967 \n",
      "\n",
      "loss: 4.016843  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.943418 \n",
      "\n",
      "loss: 2.022479  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 5.212474 \n",
      "\n",
      "loss: 5.493079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 3.962641 \n",
      "\n",
      "loss: 3.740200  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 2.269145 \n",
      "\n",
      "loss: 1.911197  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 4.697967 \n",
      "\n",
      "loss: 4.597697  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 2.285892 \n",
      "\n",
      "loss: 2.315330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.0%, Avg loss: 3.332971 \n",
      "\n",
      "loss: 3.464538  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 4.474757 \n",
      "\n",
      "loss: 4.403684  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 2.434184 \n",
      "\n",
      "loss: 2.394420  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 1.650935 \n",
      "\n",
      "loss: 1.612330  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 39.1%, Avg loss: 2.179575 \n",
      "\n",
      "loss: 2.219999  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.331435 \n",
      "\n",
      "loss: 1.337909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 4.127958 \n",
      "\n",
      "loss: 4.493972  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 6.288752 \n",
      "\n",
      "loss: 6.561162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 28.7%, Avg loss: 7.651391 \n",
      "\n",
      "loss: 7.480354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.4%, Avg loss: 7.960285 \n",
      "\n",
      "loss: 7.715401  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 3.765231 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 431/500\n",
      "--------------------\n",
      "{'hl': [519], 'alpha': 0.035672152792519986, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.49344257816831016}\n",
      "loss: 1.096063  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.454583 \n",
      "\n",
      "loss: 0.459853  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.439704 \n",
      "\n",
      "loss: 0.431979  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.423999 \n",
      "\n",
      "loss: 0.413974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.431261 \n",
      "\n",
      "loss: 0.430056  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.423045 \n",
      "\n",
      "loss: 0.450164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.431569 \n",
      "\n",
      "loss: 0.420689  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.438261 \n",
      "\n",
      "loss: 0.400909  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.428804 \n",
      "\n",
      "loss: 0.410282  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.426886 \n",
      "\n",
      "loss: 0.445100  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.417877 \n",
      "\n",
      "loss: 0.454454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.421853 \n",
      "\n",
      "loss: 0.429552  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.426299 \n",
      "\n",
      "loss: 0.390437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.429796 \n",
      "\n",
      "loss: 0.447055  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.427666 \n",
      "\n",
      "loss: 0.418302  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.412915 \n",
      "\n",
      "loss: 0.384302  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.441096 \n",
      "\n",
      "loss: 0.421763  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.424465 \n",
      "\n",
      "loss: 0.434469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.424936 \n",
      "\n",
      "loss: 0.436874  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.435645 \n",
      "\n",
      "loss: 0.433180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.413910 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 432/500\n",
      "--------------------\n",
      "{'hl': [143, 404], 'alpha': 0.2774955453395093, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.27322347495855936}\n",
      "loss: 1.229668  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 3.500125 \n",
      "\n",
      "loss: 3.226719  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 3.307750 \n",
      "\n",
      "loss: 3.150499  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.004631 \n",
      "\n",
      "loss: 1.098310  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 3.004946 \n",
      "\n",
      "loss: 3.461202  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 11.914757 \n",
      "\n",
      "loss: 12.006234  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 7.102602 \n",
      "\n",
      "loss: 7.055705  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 8.413764 \n",
      "\n",
      "loss: 8.888908  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 10.319270 \n",
      "\n",
      "loss: 10.291493  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 7.345926 \n",
      "\n",
      "loss: 7.658915  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 6.130473 \n",
      "\n",
      "loss: 5.931558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 11.315320 \n",
      "\n",
      "loss: 11.638846  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 6.742746 \n",
      "\n",
      "loss: 6.612314  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 8.399135 \n",
      "\n",
      "loss: 8.462854  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 5.757989 \n",
      "\n",
      "loss: 5.661458  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.267701 \n",
      "\n",
      "loss: 3.244720  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 5.447722 \n",
      "\n",
      "loss: 5.827146  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.773379 \n",
      "\n",
      "loss: 2.922165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.663964 \n",
      "\n",
      "loss: 1.605222  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 5.682995 \n",
      "\n",
      "loss: 5.359133  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.007584 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 433/500\n",
      "--------------------\n",
      "{'hl': [490], 'alpha': 0.6573731108649497, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2937230121132696}\n",
      "loss: 1.245157  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.767359 \n",
      "\n",
      "loss: 0.769620  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.778502 \n",
      "\n",
      "loss: 0.781469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.772494 \n",
      "\n",
      "loss: 0.768112  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.769304 \n",
      "\n",
      "loss: 0.778614  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.765530 \n",
      "\n",
      "loss: 0.762218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.764868 \n",
      "\n",
      "loss: 0.757680  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.786295 \n",
      "\n",
      "loss: 0.771587  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.778204 \n",
      "\n",
      "loss: 0.762444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.768817 \n",
      "\n",
      "loss: 0.775805  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.779590 \n",
      "\n",
      "loss: 0.775207  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.764102 \n",
      "\n",
      "loss: 0.753862  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.767336 \n",
      "\n",
      "loss: 0.769060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.767308 \n",
      "\n",
      "loss: 0.765662  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.772066 \n",
      "\n",
      "loss: 0.791020  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.769540 \n",
      "\n",
      "loss: 0.770276  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.766286 \n",
      "\n",
      "loss: 0.782018  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.780036 \n",
      "\n",
      "loss: 0.773541  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.771238 \n",
      "\n",
      "loss: 0.783992  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.778976 \n",
      "\n",
      "loss: 0.776957  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.768532 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 434/500\n",
      "--------------------\n",
      "{'hl': [276], 'alpha': 0.0007294100688584966, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.253354641077036}\n",
      "loss: 1.007546  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 12.465380 \n",
      "\n",
      "loss: 13.506990  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 7.417377 \n",
      "\n",
      "loss: 2.143459  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.747139 \n",
      "\n",
      "loss: 0.628446  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.441236 \n",
      "\n",
      "loss: 0.366589  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.422560 \n",
      "\n",
      "loss: 0.409063  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.451359 \n",
      "\n",
      "loss: 0.338286  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.442916 \n",
      "\n",
      "loss: 0.366005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.444353 \n",
      "\n",
      "loss: 0.401267  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.480025 \n",
      "\n",
      "loss: 0.565639  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.395327 \n",
      "\n",
      "loss: 0.395247  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.357112 \n",
      "\n",
      "loss: 0.346265  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.407812 \n",
      "\n",
      "loss: 0.349906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.405310 \n",
      "\n",
      "loss: 0.414774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.367336 \n",
      "\n",
      "loss: 0.403609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.384980 \n",
      "\n",
      "loss: 0.376916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.370025 \n",
      "\n",
      "loss: 0.388250  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.391481 \n",
      "\n",
      "loss: 0.377724  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.363676 \n",
      "\n",
      "loss: 0.357744  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.375207 \n",
      "\n",
      "loss: 0.365291  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.362014 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 435/500\n",
      "--------------------\n",
      "{'hl': [521, 433, 441], 'alpha': 0.06415677936716299, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.13880612109370657}\n",
      "loss: 1.107911  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.542998 \n",
      "\n",
      "loss: 0.541666  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.516870 \n",
      "\n",
      "loss: 0.514839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.490474 \n",
      "\n",
      "loss: 0.486659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.482139 \n",
      "\n",
      "loss: 0.471274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.450912 \n",
      "\n",
      "loss: 0.486866  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.457470 \n",
      "\n",
      "loss: 0.462815  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.468693 \n",
      "\n",
      "loss: 0.449435  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.458891 \n",
      "\n",
      "loss: 0.444863  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.452002 \n",
      "\n",
      "loss: 0.450352  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.448330 \n",
      "\n",
      "loss: 0.465374  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.448874 \n",
      "\n",
      "loss: 0.475096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.456220 \n",
      "\n",
      "loss: 0.440172  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.463905 \n",
      "\n",
      "loss: 0.435114  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.451739 \n",
      "\n",
      "loss: 0.489096  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.456687 \n",
      "\n",
      "loss: 0.426682  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.460403 \n",
      "\n",
      "loss: 0.428964  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.462117 \n",
      "\n",
      "loss: 0.438144  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.460891 \n",
      "\n",
      "loss: 0.481310  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.445470 \n",
      "\n",
      "loss: 0.491517  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.447135 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 436/500\n",
      "--------------------\n",
      "{'hl': [88, 531], 'alpha': 0.4827246041600365, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.195426678333878}\n",
      "loss: 1.088628  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 4.787699 \n",
      "\n",
      "loss: 5.150521  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.770316 \n",
      "\n",
      "loss: 0.759152  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.760900 \n",
      "\n",
      "loss: 0.770105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.749352 \n",
      "\n",
      "loss: 0.749207  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.793211 \n",
      "\n",
      "loss: 0.805507  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.748379 \n",
      "\n",
      "loss: 0.748433  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.769144 \n",
      "\n",
      "loss: 0.762363  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.756154 \n",
      "\n",
      "loss: 0.760612  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.758173 \n",
      "\n",
      "loss: 0.766497  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.738921 \n",
      "\n",
      "loss: 0.712706  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.736505 \n",
      "\n",
      "loss: 0.727916  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.786397 \n",
      "\n",
      "loss: 0.782711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.727471 \n",
      "\n",
      "loss: 0.708612  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.774153 \n",
      "\n",
      "loss: 0.781371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.739431 \n",
      "\n",
      "loss: 0.731073  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.728328 \n",
      "\n",
      "loss: 0.740190  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.736347 \n",
      "\n",
      "loss: 0.749211  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.773309 \n",
      "\n",
      "loss: 0.759687  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.770991 \n",
      "\n",
      "loss: 0.766002  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.787611 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 437/500\n",
      "--------------------\n",
      "{'hl': [673, 705, 666], 'alpha': 0.00018384860313394125, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.0290471814171629}\n",
      "loss: 1.328691  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.105798 \n",
      "\n",
      "loss: 1.096472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.033107 \n",
      "\n",
      "loss: 1.036240  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.843250 \n",
      "\n",
      "loss: 0.842342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.921610 \n",
      "\n",
      "loss: 0.932419  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.860696 \n",
      "\n",
      "loss: 0.901589  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.859072 \n",
      "\n",
      "loss: 0.852036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.886891 \n",
      "\n",
      "loss: 0.868418  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.825180 \n",
      "\n",
      "loss: 0.810567  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.853039 \n",
      "\n",
      "loss: 0.856097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.803717 \n",
      "\n",
      "loss: 0.825754  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.818496 \n",
      "\n",
      "loss: 0.811619  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.880294 \n",
      "\n",
      "loss: 0.843652  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809776 \n",
      "\n",
      "loss: 0.818169  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.821289 \n",
      "\n",
      "loss: 0.845656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.7%, Avg loss: 0.806708 \n",
      "\n",
      "loss: 0.809069  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.823652 \n",
      "\n",
      "loss: 0.816062  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.818045 \n",
      "\n",
      "loss: 0.826517  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.812089 \n",
      "\n",
      "loss: 0.821628  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 0.813763 \n",
      "\n",
      "loss: 0.823184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.802053 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 438/500\n",
      "--------------------\n",
      "{'hl': [452], 'alpha': 0.00029103574090054684, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.33307318147176934}\n",
      "loss: 1.062686  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 83.206748 \n",
      "\n",
      "loss: 50.804680  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 12.104268 \n",
      "\n",
      "loss: 9.308805  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 8.995749 \n",
      "\n",
      "loss: 17.403168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 1.098398 \n",
      "\n",
      "loss: 1.932360  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.771903 \n",
      "\n",
      "loss: 0.402348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.391567 \n",
      "\n",
      "loss: 0.328060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.368553 \n",
      "\n",
      "loss: 0.354539  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.342009 \n",
      "\n",
      "loss: 0.291412  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.364644 \n",
      "\n",
      "loss: 0.344021  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.348490 \n",
      "\n",
      "loss: 0.327998  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.345509 \n",
      "\n",
      "loss: 0.340711  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.356558 \n",
      "\n",
      "loss: 0.390828  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.365491 \n",
      "\n",
      "loss: 0.333897  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.348831 \n",
      "\n",
      "loss: 0.364135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.333090 \n",
      "\n",
      "loss: 0.338148  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.347169 \n",
      "\n",
      "loss: 0.314015  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.358235 \n",
      "\n",
      "loss: 0.300278  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.396285 \n",
      "\n",
      "loss: 0.422125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.343670 \n",
      "\n",
      "loss: 0.371058  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.353804 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 439/500\n",
      "--------------------\n",
      "{'hl': [187, 130, 20], 'alpha': 0.06785821454112351, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.2482568249681055}\n",
      "loss: 1.115632  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.611215 \n",
      "\n",
      "loss: 0.595583  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.524698 \n",
      "\n",
      "loss: 0.511920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.488723 \n",
      "\n",
      "loss: 0.487053  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.471725 \n",
      "\n",
      "loss: 0.480427  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.480477 \n",
      "\n",
      "loss: 0.511523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.464068 \n",
      "\n",
      "loss: 0.475126  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.462921 \n",
      "\n",
      "loss: 0.500989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.467595 \n",
      "\n",
      "loss: 0.488852  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.463296 \n",
      "\n",
      "loss: 0.484039  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.462035 \n",
      "\n",
      "loss: 0.451216  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.465029 \n",
      "\n",
      "loss: 0.461551  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.463157 \n",
      "\n",
      "loss: 0.454026  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.477669 \n",
      "\n",
      "loss: 0.436715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.456711 \n",
      "\n",
      "loss: 0.463892  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.459164 \n",
      "\n",
      "loss: 0.456089  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.453077 \n",
      "\n",
      "loss: 0.488206  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.469696 \n",
      "\n",
      "loss: 0.492003  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.462068 \n",
      "\n",
      "loss: 0.463547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.467278 \n",
      "\n",
      "loss: 0.475846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.474535 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 440/500\n",
      "--------------------\n",
      "{'hl': [543, 537], 'alpha': 0.13550284265331192, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.18599752850273701}\n",
      "loss: 1.050488  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.550709 \n",
      "\n",
      "loss: 0.548658  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.549680 \n",
      "\n",
      "loss: 0.522996  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.540087 \n",
      "\n",
      "loss: 0.542120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.536414 \n",
      "\n",
      "loss: 0.536735  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.531397 \n",
      "\n",
      "loss: 0.548249  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.534221 \n",
      "\n",
      "loss: 0.536603  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.541313 \n",
      "\n",
      "loss: 0.537481  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.535375 \n",
      "\n",
      "loss: 0.505520  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.537718 \n",
      "\n",
      "loss: 0.540061  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.536750 \n",
      "\n",
      "loss: 0.513422  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.539848 \n",
      "\n",
      "loss: 0.549139  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.537610 \n",
      "\n",
      "loss: 0.533224  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.538951 \n",
      "\n",
      "loss: 0.550051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.537420 \n",
      "\n",
      "loss: 0.494430  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.545018 \n",
      "\n",
      "loss: 0.527830  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.534855 \n",
      "\n",
      "loss: 0.523029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.536361 \n",
      "\n",
      "loss: 0.546021  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.535349 \n",
      "\n",
      "loss: 0.527640  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.540813 \n",
      "\n",
      "loss: 0.513294  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.534563 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 441/500\n",
      "--------------------\n",
      "{'hl': [283, 128, 38], 'alpha': 0.002187983815825225, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.26197472030318975}\n",
      "loss: 1.120106  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.848787 \n",
      "\n",
      "loss: 0.835506  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.916137 \n",
      "\n",
      "loss: 0.929807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.877956 \n",
      "\n",
      "loss: 0.885914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.822175 \n",
      "\n",
      "loss: 0.800387  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.844031 \n",
      "\n",
      "loss: 0.884895  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.824229 \n",
      "\n",
      "loss: 0.803724  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.222297 \n",
      "\n",
      "loss: 1.209109  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.819797 \n",
      "\n",
      "loss: 0.831632  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.804381 \n",
      "\n",
      "loss: 0.814050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.816603 \n",
      "\n",
      "loss: 0.823454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.5%, Avg loss: 0.828701 \n",
      "\n",
      "loss: 0.819037  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.824453 \n",
      "\n",
      "loss: 0.825115  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.026314 \n",
      "\n",
      "loss: 0.952552  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.872747 \n",
      "\n",
      "loss: 0.881160  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.989292 \n",
      "\n",
      "loss: 1.004931  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.858857 \n",
      "\n",
      "loss: 0.858739  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.873976 \n",
      "\n",
      "loss: 0.860810  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.814424 \n",
      "\n",
      "loss: 0.817867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.775740 \n",
      "\n",
      "loss: 0.769455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.825688 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 442/500\n",
      "--------------------\n",
      "{'hl': [598, 650], 'alpha': 0.0002033668328426929, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.02781401151012655}\n",
      "loss: 1.073869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.473882 \n",
      "\n",
      "loss: 0.459270  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.455779 \n",
      "\n",
      "loss: 0.432171  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.432670 \n",
      "\n",
      "loss: 0.441902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.439676 \n",
      "\n",
      "loss: 0.433711  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.436460 \n",
      "\n",
      "loss: 0.472482  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.414941 \n",
      "\n",
      "loss: 0.358016  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.398870 \n",
      "\n",
      "loss: 0.375225  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.430444 \n",
      "\n",
      "loss: 0.432521  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.397782 \n",
      "\n",
      "loss: 0.373282  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.401878 \n",
      "\n",
      "loss: 0.406324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.410533 \n",
      "\n",
      "loss: 0.410429  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.400908 \n",
      "\n",
      "loss: 0.393530  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.398482 \n",
      "\n",
      "loss: 0.402780  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.382525 \n",
      "\n",
      "loss: 0.357075  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.378427 \n",
      "\n",
      "loss: 0.378004  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.375462 \n",
      "\n",
      "loss: 0.407610  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.418463 \n",
      "\n",
      "loss: 0.417664  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.361371 \n",
      "\n",
      "loss: 0.384696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.362022 \n",
      "\n",
      "loss: 0.328814  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.386299 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 443/500\n",
      "--------------------\n",
      "{'hl': [178, 384, 169], 'alpha': 0.0010482486799100331, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.1142793711343102}\n",
      "loss: 1.111936  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.575957 \n",
      "\n",
      "loss: 0.601434  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.489268 \n",
      "\n",
      "loss: 0.500460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.472886 \n",
      "\n",
      "loss: 0.445217  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.430264 \n",
      "\n",
      "loss: 0.517557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.405199 \n",
      "\n",
      "loss: 0.423828  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.407906 \n",
      "\n",
      "loss: 0.369904  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.409162 \n",
      "\n",
      "loss: 0.341853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.387201 \n",
      "\n",
      "loss: 0.371830  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.378417 \n",
      "\n",
      "loss: 0.360914  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.356377 \n",
      "\n",
      "loss: 0.358628  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.367144 \n",
      "\n",
      "loss: 0.398189  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.360106 \n",
      "\n",
      "loss: 0.299917  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.388462 \n",
      "\n",
      "loss: 0.373290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.368287 \n",
      "\n",
      "loss: 0.372044  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.356356 \n",
      "\n",
      "loss: 0.356404  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.336148 \n",
      "\n",
      "loss: 0.346245  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.344723 \n",
      "\n",
      "loss: 0.305617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.321525 \n",
      "\n",
      "loss: 0.321901  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.342934 \n",
      "\n",
      "loss: 0.329315  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.311723 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 444/500\n",
      "--------------------\n",
      "{'hl': [10, 53, 20], 'alpha': 0.0009510553685353995, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.1915514392362628}\n",
      "loss: 1.094466  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.490010 \n",
      "\n",
      "loss: 0.526235  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.477025 \n",
      "\n",
      "loss: 0.431801  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.457159 \n",
      "\n",
      "loss: 0.430340  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.501719 \n",
      "\n",
      "loss: 0.508309  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.426742 \n",
      "\n",
      "loss: 0.412168  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.547029 \n",
      "\n",
      "loss: 0.505026  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.436673 \n",
      "\n",
      "loss: 0.482534  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.454613 \n",
      "\n",
      "loss: 0.434689  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.470969 \n",
      "\n",
      "loss: 0.526412  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.447828 \n",
      "\n",
      "loss: 0.440380  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.420928 \n",
      "\n",
      "loss: 0.455494  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.475876 \n",
      "\n",
      "loss: 0.419851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.454841 \n",
      "\n",
      "loss: 0.420885  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.436615 \n",
      "\n",
      "loss: 0.420722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.564218 \n",
      "\n",
      "loss: 0.515249  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.442806 \n",
      "\n",
      "loss: 0.438201  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.557238 \n",
      "\n",
      "loss: 0.581702  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.420951 \n",
      "\n",
      "loss: 0.437925  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.524329 \n",
      "\n",
      "loss: 0.507782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.499875 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 445/500\n",
      "--------------------\n",
      "{'hl': [191], 'alpha': 0.5304449371515396, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.11233520537740606}\n",
      "loss: 1.179182  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.750336 \n",
      "\n",
      "loss: 0.744432  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.716479 \n",
      "\n",
      "loss: 0.717846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.721222 \n",
      "\n",
      "loss: 0.724616  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.704874 \n",
      "\n",
      "loss: 0.731263  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.713895 \n",
      "\n",
      "loss: 0.719676  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.690009 \n",
      "\n",
      "loss: 0.688401  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.765046 \n",
      "\n",
      "loss: 0.779431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.749342 \n",
      "\n",
      "loss: 0.746442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.699597 \n",
      "\n",
      "loss: 0.689248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.751898 \n",
      "\n",
      "loss: 0.750185  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.723568 \n",
      "\n",
      "loss: 0.726311  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.714058 \n",
      "\n",
      "loss: 0.679791  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.741684 \n",
      "\n",
      "loss: 0.739507  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.759672 \n",
      "\n",
      "loss: 0.755387  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.709736 \n",
      "\n",
      "loss: 0.706230  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.708279 \n",
      "\n",
      "loss: 0.708994  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.726997 \n",
      "\n",
      "loss: 0.728532  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.723631 \n",
      "\n",
      "loss: 0.713811  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.720318 \n",
      "\n",
      "loss: 0.750177  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.723563 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 446/500\n",
      "--------------------\n",
      "{'hl': [434], 'alpha': 0.46070089878665477, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.41301589807671113}\n",
      "loss: 1.073623  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 1.245523 \n",
      "\n",
      "loss: 1.410821  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.631798 \n",
      "\n",
      "loss: 0.614288  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.691672 \n",
      "\n",
      "loss: 0.678431  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.682179 \n",
      "\n",
      "loss: 0.697783  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.707245 \n",
      "\n",
      "loss: 0.707767  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.685677 \n",
      "\n",
      "loss: 0.669292  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.678581 \n",
      "\n",
      "loss: 0.687270  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.711733 \n",
      "\n",
      "loss: 0.723891  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.684330 \n",
      "\n",
      "loss: 0.684944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.683502 \n",
      "\n",
      "loss: 0.696029  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.682064 \n",
      "\n",
      "loss: 0.691204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.735770 \n",
      "\n",
      "loss: 0.731132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.687315 \n",
      "\n",
      "loss: 0.680658  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.671716 \n",
      "\n",
      "loss: 0.638361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.699985 \n",
      "\n",
      "loss: 0.701359  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.661199 \n",
      "\n",
      "loss: 0.668346  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.695754 \n",
      "\n",
      "loss: 0.684986  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.724417 \n",
      "\n",
      "loss: 0.707622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.677068 \n",
      "\n",
      "loss: 0.681965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.701144 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 447/500\n",
      "--------------------\n",
      "{'hl': [389, 130, 522], 'alpha': 0.04935178518511205, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.11167021196923085}\n",
      "loss: 1.080834  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.560960 \n",
      "\n",
      "loss: 0.523017  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.515251 \n",
      "\n",
      "loss: 0.491803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.493420 \n",
      "\n",
      "loss: 0.533361  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.469264 \n",
      "\n",
      "loss: 0.459593  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.451410 \n",
      "\n",
      "loss: 0.446964  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.447182 \n",
      "\n",
      "loss: 0.442117  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.443324 \n",
      "\n",
      "loss: 0.452961  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.436761 \n",
      "\n",
      "loss: 0.435777  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.436830 \n",
      "\n",
      "loss: 0.479424  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.428535 \n",
      "\n",
      "loss: 0.439870  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.426204 \n",
      "\n",
      "loss: 0.447775  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.444460 \n",
      "\n",
      "loss: 0.421414  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.423720 \n",
      "\n",
      "loss: 0.400042  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.429064 \n",
      "\n",
      "loss: 0.425971  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.421074 \n",
      "\n",
      "loss: 0.420154  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.428579 \n",
      "\n",
      "loss: 0.443370  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.423843 \n",
      "\n",
      "loss: 0.378250  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.432452 \n",
      "\n",
      "loss: 0.439932  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.422802 \n",
      "\n",
      "loss: 0.443443  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.417674 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 448/500\n",
      "--------------------\n",
      "{'hl': [55, 418, 78], 'alpha': 0.32208088637791726, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.16371773077088683}\n",
      "loss: 1.103910  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.8%, Avg loss: 1.367325 \n",
      "\n",
      "loss: 1.122145  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 0.822606 \n",
      "\n",
      "loss: 0.876839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.871781 \n",
      "\n",
      "loss: 0.875939  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.925625 \n",
      "\n",
      "loss: 0.936978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.928016 \n",
      "\n",
      "loss: 0.930320  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.929905 \n",
      "\n",
      "loss: 0.945330  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.930597 \n",
      "\n",
      "loss: 0.928354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.925837 \n",
      "\n",
      "loss: 0.927772  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.929347 \n",
      "\n",
      "loss: 0.932544  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.927718 \n",
      "\n",
      "loss: 0.933826  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.932964 \n",
      "\n",
      "loss: 0.927606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.928326 \n",
      "\n",
      "loss: 0.926013  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.928160 \n",
      "\n",
      "loss: 0.934000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.928405 \n",
      "\n",
      "loss: 0.931014  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.927729 \n",
      "\n",
      "loss: 0.930887  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.925960 \n",
      "\n",
      "loss: 0.924675  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.932087 \n",
      "\n",
      "loss: 0.935940  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.924608 \n",
      "\n",
      "loss: 0.927696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.930351 \n",
      "\n",
      "loss: 0.924834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.927540 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 449/500\n",
      "--------------------\n",
      "{'hl': [475, 16, 385], 'alpha': 0.0006348697197700551, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.2320169526211916}\n",
      "loss: 1.128098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.462851 \n",
      "\n",
      "loss: 0.461267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.426170 \n",
      "\n",
      "loss: 0.417744  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.391355 \n",
      "\n",
      "loss: 0.352235  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.376961 \n",
      "\n",
      "loss: 0.374076  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.436082 \n",
      "\n",
      "loss: 0.421781  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.355383 \n",
      "\n",
      "loss: 0.389235  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.344837 \n",
      "\n",
      "loss: 0.370027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.336909 \n",
      "\n",
      "loss: 0.319572  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.334947 \n",
      "\n",
      "loss: 0.316972  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.314043 \n",
      "\n",
      "loss: 0.333703  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.309834 \n",
      "\n",
      "loss: 0.294993  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.338341 \n",
      "\n",
      "loss: 0.323894  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.366505 \n",
      "\n",
      "loss: 0.371122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.304783 \n",
      "\n",
      "loss: 0.340087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.292694 \n",
      "\n",
      "loss: 0.307398  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.330920 \n",
      "\n",
      "loss: 0.341505  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.304085 \n",
      "\n",
      "loss: 0.285640  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.283567 \n",
      "\n",
      "loss: 0.278000  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.299843 \n",
      "\n",
      "loss: 0.292576  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.372820 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 450/500\n",
      "--------------------\n",
      "{'hl': [513, 208, 567], 'alpha': 0.1101358939659915, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.003288303587626852}\n",
      "loss: 1.114165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 1.001267 \n",
      "\n",
      "loss: 1.004163  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.915705 \n",
      "\n",
      "loss: 0.914537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.845754 \n",
      "\n",
      "loss: 0.839676  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.782558 \n",
      "\n",
      "loss: 0.783349  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.739883 \n",
      "\n",
      "loss: 0.727621  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.703842 \n",
      "\n",
      "loss: 0.681694  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.678000 \n",
      "\n",
      "loss: 0.666406  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.655981 \n",
      "\n",
      "loss: 0.663853  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.638193 \n",
      "\n",
      "loss: 0.619516  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.626589 \n",
      "\n",
      "loss: 0.626970  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.611473 \n",
      "\n",
      "loss: 0.627234  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.609466 \n",
      "\n",
      "loss: 0.611196  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.595422 \n",
      "\n",
      "loss: 0.594823  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.573857 \n",
      "\n",
      "loss: 0.583604  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.590965 \n",
      "\n",
      "loss: 0.601693  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.584416 \n",
      "\n",
      "loss: 0.589466  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.581248 \n",
      "\n",
      "loss: 0.563989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.573826 \n",
      "\n",
      "loss: 0.590826  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.570846 \n",
      "\n",
      "loss: 0.561060  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.579794 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 451/500\n",
      "--------------------\n",
      "{'hl': [32, 246], 'alpha': 0.014661580856685215, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.0008308740637353156}\n",
      "loss: 1.087811  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.551921 \n",
      "\n",
      "loss: 0.560353  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.490859 \n",
      "\n",
      "loss: 0.494251  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.452912 \n",
      "\n",
      "loss: 0.449960  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.421129 \n",
      "\n",
      "loss: 0.408716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.409297 \n",
      "\n",
      "loss: 0.418838  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.405434 \n",
      "\n",
      "loss: 0.375377  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.385050 \n",
      "\n",
      "loss: 0.390971  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.386650 \n",
      "\n",
      "loss: 0.379327  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.389177 \n",
      "\n",
      "loss: 0.352731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.365666 \n",
      "\n",
      "loss: 0.401567  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.369574 \n",
      "\n",
      "loss: 0.338068  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.367314 \n",
      "\n",
      "loss: 0.343396  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.367051 \n",
      "\n",
      "loss: 0.323978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.367809 \n",
      "\n",
      "loss: 0.381071  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.344890 \n",
      "\n",
      "loss: 0.358423  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.352225 \n",
      "\n",
      "loss: 0.372596  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.358626 \n",
      "\n",
      "loss: 0.366247  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360393 \n",
      "\n",
      "loss: 0.364150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.360702 \n",
      "\n",
      "loss: 0.376704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.347141 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 452/500\n",
      "--------------------\n",
      "{'hl': [393, 322, 114], 'alpha': 0.0006618773076377993, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.2460652355372638}\n",
      "loss: 1.105111  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.0%, Avg loss: 1.032347 \n",
      "\n",
      "loss: 1.047787  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.846622 \n",
      "\n",
      "loss: 0.783888  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.851415 \n",
      "\n",
      "loss: 0.854228  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.652277 \n",
      "\n",
      "loss: 0.742978  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 1.212954 \n",
      "\n",
      "loss: 1.037925  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.245218 \n",
      "\n",
      "loss: 1.218645  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.547500 \n",
      "\n",
      "loss: 1.506867  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.881842 \n",
      "\n",
      "loss: 0.980682  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.603887 \n",
      "\n",
      "loss: 0.702485  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.735926 \n",
      "\n",
      "loss: 0.679254  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.853698 \n",
      "\n",
      "loss: 0.854121  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 1.178978 \n",
      "\n",
      "loss: 1.196135  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.718444 \n",
      "\n",
      "loss: 0.719292  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.700280 \n",
      "\n",
      "loss: 0.671558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.742801 \n",
      "\n",
      "loss: 0.747159  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.714278 \n",
      "\n",
      "loss: 0.715164  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.569843 \n",
      "\n",
      "loss: 0.568829  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 2.678038 \n",
      "\n",
      "loss: 2.690038  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.915084 \n",
      "\n",
      "loss: 1.019374  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.649450 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 453/500\n",
      "--------------------\n",
      "{'hl': [153], 'alpha': 0.07024410749022296, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.460645074045756}\n",
      "loss: 1.171371  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.486412 \n",
      "\n",
      "loss: 0.487698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.482203 \n",
      "\n",
      "loss: 0.501718  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.470361 \n",
      "\n",
      "loss: 0.529651  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.470060 \n",
      "\n",
      "loss: 0.483188  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.462178 \n",
      "\n",
      "loss: 0.492909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.468398 \n",
      "\n",
      "loss: 0.490154  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.482000 \n",
      "\n",
      "loss: 0.465218  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.463325 \n",
      "\n",
      "loss: 0.493942  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.470041 \n",
      "\n",
      "loss: 0.439799  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.466120 \n",
      "\n",
      "loss: 0.468469  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.471861 \n",
      "\n",
      "loss: 0.482606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.476235 \n",
      "\n",
      "loss: 0.469050  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.465059 \n",
      "\n",
      "loss: 0.439498  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.457352 \n",
      "\n",
      "loss: 0.449153  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.471214 \n",
      "\n",
      "loss: 0.443113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.471606 \n",
      "\n",
      "loss: 0.476279  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.472860 \n",
      "\n",
      "loss: 0.455720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.462399 \n",
      "\n",
      "loss: 0.473762  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.470433 \n",
      "\n",
      "loss: 0.479474  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.473810 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 454/500\n",
      "--------------------\n",
      "{'hl': [430, 389, 477], 'alpha': 0.7910777336710242, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.25276333915400184}\n",
      "loss: 1.073216  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991864 \n",
      "\n",
      "loss: 0.993130  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.994066 \n",
      "\n",
      "loss: 0.992321  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.990939 \n",
      "\n",
      "loss: 0.994642  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.990598 \n",
      "\n",
      "loss: 0.993964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.992056 \n",
      "\n",
      "loss: 0.992599  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.990853 \n",
      "\n",
      "loss: 0.988467  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.994150 \n",
      "\n",
      "loss: 0.987934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.988920 \n",
      "\n",
      "loss: 0.990761  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.990835 \n",
      "\n",
      "loss: 0.996303  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.989971 \n",
      "\n",
      "loss: 0.986818  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991517 \n",
      "\n",
      "loss: 0.987259  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.992122 \n",
      "\n",
      "loss: 0.989159  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.990012 \n",
      "\n",
      "loss: 0.994243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.991814 \n",
      "\n",
      "loss: 0.991226  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.992110 \n",
      "\n",
      "loss: 0.994392  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.991277 \n",
      "\n",
      "loss: 0.990454  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.994106 \n",
      "\n",
      "loss: 0.993490  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.991359 \n",
      "\n",
      "loss: 0.995983  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.992239 \n",
      "\n",
      "loss: 0.990264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.990630 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 455/500\n",
      "--------------------\n",
      "{'hl': [411, 84, 614], 'alpha': 0.01867595905672996, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.11846219019747406}\n",
      "loss: 1.100945  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.341493 \n",
      "\n",
      "loss: 2.259003  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 2.665897 \n",
      "\n",
      "loss: 2.703182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.132279 \n",
      "\n",
      "loss: 1.115661  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.139980 \n",
      "\n",
      "loss: 1.133300  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.051220 \n",
      "\n",
      "loss: 1.071822  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.036721 \n",
      "\n",
      "loss: 0.986818  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.884912 \n",
      "\n",
      "loss: 0.861934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.912269 \n",
      "\n",
      "loss: 0.870175  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.078494 \n",
      "\n",
      "loss: 1.072127  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.151644 \n",
      "\n",
      "loss: 1.189628  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 0.984862 \n",
      "\n",
      "loss: 1.019145  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.917198 \n",
      "\n",
      "loss: 0.886460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.988335 \n",
      "\n",
      "loss: 0.945045  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.864120 \n",
      "\n",
      "loss: 0.851403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.970167 \n",
      "\n",
      "loss: 0.991484  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.094995 \n",
      "\n",
      "loss: 1.090180  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.995973 \n",
      "\n",
      "loss: 0.953282  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.906707 \n",
      "\n",
      "loss: 0.929463  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.950252 \n",
      "\n",
      "loss: 0.953460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.030903 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 456/500\n",
      "--------------------\n",
      "{'hl': [330, 410], 'alpha': 0.06351882054922249, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.22643365037255536}\n",
      "loss: 1.083645  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 101.482873 \n",
      "\n",
      "loss: 78.197937  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 29.961452 \n",
      "\n",
      "loss: 33.977627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 9.835434 \n",
      "\n",
      "loss: 10.532656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 4.864536 \n",
      "\n",
      "loss: 5.137637  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 1.864526 \n",
      "\n",
      "loss: 1.444926  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 9.387083 \n",
      "\n",
      "loss: 8.081113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 12.842859 \n",
      "\n",
      "loss: 15.773015  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 14.386552 \n",
      "\n",
      "loss: 15.111175  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 27.374810 \n",
      "\n",
      "loss: 27.025774  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 76.701770 \n",
      "\n",
      "loss: 92.351639  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 54.736897 \n",
      "\n",
      "loss: 56.912811  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 2185.532376 \n",
      "\n",
      "loss: 2393.663086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 1885.324415 \n",
      "\n",
      "loss: 976.369934  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1084.782369 \n",
      "\n",
      "loss: 961.246887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.7%, Avg loss: 76.488931 \n",
      "\n",
      "loss: 105.460907  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 10.776232 \n",
      "\n",
      "loss: 11.134362  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 3.090226 \n",
      "\n",
      "loss: 1.471930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 1.506942 \n",
      "\n",
      "loss: 1.326425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.874058 \n",
      "\n",
      "loss: 0.734129  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 4.077128 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 457/500\n",
      "--------------------\n",
      "{'hl': [84], 'alpha': 0.5945915652736729, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.07778973460583616}\n",
      "loss: 1.172400  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.707778 \n",
      "\n",
      "loss: 0.726439  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.707182 \n",
      "\n",
      "loss: 0.717399  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.709410 \n",
      "\n",
      "loss: 0.721666  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.702743 \n",
      "\n",
      "loss: 0.705168  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.696810 \n",
      "\n",
      "loss: 0.700769  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.707256 \n",
      "\n",
      "loss: 0.685501  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.696481 \n",
      "\n",
      "loss: 0.705704  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.699544 \n",
      "\n",
      "loss: 0.695157  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.706359 \n",
      "\n",
      "loss: 0.696851  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.698797 \n",
      "\n",
      "loss: 0.700425  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.708608 \n",
      "\n",
      "loss: 0.709780  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.704378 \n",
      "\n",
      "loss: 0.718312  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.712444 \n",
      "\n",
      "loss: 0.694777  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.693387 \n",
      "\n",
      "loss: 0.710371  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.698242 \n",
      "\n",
      "loss: 0.702528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.704424 \n",
      "\n",
      "loss: 0.708224  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.704342 \n",
      "\n",
      "loss: 0.706422  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.709538 \n",
      "\n",
      "loss: 0.696731  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.696727 \n",
      "\n",
      "loss: 0.711869  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.705949 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 458/500\n",
      "--------------------\n",
      "{'hl': [468], 'alpha': 0.007315103070357372, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.2680086820901028}\n",
      "loss: 1.075626  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 1.173284 \n",
      "\n",
      "loss: 1.173133  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.198157 \n",
      "\n",
      "loss: 1.093405  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 1.689389 \n",
      "\n",
      "loss: 1.582468  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.783191 \n",
      "\n",
      "loss: 1.781372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 1.308755 \n",
      "\n",
      "loss: 1.309475  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.898523 \n",
      "\n",
      "loss: 0.866828  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 3.114452 \n",
      "\n",
      "loss: 3.197186  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 1.018728 \n",
      "\n",
      "loss: 0.995558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.564211 \n",
      "\n",
      "loss: 0.623591  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.749897 \n",
      "\n",
      "loss: 0.684314  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.656353 \n",
      "\n",
      "loss: 0.628464  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 1.457672 \n",
      "\n",
      "loss: 1.402414  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.765035 \n",
      "\n",
      "loss: 0.777005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 1.296046 \n",
      "\n",
      "loss: 1.318022  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.680668 \n",
      "\n",
      "loss: 0.738348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 1.062827 \n",
      "\n",
      "loss: 1.176293  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.781900 \n",
      "\n",
      "loss: 0.744495  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.881574 \n",
      "\n",
      "loss: 0.826354  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.943664 \n",
      "\n",
      "loss: 0.923034  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.698802 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 459/500\n",
      "--------------------\n",
      "{'hl': [470], 'alpha': 0.0017109246083972342, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.04530140193545759}\n",
      "loss: 1.070185  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.544727 \n",
      "\n",
      "loss: 0.554869  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.520975 \n",
      "\n",
      "loss: 0.545582  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.485432 \n",
      "\n",
      "loss: 0.499643  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.465725 \n",
      "\n",
      "loss: 0.493990  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.460097 \n",
      "\n",
      "loss: 0.445915  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.468673 \n",
      "\n",
      "loss: 0.455169  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.457686 \n",
      "\n",
      "loss: 0.464345  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.438873 \n",
      "\n",
      "loss: 0.406547  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.441142 \n",
      "\n",
      "loss: 0.418967  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.422337 \n",
      "\n",
      "loss: 0.414437  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.422980 \n",
      "\n",
      "loss: 0.394956  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.437821 \n",
      "\n",
      "loss: 0.448261  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.417736 \n",
      "\n",
      "loss: 0.390954  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.408777 \n",
      "\n",
      "loss: 0.425447  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.394133 \n",
      "\n",
      "loss: 0.378612  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.396075 \n",
      "\n",
      "loss: 0.401456  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.398102 \n",
      "\n",
      "loss: 0.389661  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.399798 \n",
      "\n",
      "loss: 0.366141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.395281 \n",
      "\n",
      "loss: 0.415208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.383931 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 460/500\n",
      "--------------------\n",
      "{'hl': [319, 625, 49], 'alpha': 0.000724574686998239, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.045697330605295176}\n",
      "loss: 1.143198  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.716563 \n",
      "\n",
      "loss: 0.708816  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.561449 \n",
      "\n",
      "loss: 0.522062  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.524930 \n",
      "\n",
      "loss: 0.489237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.489430 \n",
      "\n",
      "loss: 0.499264  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.474919 \n",
      "\n",
      "loss: 0.491277  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.450239 \n",
      "\n",
      "loss: 0.434992  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.462735 \n",
      "\n",
      "loss: 0.473631  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.430735 \n",
      "\n",
      "loss: 0.434209  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.417961 \n",
      "\n",
      "loss: 0.450713  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.421685 \n",
      "\n",
      "loss: 0.413811  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.418688 \n",
      "\n",
      "loss: 0.392461  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.415425 \n",
      "\n",
      "loss: 0.425863  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.405613 \n",
      "\n",
      "loss: 0.406064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.396162 \n",
      "\n",
      "loss: 0.414628  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.376421 \n",
      "\n",
      "loss: 0.385227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.381789 \n",
      "\n",
      "loss: 0.370603  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.394310 \n",
      "\n",
      "loss: 0.389947  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.371811 \n",
      "\n",
      "loss: 0.367150  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.386079 \n",
      "\n",
      "loss: 0.405216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.369779 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 461/500\n",
      "--------------------\n",
      "{'hl': [372], 'alpha': 0.003845721681323189, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.1301573796813398}\n",
      "loss: 1.081063  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 9.331817 \n",
      "\n",
      "loss: 9.969742  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 1.072354 \n",
      "\n",
      "loss: 0.737094  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.656658 \n",
      "\n",
      "loss: 0.599108  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.609129 \n",
      "\n",
      "loss: 0.675381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.448317 \n",
      "\n",
      "loss: 0.489307  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.427548 \n",
      "\n",
      "loss: 0.388863  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.422984 \n",
      "\n",
      "loss: 0.429688  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.419359 \n",
      "\n",
      "loss: 0.395659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.417825 \n",
      "\n",
      "loss: 0.438787  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.400727 \n",
      "\n",
      "loss: 0.357523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.395781 \n",
      "\n",
      "loss: 0.442673  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.408275 \n",
      "\n",
      "loss: 0.370656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.416461 \n",
      "\n",
      "loss: 0.435257  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.405652 \n",
      "\n",
      "loss: 0.386384  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.390168 \n",
      "\n",
      "loss: 0.346113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.407305 \n",
      "\n",
      "loss: 0.389147  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.431416 \n",
      "\n",
      "loss: 0.447829  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.424272 \n",
      "\n",
      "loss: 0.444368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.402670 \n",
      "\n",
      "loss: 0.418928  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.405792 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 462/500\n",
      "--------------------\n",
      "{'hl': [39], 'alpha': 0.6432598235924111, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.04745316596832437}\n",
      "loss: 1.377921  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 0.827216 \n",
      "\n",
      "loss: 0.816919  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.837280 \n",
      "\n",
      "loss: 0.831909  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.841289 \n",
      "\n",
      "loss: 0.818722  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.841113 \n",
      "\n",
      "loss: 0.841622  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.837748 \n",
      "\n",
      "loss: 0.844800  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.846984 \n",
      "\n",
      "loss: 0.855534  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.847329 \n",
      "\n",
      "loss: 0.834906  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.840744 \n",
      "\n",
      "loss: 0.864964  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.841532 \n",
      "\n",
      "loss: 0.850054  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.841426 \n",
      "\n",
      "loss: 0.850782  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.842510 \n",
      "\n",
      "loss: 0.834045  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.850001 \n",
      "\n",
      "loss: 0.843582  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.843089 \n",
      "\n",
      "loss: 0.846195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.843659 \n",
      "\n",
      "loss: 0.845480  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.841270 \n",
      "\n",
      "loss: 0.852433  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.847278 \n",
      "\n",
      "loss: 0.846033  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.848003 \n",
      "\n",
      "loss: 0.847635  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.844934 \n",
      "\n",
      "loss: 0.844066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.844185 \n",
      "\n",
      "loss: 0.854685  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.841236 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 463/500\n",
      "--------------------\n",
      "{'hl': [151], 'alpha': 0.000306064544199009, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.06544454724823459}\n",
      "loss: 1.135182  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.540397 \n",
      "\n",
      "loss: 0.528071  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.492864 \n",
      "\n",
      "loss: 0.520328  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.470762 \n",
      "\n",
      "loss: 0.474184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.458720 \n",
      "\n",
      "loss: 0.505103  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.443976 \n",
      "\n",
      "loss: 0.458614  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.447810 \n",
      "\n",
      "loss: 0.446733  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.449838 \n",
      "\n",
      "loss: 0.459117  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.437136 \n",
      "\n",
      "loss: 0.463724  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.414999 \n",
      "\n",
      "loss: 0.458342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.413607 \n",
      "\n",
      "loss: 0.422066  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.408998 \n",
      "\n",
      "loss: 0.403092  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.407834 \n",
      "\n",
      "loss: 0.396518  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.404526 \n",
      "\n",
      "loss: 0.428216  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.388835 \n",
      "\n",
      "loss: 0.399579  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.374743 \n",
      "\n",
      "loss: 0.402649  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.387689 \n",
      "\n",
      "loss: 0.396552  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.401480 \n",
      "\n",
      "loss: 0.363059  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.394089 \n",
      "\n",
      "loss: 0.403838  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.382876 \n",
      "\n",
      "loss: 0.394280  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.372510 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 464/500\n",
      "--------------------\n",
      "{'hl': [389, 710], 'alpha': 0.0332039838853254, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.4587225478976389}\n",
      "loss: 1.129096  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 2072.246745 \n",
      "\n",
      "loss: 1595.036743  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 2475.229289 \n",
      "\n",
      "loss: 1994.199341  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1102.709968 \n",
      "\n",
      "loss: 1049.877197  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 76.257766 \n",
      "\n",
      "loss: 52.117573  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 2.759997 \n",
      "\n",
      "loss: 4.276636  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 3.908251 \n",
      "\n",
      "loss: 3.518035  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.714206 \n",
      "\n",
      "loss: 0.611048  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.509560 \n",
      "\n",
      "loss: 0.496266  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.608971 \n",
      "\n",
      "loss: 0.655997  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.610178 \n",
      "\n",
      "loss: 0.659224  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 255.619045 \n",
      "\n",
      "loss: 115.447983  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 1444.855313 \n",
      "\n",
      "loss: 1257.917725  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 621.305627 \n",
      "\n",
      "loss: 667.694031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 100.283964 \n",
      "\n",
      "loss: 114.188194  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 4.045903 \n",
      "\n",
      "loss: 2.667126  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 1.698491 \n",
      "\n",
      "loss: 1.784990  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.710861 \n",
      "\n",
      "loss: 0.655312  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.746657 \n",
      "\n",
      "loss: 0.774816  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.456690 \n",
      "\n",
      "loss: 0.427188  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.493819 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 465/500\n",
      "--------------------\n",
      "{'hl': [30], 'alpha': 0.9741945699221056, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.40466840277897487}\n",
      "loss: 1.266098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.823457 \n",
      "\n",
      "loss: 0.820743  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.799555 \n",
      "\n",
      "loss: 0.776470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.833603 \n",
      "\n",
      "loss: 0.843183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.837282 \n",
      "\n",
      "loss: 0.823217  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.830797 \n",
      "\n",
      "loss: 0.836282  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.2%, Avg loss: 0.805212 \n",
      "\n",
      "loss: 0.816866  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.832050 \n",
      "\n",
      "loss: 0.841647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.792585 \n",
      "\n",
      "loss: 0.781643  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.808499 \n",
      "\n",
      "loss: 0.807943  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.812201 \n",
      "\n",
      "loss: 0.813802  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.800608 \n",
      "\n",
      "loss: 0.807205  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.827651 \n",
      "\n",
      "loss: 0.832027  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.810864 \n",
      "\n",
      "loss: 0.812608  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.798266 \n",
      "\n",
      "loss: 0.796219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 0.981546 \n",
      "\n",
      "loss: 0.979325  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 0.879694 \n",
      "\n",
      "loss: 0.880785  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 23.3%, Avg loss: 1.234579 \n",
      "\n",
      "loss: 1.235427  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.089978 \n",
      "\n",
      "loss: 1.079854  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.870710 \n",
      "\n",
      "loss: 0.874134  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.843699 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 466/500\n",
      "--------------------\n",
      "{'hl': [347], 'alpha': 0.0003091082789194264, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.08407780544365531}\n",
      "loss: 1.011242  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.695575 \n",
      "\n",
      "loss: 0.672384  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.526931 \n",
      "\n",
      "loss: 0.514476  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.528431 \n",
      "\n",
      "loss: 0.517045  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.515717 \n",
      "\n",
      "loss: 0.589754  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.510820 \n",
      "\n",
      "loss: 0.500610  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.539041 \n",
      "\n",
      "loss: 0.540715  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.513924 \n",
      "\n",
      "loss: 0.498248  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.508685 \n",
      "\n",
      "loss: 0.527335  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.486755 \n",
      "\n",
      "loss: 0.490089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.511273 \n",
      "\n",
      "loss: 0.511629  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.503147 \n",
      "\n",
      "loss: 0.525447  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.501823 \n",
      "\n",
      "loss: 0.497610  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.484781 \n",
      "\n",
      "loss: 0.498470  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.491142 \n",
      "\n",
      "loss: 0.502051  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.483876 \n",
      "\n",
      "loss: 0.475993  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.488038 \n",
      "\n",
      "loss: 0.503221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.492253 \n",
      "\n",
      "loss: 0.489601  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.488575 \n",
      "\n",
      "loss: 0.496402  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.477282 \n",
      "\n",
      "loss: 0.474163  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.465587 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 467/500\n",
      "--------------------\n",
      "{'hl': [451, 412, 516], 'alpha': 0.0001311985913075365, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.17703623201129268}\n",
      "loss: 1.117689  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.845086 \n",
      "\n",
      "loss: 0.829565  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.869492 \n",
      "\n",
      "loss: 0.864240  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815176 \n",
      "\n",
      "loss: 0.810775  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814956 \n",
      "\n",
      "loss: 0.806727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.803255 \n",
      "\n",
      "loss: 0.818866  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.822273 \n",
      "\n",
      "loss: 0.822634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.837167 \n",
      "\n",
      "loss: 0.831185  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.820746 \n",
      "\n",
      "loss: 0.827450  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.804837 \n",
      "\n",
      "loss: 0.801118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.799168 \n",
      "\n",
      "loss: 0.782825  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.789418 \n",
      "\n",
      "loss: 0.793091  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.834171 \n",
      "\n",
      "loss: 0.800487  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.806022 \n",
      "\n",
      "loss: 0.787892  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 0.819400 \n",
      "\n",
      "loss: 0.828521  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.839709 \n",
      "\n",
      "loss: 0.856512  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.579458 \n",
      "\n",
      "loss: 0.566155  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.589882 \n",
      "\n",
      "loss: 0.591984  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.554870 \n",
      "\n",
      "loss: 0.550326  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.537282 \n",
      "\n",
      "loss: 0.534052  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.609028 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 468/500\n",
      "--------------------\n",
      "{'hl': [289], 'alpha': 0.001316491978096092, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.3070918782310661}\n",
      "loss: 1.104606  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.481653 \n",
      "\n",
      "loss: 0.465586  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.464071 \n",
      "\n",
      "loss: 0.455698  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.454181 \n",
      "\n",
      "loss: 0.414074  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.442337 \n",
      "\n",
      "loss: 0.461636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.427706 \n",
      "\n",
      "loss: 0.431360  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.411393 \n",
      "\n",
      "loss: 0.403643  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.417715 \n",
      "\n",
      "loss: 0.413690  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.405279 \n",
      "\n",
      "loss: 0.383635  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.390711 \n",
      "\n",
      "loss: 0.417320  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.378883 \n",
      "\n",
      "loss: 0.397849  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.377850 \n",
      "\n",
      "loss: 0.427165  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.399075 \n",
      "\n",
      "loss: 0.375488  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.384306 \n",
      "\n",
      "loss: 0.354197  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.383512 \n",
      "\n",
      "loss: 0.386445  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.432523 \n",
      "\n",
      "loss: 0.385011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.374364 \n",
      "\n",
      "loss: 0.376582  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.368965 \n",
      "\n",
      "loss: 0.331855  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.368377 \n",
      "\n",
      "loss: 0.333745  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.411540 \n",
      "\n",
      "loss: 0.378105  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.351495 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 469/500\n",
      "--------------------\n",
      "{'hl': [259, 670, 310], 'alpha': 0.009898432821953854, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.04395200337439784}\n",
      "loss: 1.377609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.818460 \n",
      "\n",
      "loss: 0.789528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.818833 \n",
      "\n",
      "loss: 0.799506  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.828816 \n",
      "\n",
      "loss: 0.838488  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.815438 \n",
      "\n",
      "loss: 0.779460  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.814619 \n",
      "\n",
      "loss: 0.804231  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.826182 \n",
      "\n",
      "loss: 0.822353  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.828869 \n",
      "\n",
      "loss: 0.824846  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.815848 \n",
      "\n",
      "loss: 0.813318  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.815166 \n",
      "\n",
      "loss: 0.818095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.810326 \n",
      "\n",
      "loss: 0.815679  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.818102 \n",
      "\n",
      "loss: 0.840537  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.822498 \n",
      "\n",
      "loss: 0.821996  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.820515 \n",
      "\n",
      "loss: 0.842647  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.813160 \n",
      "\n",
      "loss: 0.807165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.806793 \n",
      "\n",
      "loss: 0.816027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.814584 \n",
      "\n",
      "loss: 0.814348  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.828032 \n",
      "\n",
      "loss: 0.848043  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.819608 \n",
      "\n",
      "loss: 0.826179  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.821523 \n",
      "\n",
      "loss: 0.795274  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813585 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 470/500\n",
      "--------------------\n",
      "{'hl': [148, 437], 'alpha': 0.0006278143333570129, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.4947028675191908}\n",
      "loss: 1.135227  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.461394 \n",
      "\n",
      "loss: 0.468389  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.505583 \n",
      "\n",
      "loss: 0.496863  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.433170 \n",
      "\n",
      "loss: 0.389374  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.420606 \n",
      "\n",
      "loss: 0.404433  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.398660 \n",
      "\n",
      "loss: 0.385248  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.397530 \n",
      "\n",
      "loss: 0.391489  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.405305 \n",
      "\n",
      "loss: 0.366877  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.390818 \n",
      "\n",
      "loss: 0.416383  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.395656 \n",
      "\n",
      "loss: 0.404195  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.352435 \n",
      "\n",
      "loss: 0.350181  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.357243 \n",
      "\n",
      "loss: 0.340420  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.361321 \n",
      "\n",
      "loss: 0.340193  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366141 \n",
      "\n",
      "loss: 0.327636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.377288 \n",
      "\n",
      "loss: 0.373428  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.353480 \n",
      "\n",
      "loss: 0.351204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.371344 \n",
      "\n",
      "loss: 0.380044  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.344533 \n",
      "\n",
      "loss: 0.319557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.354285 \n",
      "\n",
      "loss: 0.342624  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.360279 \n",
      "\n",
      "loss: 0.365162  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.341669 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 471/500\n",
      "--------------------\n",
      "{'hl': [375, 499, 565], 'alpha': 0.13357968756537345, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.19425179915719326}\n",
      "loss: 1.079368  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 2131.409030 \n",
      "\n",
      "loss: 2144.242432  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 151.579127 \n",
      "\n",
      "loss: 114.651306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 10.550377 \n",
      "\n",
      "loss: 8.445436  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 2.078826 \n",
      "\n",
      "loss: 2.378895  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.661438 \n",
      "\n",
      "loss: 0.631827  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.804391 \n",
      "\n",
      "loss: 0.887212  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.729064 \n",
      "\n",
      "loss: 0.713857  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.499565 \n",
      "\n",
      "loss: 0.480680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.475460 \n",
      "\n",
      "loss: 0.472680  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.473236 \n",
      "\n",
      "loss: 0.475409  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.470951 \n",
      "\n",
      "loss: 0.477078  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.469173 \n",
      "\n",
      "loss: 0.489064  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.568240 \n",
      "\n",
      "loss: 0.567563  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.443860 \n",
      "\n",
      "loss: 0.414200  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.482070 \n",
      "\n",
      "loss: 0.446521  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.465284 \n",
      "\n",
      "loss: 0.469925  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.469298 \n",
      "\n",
      "loss: 0.485863  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.449030 \n",
      "\n",
      "loss: 0.440469  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.535868 \n",
      "\n",
      "loss: 0.513927  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.478190 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 472/500\n",
      "--------------------\n",
      "{'hl': [34], 'alpha': 0.0018858635620504149, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.4478928143289954}\n",
      "loss: 1.280265  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.463601 \n",
      "\n",
      "loss: 0.506196  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.456136 \n",
      "\n",
      "loss: 0.446526  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.434891 \n",
      "\n",
      "loss: 0.407379  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.407986 \n",
      "\n",
      "loss: 0.406831  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.397337 \n",
      "\n",
      "loss: 0.424139  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.392002 \n",
      "\n",
      "loss: 0.381992  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.409438 \n",
      "\n",
      "loss: 0.386750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.375700 \n",
      "\n",
      "loss: 0.413229  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.402215 \n",
      "\n",
      "loss: 0.375249  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.364499 \n",
      "\n",
      "loss: 0.364274  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.365842 \n",
      "\n",
      "loss: 0.389114  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.357818 \n",
      "\n",
      "loss: 0.362483  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.369606 \n",
      "\n",
      "loss: 0.371514  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.356752 \n",
      "\n",
      "loss: 0.322258  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.362811 \n",
      "\n",
      "loss: 0.426540  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.356589 \n",
      "\n",
      "loss: 0.353759  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.368327 \n",
      "\n",
      "loss: 0.351113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.350847 \n",
      "\n",
      "loss: 0.337427  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.342300 \n",
      "\n",
      "loss: 0.322310  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.340264 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 473/500\n",
      "--------------------\n",
      "{'hl': [67, 491], 'alpha': 0.013113818478338712, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.0501571552187483}\n",
      "loss: 1.138522  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.547645 \n",
      "\n",
      "loss: 0.572974  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.514674 \n",
      "\n",
      "loss: 0.499434  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.494094 \n",
      "\n",
      "loss: 0.507764  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.478263 \n",
      "\n",
      "loss: 0.490465  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.479252 \n",
      "\n",
      "loss: 0.489591  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.465875 \n",
      "\n",
      "loss: 0.460060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.471614 \n",
      "\n",
      "loss: 0.478455  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.471412 \n",
      "\n",
      "loss: 0.482213  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.465923 \n",
      "\n",
      "loss: 0.469116  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.454284 \n",
      "\n",
      "loss: 0.454691  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.444210 \n",
      "\n",
      "loss: 0.446946  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.459880 \n",
      "\n",
      "loss: 0.435372  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.451541 \n",
      "\n",
      "loss: 0.467430  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.443153 \n",
      "\n",
      "loss: 0.435212  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.442536 \n",
      "\n",
      "loss: 0.473688  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.436228 \n",
      "\n",
      "loss: 0.409415  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.447918 \n",
      "\n",
      "loss: 0.417306  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.430012 \n",
      "\n",
      "loss: 0.497749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.413016 \n",
      "\n",
      "loss: 0.385368  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.419786 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 474/500\n",
      "--------------------\n",
      "{'hl': [254, 280, 554], 'alpha': 0.18413682327290098, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.287888485099136}\n",
      "loss: 1.116406  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.814403 \n",
      "\n",
      "loss: 0.820325  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.724246 \n",
      "\n",
      "loss: 0.716850  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.685699 \n",
      "\n",
      "loss: 0.671070  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.683667 \n",
      "\n",
      "loss: 0.687425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.676002 \n",
      "\n",
      "loss: 0.677441  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.680176 \n",
      "\n",
      "loss: 0.664644  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.687825 \n",
      "\n",
      "loss: 0.661290  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.677665 \n",
      "\n",
      "loss: 0.691484  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.684799 \n",
      "\n",
      "loss: 0.680471  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.679829 \n",
      "\n",
      "loss: 0.670208  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.687566 \n",
      "\n",
      "loss: 0.690238  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.686604 \n",
      "\n",
      "loss: 0.668041  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.680735 \n",
      "\n",
      "loss: 0.695944  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.676902 \n",
      "\n",
      "loss: 0.673121  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.687684 \n",
      "\n",
      "loss: 0.670408  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.681908 \n",
      "\n",
      "loss: 0.675221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.688680 \n",
      "\n",
      "loss: 0.691565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.683106 \n",
      "\n",
      "loss: 0.690137  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.676736 \n",
      "\n",
      "loss: 0.682204  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.673575 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 475/500\n",
      "--------------------\n",
      "{'hl': [371, 185], 'alpha': 0.0005062924724149284, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.4569986040638543}\n",
      "loss: 1.129059  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 751.901435 \n",
      "\n",
      "loss: 674.999756  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.7%, Avg loss: 175.275036 \n",
      "\n",
      "loss: 201.031586  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 26.376753 \n",
      "\n",
      "loss: 31.873362  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 41.312987 \n",
      "\n",
      "loss: 42.148716  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 5.811401 \n",
      "\n",
      "loss: 6.313727  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 2.636074 \n",
      "\n",
      "loss: 2.046798  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 3.316591 \n",
      "\n",
      "loss: 2.374893  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 4.104863 \n",
      "\n",
      "loss: 3.515788  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 1.698206 \n",
      "\n",
      "loss: 1.878325  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 1.477934 \n",
      "\n",
      "loss: 1.293698  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.995316 \n",
      "\n",
      "loss: 1.191631  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.932246 \n",
      "\n",
      "loss: 1.052208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.913759 \n",
      "\n",
      "loss: 0.908113  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.587010 \n",
      "\n",
      "loss: 0.496706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.745439 \n",
      "\n",
      "loss: 0.828240  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.458314 \n",
      "\n",
      "loss: 0.454958  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.468794 \n",
      "\n",
      "loss: 0.448395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.447882 \n",
      "\n",
      "loss: 0.428995  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.377873 \n",
      "\n",
      "loss: 0.322092  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.360229 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 476/500\n",
      "--------------------\n",
      "{'hl': [368], 'alpha': 0.6169286514904649, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.41836475068259465}\n",
      "loss: 1.023941  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.704454 \n",
      "\n",
      "loss: 0.705779  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.705292 \n",
      "\n",
      "loss: 0.700348  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.714505 \n",
      "\n",
      "loss: 0.703615  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.698220 \n",
      "\n",
      "loss: 0.727597  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.707906 \n",
      "\n",
      "loss: 0.717562  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.713608 \n",
      "\n",
      "loss: 0.717218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.704376 \n",
      "\n",
      "loss: 0.720097  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.711128 \n",
      "\n",
      "loss: 0.738256  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.686378 \n",
      "\n",
      "loss: 0.705927  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.705301 \n",
      "\n",
      "loss: 0.679276  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.710585 \n",
      "\n",
      "loss: 0.719221  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.703835 \n",
      "\n",
      "loss: 0.696208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.702406 \n",
      "\n",
      "loss: 0.684536  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.708593 \n",
      "\n",
      "loss: 0.700822  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.719071 \n",
      "\n",
      "loss: 0.691528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.706235 \n",
      "\n",
      "loss: 0.688397  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.722118 \n",
      "\n",
      "loss: 0.729392  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.706458 \n",
      "\n",
      "loss: 0.703147  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.712232 \n",
      "\n",
      "loss: 0.710154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.710556 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 477/500\n",
      "--------------------\n",
      "{'hl': [563, 324], 'alpha': 0.0005037639326511082, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.028178371602955568}\n",
      "loss: 1.077132  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.639965 \n",
      "\n",
      "loss: 0.623429  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.538011 \n",
      "\n",
      "loss: 0.566980  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.518258 \n",
      "\n",
      "loss: 0.542715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.497546 \n",
      "\n",
      "loss: 0.513656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.487770 \n",
      "\n",
      "loss: 0.489856  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.485921 \n",
      "\n",
      "loss: 0.451989  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.486765 \n",
      "\n",
      "loss: 0.479165  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.463913 \n",
      "\n",
      "loss: 0.465798  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.456448 \n",
      "\n",
      "loss: 0.407087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.432504 \n",
      "\n",
      "loss: 0.472590  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.441012 \n",
      "\n",
      "loss: 0.459625  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.432991 \n",
      "\n",
      "loss: 0.449528  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.435942 \n",
      "\n",
      "loss: 0.434201  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.415594 \n",
      "\n",
      "loss: 0.434770  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.412095 \n",
      "\n",
      "loss: 0.441350  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.418631 \n",
      "\n",
      "loss: 0.412160  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.415204 \n",
      "\n",
      "loss: 0.424533  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.404394 \n",
      "\n",
      "loss: 0.418456  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.409016 \n",
      "\n",
      "loss: 0.396819  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.394449 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 478/500\n",
      "--------------------\n",
      "{'hl': [232, 28, 547], 'alpha': 0.008164995555387819, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.4032420621136704}\n",
      "loss: 1.115324  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.478650 \n",
      "\n",
      "loss: 0.456280  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.427515 \n",
      "\n",
      "loss: 0.372807  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.389978 \n",
      "\n",
      "loss: 0.376642  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.393950 \n",
      "\n",
      "loss: 0.398973  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.351462 \n",
      "\n",
      "loss: 0.349905  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.358312 \n",
      "\n",
      "loss: 0.376709  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.371109 \n",
      "\n",
      "loss: 0.370593  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.343808 \n",
      "\n",
      "loss: 0.338871  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.590609 \n",
      "\n",
      "loss: 0.528930  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.347222 \n",
      "\n",
      "loss: 0.371858  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.354266 \n",
      "\n",
      "loss: 0.321141  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.383922 \n",
      "\n",
      "loss: 0.408412  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.351645 \n",
      "\n",
      "loss: 0.324537  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.379454 \n",
      "\n",
      "loss: 0.389965  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.354708 \n",
      "\n",
      "loss: 0.379558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.402773 \n",
      "\n",
      "loss: 0.412994  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.340535 \n",
      "\n",
      "loss: 0.310839  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.350658 \n",
      "\n",
      "loss: 0.317676  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.334881 \n",
      "\n",
      "loss: 0.355671  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.341974 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 479/500\n",
      "--------------------\n",
      "{'hl': [189, 339], 'alpha': 0.00017307082001361064, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.387205812760064}\n",
      "loss: 1.071850  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.473863 \n",
      "\n",
      "loss: 0.481386  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.481213 \n",
      "\n",
      "loss: 0.468118  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.475989 \n",
      "\n",
      "loss: 0.461580  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.424360 \n",
      "\n",
      "loss: 0.417128  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.411990 \n",
      "\n",
      "loss: 0.416191  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.9%, Avg loss: 0.430132 \n",
      "\n",
      "loss: 0.419429  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.385008 \n",
      "\n",
      "loss: 0.358403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.411590 \n",
      "\n",
      "loss: 0.394739  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.408399 \n",
      "\n",
      "loss: 0.423275  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.348388 \n",
      "\n",
      "loss: 0.403135  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.360482 \n",
      "\n",
      "loss: 0.338494  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.362489 \n",
      "\n",
      "loss: 0.345217  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.373667 \n",
      "\n",
      "loss: 0.371395  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.468745 \n",
      "\n",
      "loss: 0.459798  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.407083 \n",
      "\n",
      "loss: 0.397156  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.337558 \n",
      "\n",
      "loss: 0.343378  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.353928 \n",
      "\n",
      "loss: 0.324324  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.358655 \n",
      "\n",
      "loss: 0.379008  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.360531 \n",
      "\n",
      "loss: 0.334772  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.330075 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 480/500\n",
      "--------------------\n",
      "{'hl': [381, 82, 390], 'alpha': 0.06578881115763269, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.16834687946328813}\n",
      "loss: 1.093142  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.727928 \n",
      "\n",
      "loss: 2.793528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.308320 \n",
      "\n",
      "loss: 1.295174  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.330174 \n",
      "\n",
      "loss: 1.340143  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.239269 \n",
      "\n",
      "loss: 1.215243  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.307533 \n",
      "\n",
      "loss: 1.265223  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.103444 \n",
      "\n",
      "loss: 1.103737  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.156211 \n",
      "\n",
      "loss: 1.092523  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.099014 \n",
      "\n",
      "loss: 1.094500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.229439 \n",
      "\n",
      "loss: 1.198087  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.234916 \n",
      "\n",
      "loss: 1.248460  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.195324 \n",
      "\n",
      "loss: 1.178940  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.102251 \n",
      "\n",
      "loss: 1.133980  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.300234 \n",
      "\n",
      "loss: 1.261286  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.162742 \n",
      "\n",
      "loss: 1.207167  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.138923 \n",
      "\n",
      "loss: 1.169079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 1.105088 \n",
      "\n",
      "loss: 1.075640  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 1.184905 \n",
      "\n",
      "loss: 1.178557  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.050113 \n",
      "\n",
      "loss: 1.053149  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.207289 \n",
      "\n",
      "loss: 1.245164  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 1.182818 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 481/500\n",
      "--------------------\n",
      "{'hl': [147, 169], 'alpha': 0.08499788155293186, 'activition': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.3246252147958425}\n",
      "loss: 1.089428  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 2.053099 \n",
      "\n",
      "loss: 1.913734  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 4.235916 \n",
      "\n",
      "loss: 4.084963  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 2.843951 \n",
      "\n",
      "loss: 2.858141  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.798904 \n",
      "\n",
      "loss: 1.794182  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.756256 \n",
      "\n",
      "loss: 0.742647  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.842922 \n",
      "\n",
      "loss: 0.849487  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 2.155207 \n",
      "\n",
      "loss: 2.054337  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.847734 \n",
      "\n",
      "loss: 0.848057  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.108306 \n",
      "\n",
      "loss: 1.098627  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.961454 \n",
      "\n",
      "loss: 0.929772  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.043727 \n",
      "\n",
      "loss: 1.092664  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.682930 \n",
      "\n",
      "loss: 1.759951  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.540401 \n",
      "\n",
      "loss: 1.445583  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 6.055551 \n",
      "\n",
      "loss: 6.229806  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 5.797836 \n",
      "\n",
      "loss: 5.862250  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 7.430710 \n",
      "\n",
      "loss: 7.531802  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 4.273920 \n",
      "\n",
      "loss: 4.236226  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 4.732497 \n",
      "\n",
      "loss: 4.810715  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 7.001551 \n",
      "\n",
      "loss: 7.272546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.355327 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 482/500\n",
      "--------------------\n",
      "{'hl': [583], 'alpha': 0.05946228486775452, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.33279928157043587}\n",
      "loss: 1.135596  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.483623 \n",
      "\n",
      "loss: 0.475656  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.475472 \n",
      "\n",
      "loss: 0.465408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.467387 \n",
      "\n",
      "loss: 0.453049  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.457092 \n",
      "\n",
      "loss: 0.494659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.461510 \n",
      "\n",
      "loss: 0.456488  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.451927 \n",
      "\n",
      "loss: 0.506302  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.466383 \n",
      "\n",
      "loss: 0.436125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.467444 \n",
      "\n",
      "loss: 0.446485  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.451054 \n",
      "\n",
      "loss: 0.454861  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.445135 \n",
      "\n",
      "loss: 0.449209  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.453025 \n",
      "\n",
      "loss: 0.456117  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.463064 \n",
      "\n",
      "loss: 0.454103  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.463950 \n",
      "\n",
      "loss: 0.488237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.457566 \n",
      "\n",
      "loss: 0.449903  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.448756 \n",
      "\n",
      "loss: 0.479631  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.448419 \n",
      "\n",
      "loss: 0.474839  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.459908 \n",
      "\n",
      "loss: 0.464861  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.459908 \n",
      "\n",
      "loss: 0.465122  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.446285 \n",
      "\n",
      "loss: 0.476387  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.450957 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 483/500\n",
      "--------------------\n",
      "{'hl': [395], 'alpha': 0.001687690933039628, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.08893637341963195}\n",
      "loss: 1.036337  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.502151 \n",
      "\n",
      "loss: 0.517594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.477801 \n",
      "\n",
      "loss: 0.485541  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.439413 \n",
      "\n",
      "loss: 0.449184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.428661 \n",
      "\n",
      "loss: 0.436691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.419206 \n",
      "\n",
      "loss: 0.437529  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.414912 \n",
      "\n",
      "loss: 0.408726  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.411342 \n",
      "\n",
      "loss: 0.391001  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.412170 \n",
      "\n",
      "loss: 0.412389  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.395988 \n",
      "\n",
      "loss: 0.409191  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.379050 \n",
      "\n",
      "loss: 0.359309  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.380283 \n",
      "\n",
      "loss: 0.358641  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.386145 \n",
      "\n",
      "loss: 0.396451  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.386716 \n",
      "\n",
      "loss: 0.354940  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.375497 \n",
      "\n",
      "loss: 0.378552  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.364515 \n",
      "\n",
      "loss: 0.399634  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.361269 \n",
      "\n",
      "loss: 0.381938  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.366442 \n",
      "\n",
      "loss: 0.336720  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.366895 \n",
      "\n",
      "loss: 0.391981  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.353998 \n",
      "\n",
      "loss: 0.364496  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.348925 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 484/500\n",
      "--------------------\n",
      "{'hl': [594], 'alpha': 0.003684730329565928, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.3012340948587405}\n",
      "loss: 1.121079  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.448661 \n",
      "\n",
      "loss: 0.401090  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.424096 \n",
      "\n",
      "loss: 0.430366  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.397204 \n",
      "\n",
      "loss: 0.381192  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.386099 \n",
      "\n",
      "loss: 0.361844  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.357026 \n",
      "\n",
      "loss: 0.341545  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.365221 \n",
      "\n",
      "loss: 0.371097  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.357708 \n",
      "\n",
      "loss: 0.356107  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.352719 \n",
      "\n",
      "loss: 0.342936  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.346189 \n",
      "\n",
      "loss: 0.346829  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.337987 \n",
      "\n",
      "loss: 0.353478  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.331165 \n",
      "\n",
      "loss: 0.299617  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.344475 \n",
      "\n",
      "loss: 0.330974  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.344946 \n",
      "\n",
      "loss: 0.358273  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.335752 \n",
      "\n",
      "loss: 0.359125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.324203 \n",
      "\n",
      "loss: 0.312486  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.345849 \n",
      "\n",
      "loss: 0.294267  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.339214 \n",
      "\n",
      "loss: 0.309370  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.332540 \n",
      "\n",
      "loss: 0.297364  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.315707 \n",
      "\n",
      "loss: 0.376077  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.318807 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 485/500\n",
      "--------------------\n",
      "{'hl': [234, 662, 587], 'alpha': 0.00026088008785698716, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.16565109624040966}\n",
      "loss: 1.175075  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.823208 \n",
      "\n",
      "loss: 0.823794  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.826443 \n",
      "\n",
      "loss: 0.815642  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.811345 \n",
      "\n",
      "loss: 0.833825  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.814079 \n",
      "\n",
      "loss: 0.824442  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.827068 \n",
      "\n",
      "loss: 0.803586  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.820454 \n",
      "\n",
      "loss: 0.796598  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.820959 \n",
      "\n",
      "loss: 0.788812  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 0.817527 \n",
      "\n",
      "loss: 0.806415  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.807010 \n",
      "\n",
      "loss: 0.857608  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.829679 \n",
      "\n",
      "loss: 0.823279  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.2%, Avg loss: 0.806289 \n",
      "\n",
      "loss: 0.833833  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.819174 \n",
      "\n",
      "loss: 0.774592  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.792020 \n",
      "\n",
      "loss: 0.831986  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 0.820710 \n",
      "\n",
      "loss: 0.849706  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.821615 \n",
      "\n",
      "loss: 0.849270  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.785842 \n",
      "\n",
      "loss: 0.803345  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 0.770008 \n",
      "\n",
      "loss: 0.730887  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.673492 \n",
      "\n",
      "loss: 0.639920  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.632725 \n",
      "\n",
      "loss: 0.628777  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.588387 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 486/500\n",
      "--------------------\n",
      "{'hl': [251], 'alpha': 0.0024391611757920593, 'activition': 'LeakyReLU', 'optimizer': 'SGD', 'lr': 0.3181297664431601}\n",
      "loss: 1.050219  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.471364 \n",
      "\n",
      "loss: 0.482457  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.426314 \n",
      "\n",
      "loss: 0.378031  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.396434 \n",
      "\n",
      "loss: 0.408559  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.377698 \n",
      "\n",
      "loss: 0.410657  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.372775 \n",
      "\n",
      "loss: 0.375393  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.381758 \n",
      "\n",
      "loss: 0.356305  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.361568 \n",
      "\n",
      "loss: 0.357467  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.359912 \n",
      "\n",
      "loss: 0.360421  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.340317 \n",
      "\n",
      "loss: 0.388558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.333065 \n",
      "\n",
      "loss: 0.334609  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.347128 \n",
      "\n",
      "loss: 0.333475  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.344188 \n",
      "\n",
      "loss: 0.370120  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.334979 \n",
      "\n",
      "loss: 0.346181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.347655 \n",
      "\n",
      "loss: 0.336742  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.317943 \n",
      "\n",
      "loss: 0.369969  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.332602 \n",
      "\n",
      "loss: 0.336112  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.382707 \n",
      "\n",
      "loss: 0.378415  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.330973 \n",
      "\n",
      "loss: 0.316612  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.360133 \n",
      "\n",
      "loss: 0.350166  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.311352 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 487/500\n",
      "--------------------\n",
      "{'hl': [694], 'alpha': 0.0360089743631653, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.005796670585719456}\n",
      "loss: 1.096349  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.448203 \n",
      "\n",
      "loss: 0.446113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.457769 \n",
      "\n",
      "loss: 0.447945  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.429438 \n",
      "\n",
      "loss: 0.463617  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.447122 \n",
      "\n",
      "loss: 0.491465  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.440563 \n",
      "\n",
      "loss: 0.450550  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.452382 \n",
      "\n",
      "loss: 0.479174  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.449401 \n",
      "\n",
      "loss: 0.424500  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.426343 \n",
      "\n",
      "loss: 0.426696  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.425046 \n",
      "\n",
      "loss: 0.407927  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.437849 \n",
      "\n",
      "loss: 0.416359  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.431663 \n",
      "\n",
      "loss: 0.452793  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.439181 \n",
      "\n",
      "loss: 0.437535  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.429145 \n",
      "\n",
      "loss: 0.427392  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.415751 \n",
      "\n",
      "loss: 0.437673  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.428769 \n",
      "\n",
      "loss: 0.392716  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.433373 \n",
      "\n",
      "loss: 0.447115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.441516 \n",
      "\n",
      "loss: 0.403847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.433969 \n",
      "\n",
      "loss: 0.440512  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.419079 \n",
      "\n",
      "loss: 0.426066  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.422797 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 488/500\n",
      "--------------------\n",
      "{'hl': [263], 'alpha': 0.05925217615147701, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.3935313010447211}\n",
      "loss: 1.120504  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 10.791288 \n",
      "\n",
      "loss: 12.095220  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 16.147824 \n",
      "\n",
      "loss: 15.216445  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 3.362064 \n",
      "\n",
      "loss: 3.494663  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 8.684306 \n",
      "\n",
      "loss: 8.946007  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 21.125569 \n",
      "\n",
      "loss: 20.947519  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 40.251429 \n",
      "\n",
      "loss: 39.106201  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 5.497963 \n",
      "\n",
      "loss: 6.310181  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 6.708059 \n",
      "\n",
      "loss: 5.485609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 24.574239 \n",
      "\n",
      "loss: 23.173609  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 12.597607 \n",
      "\n",
      "loss: 12.583183  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 17.392770 \n",
      "\n",
      "loss: 15.607470  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 32.580005 \n",
      "\n",
      "loss: 32.040192  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 23.797157 \n",
      "\n",
      "loss: 23.176117  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 13.640578 \n",
      "\n",
      "loss: 12.735428  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 14.699799 \n",
      "\n",
      "loss: 14.250308  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 10.483977 \n",
      "\n",
      "loss: 10.157204  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 2.886740 \n",
      "\n",
      "loss: 3.473344  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 0.607680 \n",
      "\n",
      "loss: 0.625268  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.490028 \n",
      "\n",
      "loss: 0.456646  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.473167 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 489/500\n",
      "--------------------\n",
      "{'hl': [9, 57, 403], 'alpha': 0.0056608358980120566, 'activition': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.442287543593855}\n",
      "loss: 1.205956  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 1.518416 \n",
      "\n",
      "loss: 1.579441  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.884912 \n",
      "\n",
      "loss: 0.876594  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.789178 \n",
      "\n",
      "loss: 0.769095  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.764576 \n",
      "\n",
      "loss: 0.781566  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.723262 \n",
      "\n",
      "loss: 0.696397  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.653420 \n",
      "\n",
      "loss: 0.665659  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.659205 \n",
      "\n",
      "loss: 0.649546  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.684263 \n",
      "\n",
      "loss: 0.695329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.590709 \n",
      "\n",
      "loss: 0.629840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.647211 \n",
      "\n",
      "loss: 0.671665  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.525691 \n",
      "\n",
      "loss: 0.530171  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.523729 \n",
      "\n",
      "loss: 0.512237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.602918 \n",
      "\n",
      "loss: 0.591949  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.697639 \n",
      "\n",
      "loss: 0.740419  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.615342 \n",
      "\n",
      "loss: 0.651055  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.654861 \n",
      "\n",
      "loss: 0.645558  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.519198 \n",
      "\n",
      "loss: 0.494606  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.495151 \n",
      "\n",
      "loss: 0.507198  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.550282 \n",
      "\n",
      "loss: 0.510755  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.592524 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 490/500\n",
      "--------------------\n",
      "{'hl': [395, 367], 'alpha': 0.01527903306395775, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.3943861242386621}\n",
      "loss: 1.110144  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1051.760213 \n",
      "\n",
      "loss: 1058.056152  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 39.756105 \n",
      "\n",
      "loss: 51.088509  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 1.435175 \n",
      "\n",
      "loss: 1.163028  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 5.244669 \n",
      "\n",
      "loss: 6.162208  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.7%, Avg loss: 2.402626 \n",
      "\n",
      "loss: 2.613052  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 2.657096 \n",
      "\n",
      "loss: 2.065824  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 181.982029 \n",
      "\n",
      "loss: 193.074966  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 21.501334 \n",
      "\n",
      "loss: 22.457510  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 1.471087 \n",
      "\n",
      "loss: 1.581523  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 2.367181 \n",
      "\n",
      "loss: 2.862177  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.573359 \n",
      "\n",
      "loss: 0.492813  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.794333 \n",
      "\n",
      "loss: 0.849154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 117.239416 \n",
      "\n",
      "loss: 126.635719  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 6.210197 \n",
      "\n",
      "loss: 6.517838  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.739453 \n",
      "\n",
      "loss: 0.819735  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.685221 \n",
      "\n",
      "loss: 0.546027  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 1.725492 \n",
      "\n",
      "loss: 1.593796  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 25.204178 \n",
      "\n",
      "loss: 21.295782  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.713051 \n",
      "\n",
      "loss: 0.666749  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 9.306764 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 491/500\n",
      "--------------------\n",
      "{'hl': [674, 711, 238], 'alpha': 0.00044732796270237184, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.14752481569675346}\n",
      "loss: 1.072463  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.500443 \n",
      "\n",
      "loss: 0.514771  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.456871 \n",
      "\n",
      "loss: 0.462355  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.435314 \n",
      "\n",
      "loss: 0.383520  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.407637 \n",
      "\n",
      "loss: 0.379103  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.394081 \n",
      "\n",
      "loss: 0.375645  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.367955 \n",
      "\n",
      "loss: 0.358064  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.373076 \n",
      "\n",
      "loss: 0.367282  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.376371 \n",
      "\n",
      "loss: 0.363032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.359544 \n",
      "\n",
      "loss: 0.347694  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.349591 \n",
      "\n",
      "loss: 0.368018  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.328267 \n",
      "\n",
      "loss: 0.319987  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.337887 \n",
      "\n",
      "loss: 0.321803  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.324980 \n",
      "\n",
      "loss: 0.292834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.323278 \n",
      "\n",
      "loss: 0.332329  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.3%, Avg loss: 0.320595 \n",
      "\n",
      "loss: 0.290011  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.315168 \n",
      "\n",
      "loss: 0.276802  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.325913 \n",
      "\n",
      "loss: 0.340830  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.299129 \n",
      "\n",
      "loss: 0.303985  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.355542 \n",
      "\n",
      "loss: 0.394504  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.294329 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 492/500\n",
      "--------------------\n",
      "{'hl': [275, 115], 'alpha': 0.00019806220380671842, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.08053615700616941}\n",
      "loss: 1.081038  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.568461 \n",
      "\n",
      "loss: 0.570060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.504791 \n",
      "\n",
      "loss: 0.495313  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.507848 \n",
      "\n",
      "loss: 0.452444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.429097 \n",
      "\n",
      "loss: 0.451005  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.432965 \n",
      "\n",
      "loss: 0.489666  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.399450 \n",
      "\n",
      "loss: 0.376427  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.400853 \n",
      "\n",
      "loss: 0.325844  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.405792 \n",
      "\n",
      "loss: 0.349884  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.380083 \n",
      "\n",
      "loss: 0.387445  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.375694 \n",
      "\n",
      "loss: 0.394979  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.392115 \n",
      "\n",
      "loss: 0.405301  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.401220 \n",
      "\n",
      "loss: 0.386752  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.380905 \n",
      "\n",
      "loss: 0.403381  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.432981 \n",
      "\n",
      "loss: 0.467494  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.363141 \n",
      "\n",
      "loss: 0.351022  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.393372 \n",
      "\n",
      "loss: 0.405049  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.384537 \n",
      "\n",
      "loss: 0.366022  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.425819 \n",
      "\n",
      "loss: 0.486154  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.400238 \n",
      "\n",
      "loss: 0.393086  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.438149 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 493/500\n",
      "--------------------\n",
      "{'hl': [568], 'alpha': 0.5852434666232895, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.2970558689716422}\n",
      "loss: 1.219216  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 2.280024 \n",
      "\n",
      "loss: 2.571556  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.679851 \n",
      "\n",
      "loss: 0.681219  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.743339 \n",
      "\n",
      "loss: 0.742816  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.708443 \n",
      "\n",
      "loss: 0.719161  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.777379 \n",
      "\n",
      "loss: 0.783269  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.732315 \n",
      "\n",
      "loss: 0.720113  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.753446 \n",
      "\n",
      "loss: 0.755659  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.742825 \n",
      "\n",
      "loss: 0.743503  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.723959 \n",
      "\n",
      "loss: 0.721403  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.740737 \n",
      "\n",
      "loss: 0.738159  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.754285 \n",
      "\n",
      "loss: 0.756239  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.754433 \n",
      "\n",
      "loss: 0.747729  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.728138 \n",
      "\n",
      "loss: 0.721132  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.753287 \n",
      "\n",
      "loss: 0.762180  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.736168 \n",
      "\n",
      "loss: 0.745366  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.722484 \n",
      "\n",
      "loss: 0.702748  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.729557 \n",
      "\n",
      "loss: 0.705554  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.741657 \n",
      "\n",
      "loss: 0.740287  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.737654 \n",
      "\n",
      "loss: 0.732700  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.732510 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 494/500\n",
      "--------------------\n",
      "{'hl': [502, 39, 449], 'alpha': 0.5885305782883915, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.07863617828765895}\n",
      "loss: 1.136263  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.951613 \n",
      "\n",
      "loss: 0.952496  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.976745 \n",
      "\n",
      "loss: 0.973478  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.972988 \n",
      "\n",
      "loss: 0.973644  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.972399 \n",
      "\n",
      "loss: 0.973840  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.970621 \n",
      "\n",
      "loss: 0.974036  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.972465 \n",
      "\n",
      "loss: 0.973143  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.972952 \n",
      "\n",
      "loss: 0.971265  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.970672 \n",
      "\n",
      "loss: 0.972123  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.977057 \n",
      "\n",
      "loss: 0.976342  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.971637 \n",
      "\n",
      "loss: 0.967457  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.971423 \n",
      "\n",
      "loss: 0.967433  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.969858 \n",
      "\n",
      "loss: 0.973565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.971491 \n",
      "\n",
      "loss: 0.971046  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.969826 \n",
      "\n",
      "loss: 0.968237  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.967938 \n",
      "\n",
      "loss: 0.972503  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.972213 \n",
      "\n",
      "loss: 0.973956  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.971958 \n",
      "\n",
      "loss: 0.973089  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.972164 \n",
      "\n",
      "loss: 0.966691  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.969371 \n",
      "\n",
      "loss: 0.973155  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.968434 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 495/500\n",
      "--------------------\n",
      "{'hl': [347], 'alpha': 0.0006640517214429511, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.3486286322332978}\n",
      "loss: 1.124986  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 3.498902 \n",
      "\n",
      "loss: 3.271763  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 3.532174 \n",
      "\n",
      "loss: 3.490259  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 3.075866 \n",
      "\n",
      "loss: 3.105603  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 3.424494 \n",
      "\n",
      "loss: 3.414721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.9%, Avg loss: 1.622993 \n",
      "\n",
      "loss: 1.591711  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 3.209247 \n",
      "\n",
      "loss: 3.184792  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 1.648426 \n",
      "\n",
      "loss: 1.568989  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 3.364120 \n",
      "\n",
      "loss: 3.218424  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 1.940475 \n",
      "\n",
      "loss: 1.977636  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 3.757681 \n",
      "\n",
      "loss: 3.731407  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 2.614504 \n",
      "\n",
      "loss: 2.463612  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 3.301240 \n",
      "\n",
      "loss: 3.189580  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 1.897060 \n",
      "\n",
      "loss: 1.695494  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 3.920838 \n",
      "\n",
      "loss: 3.996902  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 1.675643 \n",
      "\n",
      "loss: 1.869394  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 1.316069 \n",
      "\n",
      "loss: 1.162199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 2.627282 \n",
      "\n",
      "loss: 2.546408  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 2.085921 \n",
      "\n",
      "loss: 1.876238  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 2.678058 \n",
      "\n",
      "loss: 2.873870  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 1.758322 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 496/500\n",
      "--------------------\n",
      "{'hl': [561, 279, 684], 'alpha': 0.0013368795923702527, 'activition': 'Tanh', 'optimizer': 'SGD', 'lr': 0.024912757974951082}\n",
      "loss: 1.093075  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.612009 \n",
      "\n",
      "loss: 0.631359  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.561657 \n",
      "\n",
      "loss: 0.570727  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.524779 \n",
      "\n",
      "loss: 0.515444  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.507150 \n",
      "\n",
      "loss: 0.482755  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.500283 \n",
      "\n",
      "loss: 0.522839  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.494998 \n",
      "\n",
      "loss: 0.513351  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.499748 \n",
      "\n",
      "loss: 0.499215  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.492377 \n",
      "\n",
      "loss: 0.441365  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.474361 \n",
      "\n",
      "loss: 0.523316  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.464446 \n",
      "\n",
      "loss: 0.474386  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.472029 \n",
      "\n",
      "loss: 0.464123  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.469959 \n",
      "\n",
      "loss: 0.455281  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.453412 \n",
      "\n",
      "loss: 0.496393  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.457628 \n",
      "\n",
      "loss: 0.454356  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.452009 \n",
      "\n",
      "loss: 0.428766  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.455820 \n",
      "\n",
      "loss: 0.460689  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.458413 \n",
      "\n",
      "loss: 0.421492  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.448056 \n",
      "\n",
      "loss: 0.420450  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.439075 \n",
      "\n",
      "loss: 0.480565  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.431309 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 497/500\n",
      "--------------------\n",
      "{'hl': [570, 510, 165], 'alpha': 0.0001652035619203608, 'activition': 'ReLU', 'optimizer': 'Adam', 'lr': 0.043905416817555304}\n",
      "loss: 1.081320  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 1.734907 \n",
      "\n",
      "loss: 1.553161  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.664289 \n",
      "\n",
      "loss: 0.595693  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.552417 \n",
      "\n",
      "loss: 0.538938  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.480974 \n",
      "\n",
      "loss: 0.465721  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.477590 \n",
      "\n",
      "loss: 0.504329  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.485920 \n",
      "\n",
      "loss: 0.495567  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 84.0%, Avg loss: 0.456447 \n",
      "\n",
      "loss: 0.438302  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.438301 \n",
      "\n",
      "loss: 0.471558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.485737 \n",
      "\n",
      "loss: 0.524480  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.793610 \n",
      "\n",
      "loss: 0.790218  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.823068 \n",
      "\n",
      "loss: 0.806097  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 0.819189 \n",
      "\n",
      "loss: 0.763425  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.774234 \n",
      "\n",
      "loss: 0.765847  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.809966 \n",
      "\n",
      "loss: 0.802123  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.813386 \n",
      "\n",
      "loss: 0.818922  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.817313 \n",
      "\n",
      "loss: 0.804199  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.828718 \n",
      "\n",
      "loss: 0.826404  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 0.810781 \n",
      "\n",
      "loss: 0.800558  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.773480 \n",
      "\n",
      "loss: 0.823124  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.748462 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 498/500\n",
      "--------------------\n",
      "{'hl': [648, 622, 499], 'alpha': 0.00062907033116529, 'activition': 'ReLU', 'optimizer': 'SGD', 'lr': 0.08549901262694232}\n",
      "loss: 1.101812  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.551893 \n",
      "\n",
      "loss: 0.540054  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.7%, Avg loss: 0.494660 \n",
      "\n",
      "loss: 0.462440  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.466319 \n",
      "\n",
      "loss: 0.519834  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 83.4%, Avg loss: 0.428019 \n",
      "\n",
      "loss: 0.492178  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.418606 \n",
      "\n",
      "loss: 0.386968  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.418249 \n",
      "\n",
      "loss: 0.366098  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.396396 \n",
      "\n",
      "loss: 0.345475  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.393346 \n",
      "\n",
      "loss: 0.337386  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.378418 \n",
      "\n",
      "loss: 0.410004  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.355005 \n",
      "\n",
      "loss: 0.370271  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.368956 \n",
      "\n",
      "loss: 0.372374  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.362420 \n",
      "\n",
      "loss: 0.369750  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.346999 \n",
      "\n",
      "loss: 0.332093  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.353673 \n",
      "\n",
      "loss: 0.327514  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.330189 \n",
      "\n",
      "loss: 0.347594  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.332973 \n",
      "\n",
      "loss: 0.297523  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.345539 \n",
      "\n",
      "loss: 0.322019  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.346958 \n",
      "\n",
      "loss: 0.360184  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.326658 \n",
      "\n",
      "loss: 0.350407  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.323681 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 499/500\n",
      "--------------------\n",
      "{'hl': [91, 492], 'alpha': 0.2371790348102561, 'activition': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.2355251320294998}\n",
      "loss: 1.102435  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 35.305137 \n",
      "\n",
      "loss: 25.446115  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 20.293226 \n",
      "\n",
      "loss: 19.528183  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 1.002631 \n",
      "\n",
      "loss: 1.040607  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.522528 \n",
      "\n",
      "loss: 0.495370  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.563838 \n",
      "\n",
      "loss: 0.544379  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.592582 \n",
      "\n",
      "loss: 0.565019  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.609441 \n",
      "\n",
      "loss: 0.634032  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.616082 \n",
      "\n",
      "loss: 0.636615  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.634571 \n",
      "\n",
      "loss: 0.632656  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.634194 \n",
      "\n",
      "loss: 0.647909  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.636948 \n",
      "\n",
      "loss: 0.634134  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.636420 \n",
      "\n",
      "loss: 0.656104  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.629683 \n",
      "\n",
      "loss: 0.620517  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.625940 \n",
      "\n",
      "loss: 0.638439  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.2%, Avg loss: 0.639540 \n",
      "\n",
      "loss: 0.614957  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.641500 \n",
      "\n",
      "loss: 0.641933  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.635325 \n",
      "\n",
      "loss: 0.629649  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.631043 \n",
      "\n",
      "loss: 0.637437  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.636274 \n",
      "\n",
      "loss: 0.635423  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.647860 \n",
      "\n",
      "--------------------\n",
      "--------------------\n",
      "Search progess: 500/500\n",
      "--------------------\n",
      "{'hl': [279, 101, 665], 'alpha': 0.015014266384058063, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.4427577971054945}\n",
      "loss: 1.128999  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 15.352233 \n",
      "\n",
      "loss: 14.401330  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 50.930173 \n",
      "\n",
      "loss: 54.190746  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 19.267394 \n",
      "\n",
      "loss: 19.802645  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 50.6%, Avg loss: 13.930605 \n",
      "\n",
      "loss: 13.435664  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 25.922890 \n",
      "\n",
      "loss: 23.860060  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 10.805192 \n",
      "\n",
      "loss: 11.045472  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 12.119272 \n",
      "\n",
      "loss: 11.648703  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 31.7%, Avg loss: 25.711883 \n",
      "\n",
      "loss: 26.582125  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 16.770672 \n",
      "\n",
      "loss: 16.589424  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 13.528332 \n",
      "\n",
      "loss: 13.091528  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 74.4%, Avg loss: 12.811177 \n",
      "\n",
      "loss: 14.733828  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 18.5%, Avg loss: 16.126179 \n",
      "\n",
      "loss: 16.380619  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 9.762626 \n",
      "\n",
      "loss: 9.392353  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 10.908412 \n",
      "\n",
      "loss: 10.801172  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 9.501870 \n",
      "\n",
      "loss: 9.303032  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 7.304914 \n",
      "\n",
      "loss: 8.246260  [ 1024/33273]\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 23.232080 \n",
      "\n",
      "loss: 23.210239  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 18.252166 \n",
      "\n",
      "loss: 17.707407  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 6.978476 \n",
      "\n",
      "loss: 6.840331  [ 1024/33274]\n",
      "Test Error: \n",
      " Accuracy: 45.9%, Avg loss: 16.725238 \n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Random search on cross validation set\n",
    "\n",
    "random.seed(random_state)\n",
    "\n",
    "input_size=X_test_selected.shape[-1]\n",
    "output_size=3\n",
    "\n",
    "num_search = 500    # The number of random search\n",
    "\n",
    "accuracy_list = []\n",
    "hp_list = []\n",
    "pm_list = []\n",
    "\n",
    "for search in range(num_search):\n",
    "    print('-'*20)\n",
    "    print(\"Search progess: \"+str(search+1)+\"/\"+str(num_search))\n",
    "    print('-'*20)\n",
    "    hp = get_hps()\n",
    "    print(hp)\n",
    "    model_rs = DNN_rs(input_size=input_size, hidden_sizes=hp['hl'], output_size=output_size, activition_layer=hp['activition']).to(device)\n",
    "    \n",
    "    if hp['optimizer'] == 'SGD':\n",
    "        optimizer_rs = torch.optim.SGD(model_rs.parameters(), lr=hp['lr'], weight_decay=hp['alpha'])\n",
    "    elif hp['optimizer'] == 'Adam':\n",
    "        optimizer_rs = torch.optim.Adam(model_rs.parameters(), lr=hp['lr'], weight_decay=hp['alpha'])\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        break\n",
    "        \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        train_dataloader = train_dataloader_list[i%5]\n",
    "        validation_dataloader = val_dataloader_list[i%5]\n",
    "        model_rs.train()\n",
    "        train(train_dataloader, model_rs, loss_fn, optimizer_rs)\n",
    "        test(validation_dataloader, model_rs, loss_fn)\n",
    "        \n",
    "        if (i+1)%5==0:\n",
    "            model_rs.eval()\n",
    "            pred = model_rs(val_dataloader_k.dataset[:][0]).detach().cpu().max(axis=1).indices.numpy()\n",
    "            true = val_dataloader_k.dataset[:][1].cpu().numpy()\n",
    "            accuracy_list.append(accuracy_score(true, pred))\n",
    "            hp.update({'epoch': i+1})\n",
    "            hp_list.append(hp.copy())\n",
    "            pm_list.append(model_rs.state_dict())\n",
    "    print('-'*20)\n",
    "    \n",
    "accuracy_list = np.array(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "The best accuracy in validation set is:  0.9177245624158492\n",
      "The best hyperparameter is:  {'hl': [142], 'alpha': 0.00011466775475719672, 'activition': 'Tanh', 'optimizer': 'Adam', 'lr': 0.00798896364722901, 'epoch': 20}\n",
      "--------------------\n",
      "Accuracy: 0.8844489324870167\n",
      "F1 score: 0.8844489324870167\n",
      "Recall score: 0.8844489324870167\n",
      "Precision score: 0.8844489324870167\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the best hyper parameters and show the performance on test set\n",
    "\n",
    "best_idx = np.argmax(accuracy_list)\n",
    "hp = hp_list[best_idx]\n",
    "print(\"-\"*20)\n",
    "print(\"The best accuracy in validation set is: \", accuracy_list[best_idx])\n",
    "print(\"The best hyperparameter is: \", hp)\n",
    "print(\"-\"*20)\n",
    "model_best = DNN_rs(input_size=input_size, hidden_sizes=hp['hl'], output_size=output_size, activition_layer=hp['activition']).to(device)\n",
    "model_best.load_state_dict(pm_list[best_idx])\n",
    "\n",
    "model_best.eval()\n",
    "pred = model_best(test_dataloader.dataset[:][0]).detach().cpu().max(axis=1).indices.numpy()\n",
    "true = test_dataloader.dataset[:][1].cpu().numpy()\n",
    "\n",
    "performance_eval(true, pred, matrix_display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
